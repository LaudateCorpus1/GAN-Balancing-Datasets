{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real neptune attacks:\n",
      "[[  0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0 225  16   1   2   0   0   6   2   0  18  16   7   3   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  36   6   1   2   0   0   7   4   0  18   6   3   1   0\n",
      "    0   0   0   0   0   0]]\n",
      "0 [D loss: 2.368061, acc.: 51.95%] [G loss: 0.751996] [Loss difference: 0.752, iterations with loss: 0]\n",
      "1 [D loss: 1.741958, acc.: 41.70%] [G loss: 0.731671] [Loss difference: -0.020, iterations with loss: 1]\n",
      "2 [D loss: 1.238004, acc.: 42.19%] [G loss: 0.726749] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3 [D loss: 0.790942, acc.: 54.10%] [G loss: 0.719540] [Loss difference: -0.007, iterations with loss: 0]\n",
      "4 [D loss: 0.555188, acc.: 67.09%] [G loss: 0.710767] [Loss difference: -0.009, iterations with loss: 0]\n",
      "5 [D loss: 0.471391, acc.: 70.12%] [G loss: 0.698561] [Loss difference: -0.012, iterations with loss: 0]\n",
      "6 [D loss: 0.425457, acc.: 70.51%] [G loss: 0.677987] [Loss difference: -0.021, iterations with loss: 0]\n",
      "7 [D loss: 0.405448, acc.: 70.61%] [G loss: 0.673708] [Loss difference: -0.004, iterations with loss: 0]\n",
      "8 [D loss: 0.395244, acc.: 69.04%] [G loss: 0.659202] [Loss difference: -0.015, iterations with loss: 0]\n",
      "9 [D loss: 0.392718, acc.: 69.04%] [G loss: 0.651089] [Loss difference: -0.008, iterations with loss: 0]\n",
      "10 [D loss: 0.399990, acc.: 63.87%] [G loss: 0.641169] [Loss difference: -0.010, iterations with loss: 0]\n",
      "11 [D loss: 0.399625, acc.: 65.33%] [G loss: 0.635612] [Loss difference: -0.006, iterations with loss: 0]\n",
      "12 [D loss: 0.400365, acc.: 65.14%] [G loss: 0.622147] [Loss difference: -0.013, iterations with loss: 0]\n",
      "13 [D loss: 0.407723, acc.: 63.38%] [G loss: 0.606006] [Loss difference: -0.016, iterations with loss: 0]\n",
      "14 [D loss: 0.412845, acc.: 62.01%] [G loss: 0.600931] [Loss difference: -0.005, iterations with loss: 0]\n",
      "15 [D loss: 0.416761, acc.: 62.21%] [G loss: 0.596939] [Loss difference: -0.004, iterations with loss: 0]\n",
      "16 [D loss: 0.428044, acc.: 60.06%] [G loss: 0.588271] [Loss difference: -0.009, iterations with loss: 0]\n",
      "17 [D loss: 0.438128, acc.: 58.30%] [G loss: 0.571333] [Loss difference: -0.017, iterations with loss: 0]\n",
      "18 [D loss: 0.442365, acc.: 58.69%] [G loss: 0.565153] [Loss difference: -0.006, iterations with loss: 0]\n",
      "19 [D loss: 0.453274, acc.: 57.13%] [G loss: 0.553295] [Loss difference: -0.012, iterations with loss: 0]\n",
      "20 [D loss: 0.455236, acc.: 56.54%] [G loss: 0.544212] [Loss difference: -0.009, iterations with loss: 0]\n",
      "21 [D loss: 0.465850, acc.: 56.25%] [G loss: 0.527401] [Loss difference: -0.017, iterations with loss: 0]\n",
      "22 [D loss: 0.475587, acc.: 56.74%] [G loss: 0.533576] [Loss difference: 0.006, iterations with loss: 0]\n",
      "23 [D loss: 0.468000, acc.: 55.57%] [G loss: 0.513729] [Loss difference: -0.020, iterations with loss: 1]\n",
      "24 [D loss: 0.488965, acc.: 56.15%] [G loss: 0.510740] [Loss difference: -0.003, iterations with loss: 0]\n",
      "25 [D loss: 0.506446, acc.: 54.98%] [G loss: 0.505239] [Loss difference: -0.006, iterations with loss: 0]\n",
      "26 [D loss: 0.501181, acc.: 54.59%] [G loss: 0.485172] [Loss difference: -0.020, iterations with loss: 0]\n",
      "27 [D loss: 0.508829, acc.: 54.10%] [G loss: 0.479761] [Loss difference: -0.005, iterations with loss: 0]\n",
      "28 [D loss: 0.528503, acc.: 52.73%] [G loss: 0.469515] [Loss difference: -0.010, iterations with loss: 0]\n",
      "29 [D loss: 0.542553, acc.: 52.83%] [G loss: 0.462412] [Loss difference: -0.007, iterations with loss: 0]\n",
      "30 [D loss: 0.554560, acc.: 53.03%] [G loss: 0.447842] [Loss difference: -0.015, iterations with loss: 0]\n",
      "31 [D loss: 0.572731, acc.: 52.34%] [G loss: 0.445370] [Loss difference: -0.002, iterations with loss: 0]\n",
      "32 [D loss: 0.570138, acc.: 52.54%] [G loss: 0.434741] [Loss difference: -0.011, iterations with loss: 0]\n",
      "33 [D loss: 0.599292, acc.: 51.37%] [G loss: 0.433651] [Loss difference: -0.001, iterations with loss: 0]\n",
      "34 [D loss: 0.580764, acc.: 52.44%] [G loss: 0.426251] [Loss difference: -0.007, iterations with loss: 0]\n",
      "35 [D loss: 0.592868, acc.: 51.95%] [G loss: 0.413695] [Loss difference: -0.013, iterations with loss: 0]\n",
      "36 [D loss: 0.609543, acc.: 51.46%] [G loss: 0.404895] [Loss difference: -0.009, iterations with loss: 0]\n",
      "37 [D loss: 0.625359, acc.: 51.46%] [G loss: 0.396980] [Loss difference: -0.008, iterations with loss: 0]\n",
      "38 [D loss: 0.639570, acc.: 50.59%] [G loss: 0.384409] [Loss difference: -0.013, iterations with loss: 0]\n",
      "39 [D loss: 0.646134, acc.: 51.56%] [G loss: 0.387069] [Loss difference: 0.003, iterations with loss: 0]\n",
      "40 [D loss: 0.640321, acc.: 51.17%] [G loss: 0.378169] [Loss difference: -0.009, iterations with loss: 1]\n",
      "41 [D loss: 0.646227, acc.: 50.98%] [G loss: 0.368796] [Loss difference: -0.009, iterations with loss: 0]\n",
      "42 [D loss: 0.661327, acc.: 51.66%] [G loss: 0.363483] [Loss difference: -0.005, iterations with loss: 0]\n",
      "43 [D loss: 0.704824, acc.: 50.49%] [G loss: 0.355940] [Loss difference: -0.008, iterations with loss: 0]\n",
      "44 [D loss: 0.712214, acc.: 50.78%] [G loss: 0.340928] [Loss difference: -0.015, iterations with loss: 0]\n",
      "45 [D loss: 0.707822, acc.: 50.88%] [G loss: 0.343557] [Loss difference: 0.003, iterations with loss: 0]\n",
      "46 [D loss: 0.718454, acc.: 50.29%] [G loss: 0.337948] [Loss difference: -0.006, iterations with loss: 1]\n",
      "47 [D loss: 0.728649, acc.: 50.59%] [G loss: 0.331821] [Loss difference: -0.006, iterations with loss: 0]\n",
      "48 [D loss: 0.738922, acc.: 50.49%] [G loss: 0.321603] [Loss difference: -0.010, iterations with loss: 0]\n",
      "49 [D loss: 0.725375, acc.: 50.59%] [G loss: 0.320079] [Loss difference: -0.002, iterations with loss: 0]\n",
      "50 [D loss: 0.760659, acc.: 50.29%] [G loss: 0.310344] [Loss difference: -0.010, iterations with loss: 0]\n",
      "51 [D loss: 0.781659, acc.: 50.39%] [G loss: 0.314837] [Loss difference: 0.004, iterations with loss: 0]\n",
      "52 [D loss: 0.809108, acc.: 50.49%] [G loss: 0.304647] [Loss difference: -0.010, iterations with loss: 1]\n",
      "53 [D loss: 0.784018, acc.: 50.20%] [G loss: 0.302185] [Loss difference: -0.002, iterations with loss: 0]\n",
      "54 [D loss: 0.803374, acc.: 50.68%] [G loss: 0.291147] [Loss difference: -0.011, iterations with loss: 0]\n",
      "55 [D loss: 0.798771, acc.: 50.29%] [G loss: 0.284903] [Loss difference: -0.006, iterations with loss: 0]\n",
      "56 [D loss: 0.814609, acc.: 50.20%] [G loss: 0.284752] [Loss difference: -0.000, iterations with loss: 0]\n",
      "57 [D loss: 0.831365, acc.: 50.20%] [G loss: 0.282996] [Loss difference: -0.002, iterations with loss: 0]\n",
      "58 [D loss: 0.839937, acc.: 50.00%] [G loss: 0.277995] [Loss difference: -0.005, iterations with loss: 0]\n",
      "59 [D loss: 0.867197, acc.: 50.29%] [G loss: 0.266273] [Loss difference: -0.012, iterations with loss: 0]\n",
      "60 [D loss: 0.899878, acc.: 50.49%] [G loss: 0.272220] [Loss difference: 0.006, iterations with loss: 0]\n",
      "61 [D loss: 0.867668, acc.: 50.39%] [G loss: 0.269266] [Loss difference: -0.003, iterations with loss: 1]\n",
      "62 [D loss: 0.855566, acc.: 50.20%] [G loss: 0.257075] [Loss difference: -0.012, iterations with loss: 0]\n",
      "63 [D loss: 0.880521, acc.: 50.00%] [G loss: 0.260498] [Loss difference: 0.003, iterations with loss: 0]\n",
      "64 [D loss: 0.880596, acc.: 50.29%] [G loss: 0.260012] [Loss difference: -0.000, iterations with loss: 1]\n",
      "65 [D loss: 0.891527, acc.: 50.29%] [G loss: 0.253492] [Loss difference: -0.007, iterations with loss: 0]\n",
      "66 [D loss: 0.911616, acc.: 50.20%] [G loss: 0.258734] [Loss difference: 0.005, iterations with loss: 0]\n",
      "67 [D loss: 0.907256, acc.: 50.20%] [G loss: 0.250673] [Loss difference: -0.008, iterations with loss: 1]\n",
      "68 [D loss: 0.879533, acc.: 50.29%] [G loss: 0.242388] [Loss difference: -0.008, iterations with loss: 0]\n",
      "69 [D loss: 0.919258, acc.: 50.39%] [G loss: 0.235019] [Loss difference: -0.007, iterations with loss: 0]\n",
      "70 [D loss: 0.912011, acc.: 50.00%] [G loss: 0.239845] [Loss difference: 0.005, iterations with loss: 0]\n",
      "71 [D loss: 0.909752, acc.: 50.20%] [G loss: 0.234241] [Loss difference: -0.006, iterations with loss: 1]\n",
      "72 [D loss: 0.908640, acc.: 50.20%] [G loss: 0.228286] [Loss difference: -0.006, iterations with loss: 0]\n",
      "73 [D loss: 0.956151, acc.: 50.20%] [G loss: 0.226460] [Loss difference: -0.002, iterations with loss: 0]\n",
      "74 [D loss: 0.955902, acc.: 50.10%] [G loss: 0.217951] [Loss difference: -0.009, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 [D loss: 0.973166, acc.: 50.10%] [G loss: 0.220845] [Loss difference: 0.003, iterations with loss: 0]\n",
      "76 [D loss: 0.991612, acc.: 50.29%] [G loss: 0.224717] [Loss difference: 0.004, iterations with loss: 1]\n",
      "77 [D loss: 0.959754, acc.: 50.10%] [G loss: 0.215526] [Loss difference: -0.009, iterations with loss: 2]\n",
      "78 [D loss: 0.963391, acc.: 50.29%] [G loss: 0.222114] [Loss difference: 0.007, iterations with loss: 0]\n",
      "79 [D loss: 0.977523, acc.: 50.00%] [G loss: 0.219163] [Loss difference: -0.003, iterations with loss: 1]\n",
      "80 [D loss: 0.989238, acc.: 50.49%] [G loss: 0.218597] [Loss difference: -0.001, iterations with loss: 0]\n",
      "81 [D loss: 0.980182, acc.: 50.10%] [G loss: 0.212645] [Loss difference: -0.006, iterations with loss: 0]\n",
      "82 [D loss: 0.994857, acc.: 50.00%] [G loss: 0.207585] [Loss difference: -0.005, iterations with loss: 0]\n",
      "83 [D loss: 1.013055, acc.: 50.10%] [G loss: 0.210751] [Loss difference: 0.003, iterations with loss: 0]\n",
      "84 [D loss: 1.029735, acc.: 50.10%] [G loss: 0.208213] [Loss difference: -0.003, iterations with loss: 1]\n",
      "85 [D loss: 1.038340, acc.: 50.20%] [G loss: 0.203764] [Loss difference: -0.004, iterations with loss: 0]\n",
      "86 [D loss: 1.017984, acc.: 50.20%] [G loss: 0.202431] [Loss difference: -0.001, iterations with loss: 0]\n",
      "87 [D loss: 1.045403, acc.: 50.20%] [G loss: 0.202224] [Loss difference: -0.000, iterations with loss: 0]\n",
      "88 [D loss: 1.061401, acc.: 50.20%] [G loss: 0.203157] [Loss difference: 0.001, iterations with loss: 0]\n",
      "89 [D loss: 1.017482, acc.: 50.20%] [G loss: 0.208713] [Loss difference: 0.006, iterations with loss: 1]\n",
      "90 [D loss: 1.031802, acc.: 50.20%] [G loss: 0.197328] [Loss difference: -0.011, iterations with loss: 2]\n",
      "91 [D loss: 1.039081, acc.: 50.10%] [G loss: 0.197482] [Loss difference: 0.000, iterations with loss: 0]\n",
      "92 [D loss: 1.034615, acc.: 50.10%] [G loss: 0.186817] [Loss difference: -0.011, iterations with loss: 1]\n",
      "93 [D loss: 1.051862, acc.: 50.10%] [G loss: 0.190886] [Loss difference: 0.004, iterations with loss: 0]\n",
      "94 [D loss: 1.073214, acc.: 50.20%] [G loss: 0.191708] [Loss difference: 0.001, iterations with loss: 1]\n",
      "95 [D loss: 1.074850, acc.: 50.00%] [G loss: 0.187312] [Loss difference: -0.004, iterations with loss: 2]\n",
      "96 [D loss: 1.063474, acc.: 50.29%] [G loss: 0.183346] [Loss difference: -0.004, iterations with loss: 0]\n",
      "97 [D loss: 1.071163, acc.: 50.10%] [G loss: 0.188128] [Loss difference: 0.005, iterations with loss: 0]\n",
      "98 [D loss: 1.063111, acc.: 50.00%] [G loss: 0.189508] [Loss difference: 0.001, iterations with loss: 1]\n",
      "99 [D loss: 1.089498, acc.: 50.00%] [G loss: 0.191219] [Loss difference: 0.002, iterations with loss: 2]\n",
      "100 [D loss: 1.068207, acc.: 50.10%] [G loss: 0.180858] [Loss difference: -0.010, iterations with loss: 3]\n",
      "101 [D loss: 1.077568, acc.: 50.00%] [G loss: 0.180637] [Loss difference: -0.000, iterations with loss: 0]\n",
      "102 [D loss: 1.135414, acc.: 50.10%] [G loss: 0.181366] [Loss difference: 0.001, iterations with loss: 0]\n",
      "103 [D loss: 1.098070, acc.: 50.10%] [G loss: 0.175062] [Loss difference: -0.006, iterations with loss: 1]\n",
      "104 [D loss: 1.073973, acc.: 50.20%] [G loss: 0.177835] [Loss difference: 0.003, iterations with loss: 0]\n",
      "105 [D loss: 1.114404, acc.: 50.10%] [G loss: 0.171874] [Loss difference: -0.006, iterations with loss: 1]\n",
      "106 [D loss: 1.111631, acc.: 50.00%] [G loss: 0.176543] [Loss difference: 0.005, iterations with loss: 0]\n",
      "107 [D loss: 1.131532, acc.: 50.20%] [G loss: 0.179106] [Loss difference: 0.003, iterations with loss: 1]\n",
      "108 [D loss: 1.062277, acc.: 50.20%] [G loss: 0.182821] [Loss difference: 0.004, iterations with loss: 2]\n",
      "109 [D loss: 1.157063, acc.: 50.00%] [G loss: 0.176386] [Loss difference: -0.006, iterations with loss: 3]\n",
      "110 [D loss: 1.137736, acc.: 50.10%] [G loss: 0.173719] [Loss difference: -0.003, iterations with loss: 0]\n",
      "111 [D loss: 1.101803, acc.: 50.00%] [G loss: 0.178244] [Loss difference: 0.005, iterations with loss: 0]\n",
      "112 [D loss: 1.107239, acc.: 50.20%] [G loss: 0.170935] [Loss difference: -0.007, iterations with loss: 1]\n",
      "113 [D loss: 1.114411, acc.: 50.10%] [G loss: 0.165480] [Loss difference: -0.005, iterations with loss: 0]\n",
      "114 [D loss: 1.104142, acc.: 50.29%] [G loss: 0.169646] [Loss difference: 0.004, iterations with loss: 0]\n",
      "115 [D loss: 1.061086, acc.: 50.00%] [G loss: 0.172800] [Loss difference: 0.003, iterations with loss: 1]\n",
      "116 [D loss: 1.097915, acc.: 50.29%] [G loss: 0.164643] [Loss difference: -0.008, iterations with loss: 2]\n",
      "117 [D loss: 1.136216, acc.: 50.10%] [G loss: 0.171508] [Loss difference: 0.007, iterations with loss: 0]\n",
      "118 [D loss: 1.162698, acc.: 50.10%] [G loss: 0.161692] [Loss difference: -0.010, iterations with loss: 1]\n",
      "119 [D loss: 1.139776, acc.: 50.00%] [G loss: 0.163183] [Loss difference: 0.001, iterations with loss: 0]\n",
      "120 [D loss: 1.170640, acc.: 50.20%] [G loss: 0.161575] [Loss difference: -0.002, iterations with loss: 1]\n",
      "121 [D loss: 1.110833, acc.: 50.00%] [G loss: 0.158112] [Loss difference: -0.003, iterations with loss: 0]\n",
      "122 [D loss: 1.140875, acc.: 50.00%] [G loss: 0.159547] [Loss difference: 0.001, iterations with loss: 0]\n",
      "123 [D loss: 1.138157, acc.: 50.29%] [G loss: 0.159133] [Loss difference: -0.000, iterations with loss: 1]\n",
      "124 [D loss: 1.161142, acc.: 50.00%] [G loss: 0.155511] [Loss difference: -0.004, iterations with loss: 0]\n",
      "125 [D loss: 1.157073, acc.: 50.10%] [G loss: 0.150635] [Loss difference: -0.005, iterations with loss: 0]\n",
      "126 [D loss: 1.131813, acc.: 50.00%] [G loss: 0.164160] [Loss difference: 0.014, iterations with loss: 0]\n",
      "127 [D loss: 1.136244, acc.: 50.10%] [G loss: 0.161004] [Loss difference: -0.003, iterations with loss: 1]\n",
      "128 [D loss: 1.161257, acc.: 50.10%] [G loss: 0.158627] [Loss difference: -0.002, iterations with loss: 0]\n",
      "129 [D loss: 1.158816, acc.: 50.20%] [G loss: 0.146655] [Loss difference: -0.012, iterations with loss: 0]\n",
      "130 [D loss: 1.179799, acc.: 50.00%] [G loss: 0.153444] [Loss difference: 0.007, iterations with loss: 0]\n",
      "131 [D loss: 1.173575, acc.: 50.00%] [G loss: 0.150673] [Loss difference: -0.003, iterations with loss: 1]\n",
      "132 [D loss: 1.162058, acc.: 50.20%] [G loss: 0.153849] [Loss difference: 0.003, iterations with loss: 0]\n",
      "133 [D loss: 1.179266, acc.: 50.10%] [G loss: 0.143941] [Loss difference: -0.010, iterations with loss: 1]\n",
      "134 [D loss: 1.165362, acc.: 50.00%] [G loss: 0.156176] [Loss difference: 0.012, iterations with loss: 0]\n",
      "135 [D loss: 1.202947, acc.: 50.00%] [G loss: 0.148436] [Loss difference: -0.008, iterations with loss: 1]\n",
      "136 [D loss: 1.179980, acc.: 50.29%] [G loss: 0.148239] [Loss difference: -0.000, iterations with loss: 0]\n",
      "137 [D loss: 1.180725, acc.: 50.10%] [G loss: 0.147942] [Loss difference: -0.000, iterations with loss: 0]\n",
      "138 [D loss: 1.189534, acc.: 50.00%] [G loss: 0.148967] [Loss difference: 0.001, iterations with loss: 0]\n",
      "139 [D loss: 1.209940, acc.: 50.00%] [G loss: 0.144477] [Loss difference: -0.004, iterations with loss: 1]\n",
      "140 [D loss: 1.225931, acc.: 50.10%] [G loss: 0.139621] [Loss difference: -0.005, iterations with loss: 0]\n",
      "141 [D loss: 1.153479, acc.: 50.10%] [G loss: 0.151289] [Loss difference: 0.012, iterations with loss: 0]\n",
      "142 [D loss: 1.188835, acc.: 50.10%] [G loss: 0.152134] [Loss difference: 0.001, iterations with loss: 1]\n",
      "143 [D loss: 1.197027, acc.: 50.00%] [G loss: 0.145631] [Loss difference: -0.007, iterations with loss: 2]\n",
      "144 [D loss: 1.187709, acc.: 50.10%] [G loss: 0.144419] [Loss difference: -0.001, iterations with loss: 0]\n",
      "145 [D loss: 1.175794, acc.: 50.10%] [G loss: 0.146314] [Loss difference: 0.002, iterations with loss: 0]\n",
      "146 [D loss: 1.224593, acc.: 50.00%] [G loss: 0.150441] [Loss difference: 0.004, iterations with loss: 1]\n",
      "147 [D loss: 1.230945, acc.: 50.00%] [G loss: 0.142391] [Loss difference: -0.008, iterations with loss: 2]\n",
      "148 [D loss: 1.194429, acc.: 50.00%] [G loss: 0.136227] [Loss difference: -0.006, iterations with loss: 0]\n",
      "149 [D loss: 1.206901, acc.: 50.00%] [G loss: 0.139576] [Loss difference: 0.003, iterations with loss: 0]\n",
      "150 [D loss: 1.182361, acc.: 50.10%] [G loss: 0.141910] [Loss difference: 0.002, iterations with loss: 1]\n",
      "151 [D loss: 1.226843, acc.: 50.00%] [G loss: 0.148195] [Loss difference: 0.006, iterations with loss: 2]\n",
      "152 [D loss: 1.212686, acc.: 50.00%] [G loss: 0.143871] [Loss difference: -0.004, iterations with loss: 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 [D loss: 1.206066, acc.: 50.00%] [G loss: 0.139695] [Loss difference: -0.004, iterations with loss: 0]\n",
      "154 [D loss: 1.244004, acc.: 50.10%] [G loss: 0.138278] [Loss difference: -0.001, iterations with loss: 0]\n",
      "155 [D loss: 1.219337, acc.: 50.10%] [G loss: 0.138162] [Loss difference: -0.000, iterations with loss: 0]\n",
      "156 [D loss: 1.194682, acc.: 50.00%] [G loss: 0.147148] [Loss difference: 0.009, iterations with loss: 0]\n",
      "157 [D loss: 1.252343, acc.: 50.10%] [G loss: 0.143584] [Loss difference: -0.004, iterations with loss: 1]\n",
      "158 [D loss: 1.234421, acc.: 50.10%] [G loss: 0.141182] [Loss difference: -0.002, iterations with loss: 0]\n",
      "159 [D loss: 1.170983, acc.: 50.00%] [G loss: 0.140741] [Loss difference: -0.000, iterations with loss: 0]\n",
      "160 [D loss: 1.203303, acc.: 50.00%] [G loss: 0.142179] [Loss difference: 0.001, iterations with loss: 0]\n",
      "161 [D loss: 1.176240, acc.: 50.10%] [G loss: 0.137990] [Loss difference: -0.004, iterations with loss: 1]\n",
      "162 [D loss: 1.188465, acc.: 50.00%] [G loss: 0.147540] [Loss difference: 0.010, iterations with loss: 0]\n",
      "163 [D loss: 1.228074, acc.: 50.00%] [G loss: 0.136762] [Loss difference: -0.011, iterations with loss: 1]\n",
      "164 [D loss: 1.196599, acc.: 50.00%] [G loss: 0.127741] [Loss difference: -0.009, iterations with loss: 0]\n",
      "165 [D loss: 1.201951, acc.: 50.10%] [G loss: 0.134198] [Loss difference: 0.006, iterations with loss: 0]\n",
      "166 [D loss: 1.174626, acc.: 50.10%] [G loss: 0.141351] [Loss difference: 0.007, iterations with loss: 1]\n",
      "167 [D loss: 1.184755, acc.: 50.10%] [G loss: 0.128932] [Loss difference: -0.012, iterations with loss: 2]\n",
      "168 [D loss: 1.253791, acc.: 50.00%] [G loss: 0.130925] [Loss difference: 0.002, iterations with loss: 0]\n",
      "169 [D loss: 1.236929, acc.: 50.20%] [G loss: 0.136057] [Loss difference: 0.005, iterations with loss: 1]\n",
      "170 [D loss: 1.224021, acc.: 50.00%] [G loss: 0.135156] [Loss difference: -0.001, iterations with loss: 2]\n",
      "171 [D loss: 1.239865, acc.: 50.00%] [G loss: 0.139068] [Loss difference: 0.004, iterations with loss: 0]\n",
      "172 [D loss: 1.260118, acc.: 50.10%] [G loss: 0.124906] [Loss difference: -0.014, iterations with loss: 1]\n",
      "173 [D loss: 1.230483, acc.: 50.00%] [G loss: 0.135103] [Loss difference: 0.010, iterations with loss: 0]\n",
      "174 [D loss: 1.215068, acc.: 50.10%] [G loss: 0.132431] [Loss difference: -0.003, iterations with loss: 1]\n",
      "175 [D loss: 1.255745, acc.: 50.00%] [G loss: 0.126144] [Loss difference: -0.006, iterations with loss: 0]\n",
      "176 [D loss: 1.247077, acc.: 50.00%] [G loss: 0.128837] [Loss difference: 0.003, iterations with loss: 0]\n",
      "177 [D loss: 1.233635, acc.: 50.10%] [G loss: 0.135398] [Loss difference: 0.007, iterations with loss: 1]\n",
      "178 [D loss: 1.257588, acc.: 50.10%] [G loss: 0.124819] [Loss difference: -0.011, iterations with loss: 2]\n",
      "179 [D loss: 1.234046, acc.: 50.10%] [G loss: 0.124309] [Loss difference: -0.001, iterations with loss: 0]\n",
      "180 [D loss: 1.232370, acc.: 50.00%] [G loss: 0.131750] [Loss difference: 0.007, iterations with loss: 0]\n",
      "181 [D loss: 1.241002, acc.: 50.10%] [G loss: 0.134888] [Loss difference: 0.003, iterations with loss: 1]\n",
      "182 [D loss: 1.240851, acc.: 50.00%] [G loss: 0.128982] [Loss difference: -0.006, iterations with loss: 2]\n",
      "183 [D loss: 1.250606, acc.: 50.00%] [G loss: 0.130082] [Loss difference: 0.001, iterations with loss: 0]\n",
      "184 [D loss: 1.240520, acc.: 50.00%] [G loss: 0.121920] [Loss difference: -0.008, iterations with loss: 1]\n",
      "185 [D loss: 1.272443, acc.: 50.00%] [G loss: 0.126711] [Loss difference: 0.005, iterations with loss: 0]\n",
      "186 [D loss: 1.240592, acc.: 50.00%] [G loss: 0.131263] [Loss difference: 0.005, iterations with loss: 1]\n",
      "187 [D loss: 1.256535, acc.: 50.10%] [G loss: 0.129452] [Loss difference: -0.002, iterations with loss: 2]\n",
      "188 [D loss: 1.253964, acc.: 50.00%] [G loss: 0.124664] [Loss difference: -0.005, iterations with loss: 0]\n",
      "189 [D loss: 1.246435, acc.: 50.00%] [G loss: 0.124056] [Loss difference: -0.001, iterations with loss: 0]\n",
      "190 [D loss: 1.273311, acc.: 50.00%] [G loss: 0.129326] [Loss difference: 0.005, iterations with loss: 0]\n",
      "191 [D loss: 1.258313, acc.: 50.00%] [G loss: 0.127315] [Loss difference: -0.002, iterations with loss: 1]\n",
      "192 [D loss: 1.221896, acc.: 50.00%] [G loss: 0.122342] [Loss difference: -0.005, iterations with loss: 0]\n",
      "193 [D loss: 1.271011, acc.: 50.10%] [G loss: 0.123857] [Loss difference: 0.002, iterations with loss: 0]\n",
      "194 [D loss: 1.263019, acc.: 50.00%] [G loss: 0.126789] [Loss difference: 0.003, iterations with loss: 1]\n",
      "195 [D loss: 1.255719, acc.: 50.10%] [G loss: 0.124389] [Loss difference: -0.002, iterations with loss: 2]\n",
      "196 [D loss: 1.275400, acc.: 50.00%] [G loss: 0.128116] [Loss difference: 0.004, iterations with loss: 0]\n",
      "197 [D loss: 1.261206, acc.: 50.10%] [G loss: 0.126893] [Loss difference: -0.001, iterations with loss: 1]\n",
      "198 [D loss: 1.322901, acc.: 50.10%] [G loss: 0.126178] [Loss difference: -0.001, iterations with loss: 0]\n",
      "199 [D loss: 1.280067, acc.: 50.00%] [G loss: 0.124255] [Loss difference: -0.002, iterations with loss: 0]\n",
      "200 [D loss: 1.247158, acc.: 50.00%] [G loss: 0.121381] [Loss difference: -0.003, iterations with loss: 0]\n",
      "201 [D loss: 1.305625, acc.: 50.00%] [G loss: 0.126588] [Loss difference: 0.005, iterations with loss: 0]\n",
      "202 [D loss: 1.274800, acc.: 50.00%] [G loss: 0.124830] [Loss difference: -0.002, iterations with loss: 1]\n",
      "203 [D loss: 1.267523, acc.: 50.00%] [G loss: 0.120139] [Loss difference: -0.005, iterations with loss: 0]\n",
      "204 [D loss: 1.277903, acc.: 50.00%] [G loss: 0.127387] [Loss difference: 0.007, iterations with loss: 0]\n",
      "205 [D loss: 1.281889, acc.: 50.00%] [G loss: 0.125167] [Loss difference: -0.002, iterations with loss: 1]\n",
      "206 [D loss: 1.275221, acc.: 50.00%] [G loss: 0.129466] [Loss difference: 0.004, iterations with loss: 0]\n",
      "207 [D loss: 1.316726, acc.: 50.00%] [G loss: 0.117648] [Loss difference: -0.012, iterations with loss: 1]\n",
      "208 [D loss: 1.276998, acc.: 50.00%] [G loss: 0.124089] [Loss difference: 0.006, iterations with loss: 0]\n",
      "209 [D loss: 1.279485, acc.: 50.00%] [G loss: 0.128322] [Loss difference: 0.004, iterations with loss: 1]\n",
      "210 [D loss: 1.253546, acc.: 50.00%] [G loss: 0.123287] [Loss difference: -0.005, iterations with loss: 2]\n",
      "211 [D loss: 1.305462, acc.: 50.00%] [G loss: 0.125044] [Loss difference: 0.002, iterations with loss: 0]\n",
      "212 [D loss: 1.274541, acc.: 50.00%] [G loss: 0.126901] [Loss difference: 0.002, iterations with loss: 1]\n",
      "213 [D loss: 1.263096, acc.: 50.00%] [G loss: 0.121189] [Loss difference: -0.006, iterations with loss: 2]\n",
      "214 [D loss: 1.295087, acc.: 50.00%] [G loss: 0.127316] [Loss difference: 0.006, iterations with loss: 0]\n",
      "215 [D loss: 1.303826, acc.: 50.00%] [G loss: 0.127232] [Loss difference: -0.000, iterations with loss: 1]\n",
      "216 [D loss: 1.290169, acc.: 50.00%] [G loss: 0.124612] [Loss difference: -0.003, iterations with loss: 0]\n",
      "217 [D loss: 1.287677, acc.: 50.00%] [G loss: 0.129432] [Loss difference: 0.005, iterations with loss: 0]\n",
      "218 [D loss: 1.296723, acc.: 50.00%] [G loss: 0.120140] [Loss difference: -0.009, iterations with loss: 1]\n",
      "219 [D loss: 1.315770, acc.: 50.00%] [G loss: 0.114468] [Loss difference: -0.006, iterations with loss: 0]\n",
      "220 [D loss: 1.302135, acc.: 50.00%] [G loss: 0.126587] [Loss difference: 0.012, iterations with loss: 0]\n",
      "221 [D loss: 1.309428, acc.: 50.00%] [G loss: 0.118647] [Loss difference: -0.008, iterations with loss: 1]\n",
      "222 [D loss: 1.271818, acc.: 50.00%] [G loss: 0.119923] [Loss difference: 0.001, iterations with loss: 0]\n",
      "223 [D loss: 1.325129, acc.: 50.00%] [G loss: 0.125750] [Loss difference: 0.006, iterations with loss: 1]\n",
      "224 [D loss: 1.307739, acc.: 50.00%] [G loss: 0.124344] [Loss difference: -0.001, iterations with loss: 2]\n",
      "225 [D loss: 1.279219, acc.: 50.20%] [G loss: 0.133811] [Loss difference: 0.009, iterations with loss: 0]\n",
      "226 [D loss: 1.305067, acc.: 50.10%] [G loss: 0.123261] [Loss difference: -0.011, iterations with loss: 1]\n",
      "227 [D loss: 1.294763, acc.: 50.00%] [G loss: 0.122932] [Loss difference: -0.000, iterations with loss: 0]\n",
      "228 [D loss: 1.289200, acc.: 50.00%] [G loss: 0.129168] [Loss difference: 0.006, iterations with loss: 0]\n",
      "229 [D loss: 1.295212, acc.: 50.00%] [G loss: 0.119608] [Loss difference: -0.010, iterations with loss: 1]\n",
      "230 [D loss: 1.283229, acc.: 50.00%] [G loss: 0.117190] [Loss difference: -0.002, iterations with loss: 0]\n",
      "231 [D loss: 1.304170, acc.: 50.10%] [G loss: 0.119880] [Loss difference: 0.003, iterations with loss: 0]\n",
      "232 [D loss: 1.277893, acc.: 50.10%] [G loss: 0.125038] [Loss difference: 0.005, iterations with loss: 1]\n",
      "233 [D loss: 1.286079, acc.: 50.00%] [G loss: 0.114167] [Loss difference: -0.011, iterations with loss: 2]\n",
      "234 [D loss: 1.315210, acc.: 50.10%] [G loss: 0.125781] [Loss difference: 0.012, iterations with loss: 0]\n",
      "235 [D loss: 1.268012, acc.: 50.00%] [G loss: 0.120729] [Loss difference: -0.005, iterations with loss: 1]\n",
      "236 [D loss: 1.270078, acc.: 50.10%] [G loss: 0.118700] [Loss difference: -0.002, iterations with loss: 0]\n",
      "237 [D loss: 1.252639, acc.: 50.00%] [G loss: 0.129390] [Loss difference: 0.011, iterations with loss: 0]\n",
      "238 [D loss: 1.266897, acc.: 50.00%] [G loss: 0.115508] [Loss difference: -0.014, iterations with loss: 1]\n",
      "239 [D loss: 1.300827, acc.: 50.00%] [G loss: 0.116865] [Loss difference: 0.001, iterations with loss: 0]\n",
      "240 [D loss: 1.304558, acc.: 50.10%] [G loss: 0.120780] [Loss difference: 0.004, iterations with loss: 1]\n",
      "241 [D loss: 1.311467, acc.: 50.00%] [G loss: 0.117475] [Loss difference: -0.003, iterations with loss: 2]\n",
      "242 [D loss: 1.332868, acc.: 50.00%] [G loss: 0.119362] [Loss difference: 0.002, iterations with loss: 0]\n",
      "243 [D loss: 1.302185, acc.: 50.00%] [G loss: 0.124083] [Loss difference: 0.005, iterations with loss: 1]\n",
      "244 [D loss: 1.336139, acc.: 50.00%] [G loss: 0.118427] [Loss difference: -0.006, iterations with loss: 2]\n",
      "245 [D loss: 1.324611, acc.: 50.00%] [G loss: 0.123468] [Loss difference: 0.005, iterations with loss: 0]\n",
      "246 [D loss: 1.350049, acc.: 50.00%] [G loss: 0.119295] [Loss difference: -0.004, iterations with loss: 1]\n",
      "247 [D loss: 1.283243, acc.: 50.00%] [G loss: 0.122046] [Loss difference: 0.003, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 [D loss: 1.257536, acc.: 50.10%] [G loss: 0.125252] [Loss difference: 0.003, iterations with loss: 1]\n",
      "249 [D loss: 1.310972, acc.: 50.00%] [G loss: 0.126777] [Loss difference: 0.002, iterations with loss: 2]\n",
      "250 [D loss: 1.294180, acc.: 50.00%] [G loss: 0.122748] [Loss difference: -0.004, iterations with loss: 3]\n",
      "251 [D loss: 1.320733, acc.: 50.00%] [G loss: 0.117281] [Loss difference: -0.005, iterations with loss: 0]\n",
      "252 [D loss: 1.282281, acc.: 50.00%] [G loss: 0.119285] [Loss difference: 0.002, iterations with loss: 0]\n",
      "253 [D loss: 1.334112, acc.: 50.00%] [G loss: 0.118269] [Loss difference: -0.001, iterations with loss: 1]\n",
      "254 [D loss: 1.308635, acc.: 50.00%] [G loss: 0.116429] [Loss difference: -0.002, iterations with loss: 0]\n",
      "255 [D loss: 1.301736, acc.: 50.00%] [G loss: 0.120404] [Loss difference: 0.004, iterations with loss: 0]\n",
      "256 [D loss: 1.275321, acc.: 50.00%] [G loss: 0.117773] [Loss difference: -0.003, iterations with loss: 1]\n",
      "257 [D loss: 1.299410, acc.: 50.00%] [G loss: 0.122321] [Loss difference: 0.005, iterations with loss: 0]\n",
      "258 [D loss: 1.258687, acc.: 50.00%] [G loss: 0.120489] [Loss difference: -0.002, iterations with loss: 1]\n",
      "259 [D loss: 1.306308, acc.: 50.00%] [G loss: 0.119982] [Loss difference: -0.001, iterations with loss: 0]\n",
      "260 [D loss: 1.256516, acc.: 50.00%] [G loss: 0.119884] [Loss difference: -0.000, iterations with loss: 0]\n",
      "261 [D loss: 1.262755, acc.: 50.00%] [G loss: 0.122188] [Loss difference: 0.002, iterations with loss: 0]\n",
      "262 [D loss: 1.317660, acc.: 50.00%] [G loss: 0.124621] [Loss difference: 0.002, iterations with loss: 1]\n",
      "263 [D loss: 1.305393, acc.: 50.00%] [G loss: 0.121686] [Loss difference: -0.003, iterations with loss: 2]\n",
      "264 [D loss: 1.291460, acc.: 50.00%] [G loss: 0.111832] [Loss difference: -0.010, iterations with loss: 0]\n",
      "265 [D loss: 1.282030, acc.: 50.00%] [G loss: 0.118082] [Loss difference: 0.006, iterations with loss: 0]\n",
      "266 [D loss: 1.314460, acc.: 50.00%] [G loss: 0.116281] [Loss difference: -0.002, iterations with loss: 1]\n",
      "267 [D loss: 1.311352, acc.: 50.00%] [G loss: 0.116775] [Loss difference: 0.000, iterations with loss: 0]\n",
      "268 [D loss: 1.309876, acc.: 50.10%] [G loss: 0.124445] [Loss difference: 0.008, iterations with loss: 1]\n",
      "269 [D loss: 1.279997, acc.: 50.00%] [G loss: 0.116273] [Loss difference: -0.008, iterations with loss: 2]\n",
      "270 [D loss: 1.336020, acc.: 50.00%] [G loss: 0.125728] [Loss difference: 0.009, iterations with loss: 0]\n",
      "271 [D loss: 1.291212, acc.: 50.00%] [G loss: 0.122380] [Loss difference: -0.003, iterations with loss: 1]\n",
      "272 [D loss: 1.313517, acc.: 50.00%] [G loss: 0.121273] [Loss difference: -0.001, iterations with loss: 0]\n",
      "273 [D loss: 1.293258, acc.: 50.00%] [G loss: 0.120495] [Loss difference: -0.001, iterations with loss: 0]\n",
      "274 [D loss: 1.323734, acc.: 50.00%] [G loss: 0.112522] [Loss difference: -0.008, iterations with loss: 0]\n",
      "275 [D loss: 1.329625, acc.: 50.00%] [G loss: 0.112496] [Loss difference: -0.000, iterations with loss: 0]\n",
      "276 [D loss: 1.325213, acc.: 50.00%] [G loss: 0.125903] [Loss difference: 0.013, iterations with loss: 0]\n",
      "277 [D loss: 1.309192, acc.: 50.00%] [G loss: 0.113702] [Loss difference: -0.012, iterations with loss: 1]\n",
      "278 [D loss: 1.289055, acc.: 50.00%] [G loss: 0.116656] [Loss difference: 0.003, iterations with loss: 0]\n",
      "279 [D loss: 1.344327, acc.: 50.00%] [G loss: 0.108699] [Loss difference: -0.008, iterations with loss: 1]\n",
      "280 [D loss: 1.326495, acc.: 50.00%] [G loss: 0.124692] [Loss difference: 0.016, iterations with loss: 0]\n",
      "281 [D loss: 1.291339, acc.: 50.00%] [G loss: 0.118152] [Loss difference: -0.007, iterations with loss: 1]\n",
      "282 [D loss: 1.341482, acc.: 50.00%] [G loss: 0.120663] [Loss difference: 0.003, iterations with loss: 0]\n",
      "283 [D loss: 1.323222, acc.: 50.00%] [G loss: 0.110117] [Loss difference: -0.011, iterations with loss: 1]\n",
      "284 [D loss: 1.324106, acc.: 50.00%] [G loss: 0.113641] [Loss difference: 0.004, iterations with loss: 0]\n",
      "285 [D loss: 1.343514, acc.: 50.00%] [G loss: 0.119207] [Loss difference: 0.006, iterations with loss: 1]\n",
      "286 [D loss: 1.326574, acc.: 50.00%] [G loss: 0.112952] [Loss difference: -0.006, iterations with loss: 2]\n",
      "287 [D loss: 1.304390, acc.: 50.00%] [G loss: 0.119981] [Loss difference: 0.007, iterations with loss: 0]\n",
      "288 [D loss: 1.320860, acc.: 50.00%] [G loss: 0.107549] [Loss difference: -0.012, iterations with loss: 1]\n",
      "289 [D loss: 1.313528, acc.: 50.00%] [G loss: 0.117495] [Loss difference: 0.010, iterations with loss: 0]\n",
      "290 [D loss: 1.314039, acc.: 50.00%] [G loss: 0.115288] [Loss difference: -0.002, iterations with loss: 1]\n",
      "291 [D loss: 1.324421, acc.: 50.00%] [G loss: 0.111493] [Loss difference: -0.004, iterations with loss: 0]\n",
      "292 [D loss: 1.335005, acc.: 50.00%] [G loss: 0.115497] [Loss difference: 0.004, iterations with loss: 0]\n",
      "293 [D loss: 1.344664, acc.: 50.00%] [G loss: 0.105682] [Loss difference: -0.010, iterations with loss: 1]\n",
      "294 [D loss: 1.302809, acc.: 50.00%] [G loss: 0.111371] [Loss difference: 0.006, iterations with loss: 0]\n",
      "295 [D loss: 1.337320, acc.: 50.00%] [G loss: 0.120763] [Loss difference: 0.009, iterations with loss: 1]\n",
      "296 [D loss: 1.341234, acc.: 50.00%] [G loss: 0.109127] [Loss difference: -0.012, iterations with loss: 2]\n",
      "297 [D loss: 1.295549, acc.: 50.00%] [G loss: 0.113027] [Loss difference: 0.004, iterations with loss: 0]\n",
      "298 [D loss: 1.353681, acc.: 50.00%] [G loss: 0.108276] [Loss difference: -0.005, iterations with loss: 1]\n",
      "299 [D loss: 1.309986, acc.: 50.00%] [G loss: 0.113680] [Loss difference: 0.005, iterations with loss: 0]\n",
      "300 [D loss: 1.315633, acc.: 50.10%] [G loss: 0.113707] [Loss difference: 0.000, iterations with loss: 1]\n",
      "301 [D loss: 1.296458, acc.: 50.00%] [G loss: 0.114291] [Loss difference: 0.001, iterations with loss: 2]\n",
      "302 [D loss: 1.347453, acc.: 50.00%] [G loss: 0.109755] [Loss difference: -0.005, iterations with loss: 3]\n",
      "303 [D loss: 1.346745, acc.: 50.00%] [G loss: 0.110971] [Loss difference: 0.001, iterations with loss: 0]\n",
      "304 [D loss: 1.320621, acc.: 50.00%] [G loss: 0.107241] [Loss difference: -0.004, iterations with loss: 1]\n",
      "305 [D loss: 1.364306, acc.: 50.00%] [G loss: 0.110299] [Loss difference: 0.003, iterations with loss: 0]\n",
      "306 [D loss: 1.357722, acc.: 50.00%] [G loss: 0.111638] [Loss difference: 0.001, iterations with loss: 1]\n",
      "307 [D loss: 1.343776, acc.: 50.00%] [G loss: 0.108725] [Loss difference: -0.003, iterations with loss: 2]\n",
      "308 [D loss: 1.344993, acc.: 50.00%] [G loss: 0.108235] [Loss difference: -0.000, iterations with loss: 0]\n",
      "309 [D loss: 1.353768, acc.: 50.00%] [G loss: 0.119197] [Loss difference: 0.011, iterations with loss: 0]\n",
      "310 [D loss: 1.333995, acc.: 50.00%] [G loss: 0.108351] [Loss difference: -0.011, iterations with loss: 1]\n",
      "311 [D loss: 1.312666, acc.: 50.00%] [G loss: 0.108588] [Loss difference: 0.000, iterations with loss: 0]\n",
      "312 [D loss: 1.368171, acc.: 50.00%] [G loss: 0.113027] [Loss difference: 0.004, iterations with loss: 1]\n",
      "313 [D loss: 1.327032, acc.: 50.00%] [G loss: 0.108019] [Loss difference: -0.005, iterations with loss: 2]\n",
      "314 [D loss: 1.292922, acc.: 50.00%] [G loss: 0.110592] [Loss difference: 0.003, iterations with loss: 0]\n",
      "315 [D loss: 1.350216, acc.: 50.00%] [G loss: 0.103048] [Loss difference: -0.008, iterations with loss: 1]\n",
      "316 [D loss: 1.338804, acc.: 50.00%] [G loss: 0.112068] [Loss difference: 0.009, iterations with loss: 0]\n",
      "317 [D loss: 1.396025, acc.: 50.00%] [G loss: 0.102806] [Loss difference: -0.009, iterations with loss: 1]\n",
      "318 [D loss: 1.330465, acc.: 50.00%] [G loss: 0.108475] [Loss difference: 0.006, iterations with loss: 0]\n",
      "319 [D loss: 1.326826, acc.: 50.00%] [G loss: 0.108521] [Loss difference: 0.000, iterations with loss: 1]\n",
      "320 [D loss: 1.371711, acc.: 49.90%] [G loss: 0.107351] [Loss difference: -0.001, iterations with loss: 2]\n",
      "321 [D loss: 1.317155, acc.: 49.90%] [G loss: 0.108600] [Loss difference: 0.001, iterations with loss: 0]\n",
      "322 [D loss: 1.378983, acc.: 49.90%] [G loss: 0.105340] [Loss difference: -0.003, iterations with loss: 1]\n",
      "323 [D loss: 1.360705, acc.: 50.00%] [G loss: 0.110779] [Loss difference: 0.005, iterations with loss: 0]\n",
      "324 [D loss: 1.363071, acc.: 50.00%] [G loss: 0.106637] [Loss difference: -0.004, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 [D loss: 1.364560, acc.: 50.00%] [G loss: 0.100888] [Loss difference: -0.006, iterations with loss: 0]\n",
      "326 [D loss: 1.362147, acc.: 50.00%] [G loss: 0.109907] [Loss difference: 0.009, iterations with loss: 0]\n",
      "327 [D loss: 1.340674, acc.: 50.00%] [G loss: 0.104381] [Loss difference: -0.006, iterations with loss: 1]\n",
      "328 [D loss: 1.344185, acc.: 50.00%] [G loss: 0.104341] [Loss difference: -0.000, iterations with loss: 0]\n",
      "329 [D loss: 1.349278, acc.: 50.00%] [G loss: 0.107443] [Loss difference: 0.003, iterations with loss: 0]\n",
      "330 [D loss: 1.337283, acc.: 50.00%] [G loss: 0.109196] [Loss difference: 0.002, iterations with loss: 1]\n",
      "331 [D loss: 1.363734, acc.: 50.00%] [G loss: 0.098821] [Loss difference: -0.010, iterations with loss: 2]\n",
      "332 [D loss: 1.361687, acc.: 50.00%] [G loss: 0.104580] [Loss difference: 0.006, iterations with loss: 0]\n",
      "333 [D loss: 1.367340, acc.: 50.00%] [G loss: 0.103504] [Loss difference: -0.001, iterations with loss: 1]\n",
      "334 [D loss: 1.382808, acc.: 50.00%] [G loss: 0.107352] [Loss difference: 0.004, iterations with loss: 0]\n",
      "335 [D loss: 1.333916, acc.: 50.00%] [G loss: 0.107671] [Loss difference: 0.000, iterations with loss: 1]\n",
      "336 [D loss: 1.327405, acc.: 50.00%] [G loss: 0.106954] [Loss difference: -0.001, iterations with loss: 2]\n",
      "337 [D loss: 1.346478, acc.: 50.00%] [G loss: 0.105483] [Loss difference: -0.001, iterations with loss: 0]\n",
      "338 [D loss: 1.390606, acc.: 49.90%] [G loss: 0.104109] [Loss difference: -0.001, iterations with loss: 0]\n",
      "339 [D loss: 1.352820, acc.: 49.90%] [G loss: 0.102863] [Loss difference: -0.001, iterations with loss: 0]\n",
      "340 [D loss: 1.323440, acc.: 50.00%] [G loss: 0.096984] [Loss difference: -0.006, iterations with loss: 0]\n",
      "341 [D loss: 1.380950, acc.: 50.00%] [G loss: 0.100014] [Loss difference: 0.003, iterations with loss: 0]\n",
      "342 [D loss: 1.326930, acc.: 50.00%] [G loss: 0.101709] [Loss difference: 0.002, iterations with loss: 1]\n",
      "343 [D loss: 1.344948, acc.: 50.00%] [G loss: 0.092937] [Loss difference: -0.009, iterations with loss: 2]\n",
      "344 [D loss: 1.372573, acc.: 50.00%] [G loss: 0.103545] [Loss difference: 0.011, iterations with loss: 0]\n",
      "345 [D loss: 1.358423, acc.: 49.90%] [G loss: 0.107666] [Loss difference: 0.004, iterations with loss: 1]\n",
      "346 [D loss: 1.384589, acc.: 50.00%] [G loss: 0.096690] [Loss difference: -0.011, iterations with loss: 2]\n",
      "347 [D loss: 1.357213, acc.: 50.00%] [G loss: 0.102370] [Loss difference: 0.006, iterations with loss: 0]\n",
      "348 [D loss: 1.334852, acc.: 50.00%] [G loss: 0.100471] [Loss difference: -0.002, iterations with loss: 1]\n",
      "349 [D loss: 1.322101, acc.: 50.00%] [G loss: 0.104957] [Loss difference: 0.004, iterations with loss: 0]\n",
      "350 [D loss: 1.365288, acc.: 50.00%] [G loss: 0.098616] [Loss difference: -0.006, iterations with loss: 1]\n",
      "351 [D loss: 1.365538, acc.: 50.00%] [G loss: 0.097815] [Loss difference: -0.001, iterations with loss: 0]\n",
      "352 [D loss: 1.373553, acc.: 50.00%] [G loss: 0.105649] [Loss difference: 0.008, iterations with loss: 0]\n",
      "353 [D loss: 1.370094, acc.: 50.00%] [G loss: 0.100947] [Loss difference: -0.005, iterations with loss: 1]\n",
      "354 [D loss: 1.372908, acc.: 50.00%] [G loss: 0.098358] [Loss difference: -0.003, iterations with loss: 0]\n",
      "355 [D loss: 1.411672, acc.: 49.90%] [G loss: 0.094371] [Loss difference: -0.004, iterations with loss: 0]\n",
      "356 [D loss: 1.376837, acc.: 50.00%] [G loss: 0.099154] [Loss difference: 0.005, iterations with loss: 0]\n",
      "357 [D loss: 1.422484, acc.: 49.90%] [G loss: 0.095549] [Loss difference: -0.004, iterations with loss: 1]\n",
      "358 [D loss: 1.360390, acc.: 50.00%] [G loss: 0.091311] [Loss difference: -0.004, iterations with loss: 0]\n",
      "359 [D loss: 1.365866, acc.: 50.00%] [G loss: 0.102289] [Loss difference: 0.011, iterations with loss: 0]\n",
      "360 [D loss: 1.383990, acc.: 50.00%] [G loss: 0.103930] [Loss difference: 0.002, iterations with loss: 1]\n",
      "361 [D loss: 1.381015, acc.: 50.00%] [G loss: 0.097513] [Loss difference: -0.006, iterations with loss: 2]\n",
      "362 [D loss: 1.382229, acc.: 50.00%] [G loss: 0.094618] [Loss difference: -0.003, iterations with loss: 0]\n",
      "363 [D loss: 1.367859, acc.: 50.00%] [G loss: 0.093806] [Loss difference: -0.001, iterations with loss: 0]\n",
      "364 [D loss: 1.361160, acc.: 49.90%] [G loss: 0.097200] [Loss difference: 0.003, iterations with loss: 0]\n",
      "365 [D loss: 1.357576, acc.: 50.00%] [G loss: 0.103808] [Loss difference: 0.007, iterations with loss: 1]\n",
      "366 [D loss: 1.376294, acc.: 50.00%] [G loss: 0.090807] [Loss difference: -0.013, iterations with loss: 2]\n",
      "367 [D loss: 1.379492, acc.: 50.00%] [G loss: 0.100839] [Loss difference: 0.010, iterations with loss: 0]\n",
      "368 [D loss: 1.366372, acc.: 50.00%] [G loss: 0.090127] [Loss difference: -0.011, iterations with loss: 1]\n",
      "369 [D loss: 1.397961, acc.: 50.00%] [G loss: 0.092771] [Loss difference: 0.003, iterations with loss: 0]\n",
      "370 [D loss: 1.387751, acc.: 50.00%] [G loss: 0.093502] [Loss difference: 0.001, iterations with loss: 1]\n",
      "371 [D loss: 1.369667, acc.: 49.90%] [G loss: 0.091909] [Loss difference: -0.002, iterations with loss: 2]\n",
      "372 [D loss: 1.374255, acc.: 50.00%] [G loss: 0.096425] [Loss difference: 0.005, iterations with loss: 0]\n",
      "373 [D loss: 1.388891, acc.: 50.00%] [G loss: 0.093545] [Loss difference: -0.003, iterations with loss: 1]\n",
      "374 [D loss: 1.407751, acc.: 50.00%] [G loss: 0.095015] [Loss difference: 0.001, iterations with loss: 0]\n",
      "375 [D loss: 1.388460, acc.: 50.00%] [G loss: 0.097154] [Loss difference: 0.002, iterations with loss: 1]\n",
      "376 [D loss: 1.389521, acc.: 50.00%] [G loss: 0.095580] [Loss difference: -0.002, iterations with loss: 2]\n",
      "377 [D loss: 1.410783, acc.: 50.00%] [G loss: 0.095524] [Loss difference: -0.000, iterations with loss: 0]\n",
      "378 [D loss: 1.384974, acc.: 50.00%] [G loss: 0.100915] [Loss difference: 0.005, iterations with loss: 0]\n",
      "379 [D loss: 1.386243, acc.: 50.00%] [G loss: 0.095585] [Loss difference: -0.005, iterations with loss: 1]\n",
      "380 [D loss: 1.388644, acc.: 50.00%] [G loss: 0.088788] [Loss difference: -0.007, iterations with loss: 0]\n",
      "381 [D loss: 1.361753, acc.: 50.00%] [G loss: 0.091165] [Loss difference: 0.002, iterations with loss: 0]\n",
      "382 [D loss: 1.387338, acc.: 50.00%] [G loss: 0.090168] [Loss difference: -0.001, iterations with loss: 1]\n",
      "383 [D loss: 1.393663, acc.: 50.00%] [G loss: 0.098328] [Loss difference: 0.008, iterations with loss: 0]\n",
      "384 [D loss: 1.372260, acc.: 50.00%] [G loss: 0.090886] [Loss difference: -0.007, iterations with loss: 1]\n",
      "385 [D loss: 1.391613, acc.: 50.00%] [G loss: 0.092698] [Loss difference: 0.002, iterations with loss: 0]\n",
      "386 [D loss: 1.386563, acc.: 50.00%] [G loss: 0.087481] [Loss difference: -0.005, iterations with loss: 1]\n",
      "387 [D loss: 1.407572, acc.: 49.90%] [G loss: 0.091982] [Loss difference: 0.005, iterations with loss: 0]\n",
      "388 [D loss: 1.388294, acc.: 50.00%] [G loss: 0.092370] [Loss difference: 0.000, iterations with loss: 1]\n",
      "389 [D loss: 1.406878, acc.: 49.80%] [G loss: 0.096686] [Loss difference: 0.004, iterations with loss: 2]\n",
      "390 [D loss: 1.374434, acc.: 50.00%] [G loss: 0.083031] [Loss difference: -0.014, iterations with loss: 3]\n",
      "391 [D loss: 1.398840, acc.: 50.00%] [G loss: 0.088095] [Loss difference: 0.005, iterations with loss: 0]\n",
      "392 [D loss: 1.359406, acc.: 50.00%] [G loss: 0.093726] [Loss difference: 0.006, iterations with loss: 1]\n",
      "393 [D loss: 1.400358, acc.: 50.00%] [G loss: 0.089794] [Loss difference: -0.004, iterations with loss: 2]\n",
      "394 [D loss: 1.408929, acc.: 50.00%] [G loss: 0.089136] [Loss difference: -0.001, iterations with loss: 0]\n",
      "395 [D loss: 1.382397, acc.: 50.00%] [G loss: 0.084126] [Loss difference: -0.005, iterations with loss: 0]\n",
      "396 [D loss: 1.394114, acc.: 50.00%] [G loss: 0.086275] [Loss difference: 0.002, iterations with loss: 0]\n",
      "397 [D loss: 1.372814, acc.: 50.00%] [G loss: 0.088784] [Loss difference: 0.003, iterations with loss: 1]\n",
      "398 [D loss: 1.390407, acc.: 50.00%] [G loss: 0.091466] [Loss difference: 0.003, iterations with loss: 2]\n",
      "399 [D loss: 1.379321, acc.: 50.00%] [G loss: 0.085537] [Loss difference: -0.006, iterations with loss: 3]\n",
      "400 [D loss: 1.396947, acc.: 50.00%] [G loss: 0.086255] [Loss difference: 0.001, iterations with loss: 0]\n",
      "401 [D loss: 1.395308, acc.: 50.00%] [G loss: 0.092253] [Loss difference: 0.006, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 [D loss: 1.376618, acc.: 50.00%] [G loss: 0.091077] [Loss difference: -0.001, iterations with loss: 2]\n",
      "403 [D loss: 1.403633, acc.: 50.00%] [G loss: 0.083562] [Loss difference: -0.008, iterations with loss: 0]\n",
      "404 [D loss: 1.377940, acc.: 50.00%] [G loss: 0.085976] [Loss difference: 0.002, iterations with loss: 0]\n",
      "405 [D loss: 1.382494, acc.: 50.00%] [G loss: 0.089300] [Loss difference: 0.003, iterations with loss: 1]\n",
      "406 [D loss: 1.413019, acc.: 50.00%] [G loss: 0.082389] [Loss difference: -0.007, iterations with loss: 2]\n",
      "407 [D loss: 1.411348, acc.: 49.90%] [G loss: 0.090083] [Loss difference: 0.008, iterations with loss: 0]\n",
      "408 [D loss: 1.370846, acc.: 50.00%] [G loss: 0.091533] [Loss difference: 0.001, iterations with loss: 1]\n",
      "409 [D loss: 1.388519, acc.: 50.00%] [G loss: 0.091976] [Loss difference: 0.000, iterations with loss: 2]\n",
      "410 [D loss: 1.378095, acc.: 50.00%] [G loss: 0.083755] [Loss difference: -0.008, iterations with loss: 3]\n",
      "411 [D loss: 1.390044, acc.: 50.00%] [G loss: 0.086785] [Loss difference: 0.003, iterations with loss: 0]\n",
      "412 [D loss: 1.395082, acc.: 50.00%] [G loss: 0.083940] [Loss difference: -0.003, iterations with loss: 1]\n",
      "413 [D loss: 1.383795, acc.: 49.90%] [G loss: 0.083101] [Loss difference: -0.001, iterations with loss: 0]\n",
      "414 [D loss: 1.384735, acc.: 50.00%] [G loss: 0.085478] [Loss difference: 0.002, iterations with loss: 0]\n",
      "415 [D loss: 1.369408, acc.: 50.00%] [G loss: 0.084498] [Loss difference: -0.001, iterations with loss: 1]\n",
      "416 [D loss: 1.395820, acc.: 50.00%] [G loss: 0.084044] [Loss difference: -0.000, iterations with loss: 0]\n",
      "417 [D loss: 1.385220, acc.: 50.00%] [G loss: 0.085126] [Loss difference: 0.001, iterations with loss: 0]\n",
      "418 [D loss: 1.376169, acc.: 49.90%] [G loss: 0.087004] [Loss difference: 0.002, iterations with loss: 1]\n",
      "419 [D loss: 1.383923, acc.: 50.00%] [G loss: 0.085482] [Loss difference: -0.002, iterations with loss: 2]\n",
      "420 [D loss: 1.384701, acc.: 50.00%] [G loss: 0.086795] [Loss difference: 0.001, iterations with loss: 0]\n",
      "421 [D loss: 1.366629, acc.: 50.00%] [G loss: 0.088447] [Loss difference: 0.002, iterations with loss: 1]\n",
      "422 [D loss: 1.375402, acc.: 50.00%] [G loss: 0.088411] [Loss difference: -0.000, iterations with loss: 2]\n",
      "423 [D loss: 1.385668, acc.: 49.90%] [G loss: 0.086648] [Loss difference: -0.002, iterations with loss: 0]\n",
      "424 [D loss: 1.407834, acc.: 50.00%] [G loss: 0.080226] [Loss difference: -0.006, iterations with loss: 0]\n",
      "425 [D loss: 1.396577, acc.: 50.00%] [G loss: 0.091490] [Loss difference: 0.011, iterations with loss: 0]\n",
      "426 [D loss: 1.388663, acc.: 50.00%] [G loss: 0.091763] [Loss difference: 0.000, iterations with loss: 1]\n",
      "427 [D loss: 1.397586, acc.: 50.00%] [G loss: 0.091340] [Loss difference: -0.000, iterations with loss: 2]\n",
      "428 [D loss: 1.405988, acc.: 50.00%] [G loss: 0.090754] [Loss difference: -0.001, iterations with loss: 0]\n",
      "429 [D loss: 1.383752, acc.: 50.00%] [G loss: 0.089185] [Loss difference: -0.002, iterations with loss: 0]\n",
      "430 [D loss: 1.378568, acc.: 50.00%] [G loss: 0.080097] [Loss difference: -0.009, iterations with loss: 0]\n",
      "431 [D loss: 1.388530, acc.: 49.90%] [G loss: 0.089390] [Loss difference: 0.009, iterations with loss: 0]\n",
      "432 [D loss: 1.399760, acc.: 50.00%] [G loss: 0.090888] [Loss difference: 0.001, iterations with loss: 1]\n",
      "433 [D loss: 1.388468, acc.: 50.00%] [G loss: 0.080412] [Loss difference: -0.010, iterations with loss: 2]\n",
      "434 [D loss: 1.383237, acc.: 50.00%] [G loss: 0.086816] [Loss difference: 0.006, iterations with loss: 0]\n",
      "435 [D loss: 1.423401, acc.: 50.00%] [G loss: 0.084623] [Loss difference: -0.002, iterations with loss: 1]\n",
      "436 [D loss: 1.387103, acc.: 50.00%] [G loss: 0.081077] [Loss difference: -0.004, iterations with loss: 0]\n",
      "437 [D loss: 1.380754, acc.: 50.00%] [G loss: 0.094055] [Loss difference: 0.013, iterations with loss: 0]\n",
      "438 [D loss: 1.400108, acc.: 50.00%] [G loss: 0.085059] [Loss difference: -0.009, iterations with loss: 1]\n",
      "439 [D loss: 1.387938, acc.: 50.00%] [G loss: 0.086145] [Loss difference: 0.001, iterations with loss: 0]\n",
      "440 [D loss: 1.401137, acc.: 50.00%] [G loss: 0.084103] [Loss difference: -0.002, iterations with loss: 1]\n",
      "441 [D loss: 1.393095, acc.: 50.00%] [G loss: 0.080403] [Loss difference: -0.004, iterations with loss: 0]\n",
      "442 [D loss: 1.398604, acc.: 50.00%] [G loss: 0.087398] [Loss difference: 0.007, iterations with loss: 0]\n",
      "443 [D loss: 1.408600, acc.: 50.00%] [G loss: 0.084607] [Loss difference: -0.003, iterations with loss: 1]\n",
      "444 [D loss: 1.420948, acc.: 50.00%] [G loss: 0.077272] [Loss difference: -0.007, iterations with loss: 0]\n",
      "445 [D loss: 1.423248, acc.: 50.00%] [G loss: 0.082620] [Loss difference: 0.005, iterations with loss: 0]\n",
      "446 [D loss: 1.395645, acc.: 50.00%] [G loss: 0.089829] [Loss difference: 0.007, iterations with loss: 1]\n",
      "447 [D loss: 1.388970, acc.: 50.00%] [G loss: 0.085096] [Loss difference: -0.005, iterations with loss: 2]\n",
      "448 [D loss: 1.412612, acc.: 50.00%] [G loss: 0.084139] [Loss difference: -0.001, iterations with loss: 0]\n",
      "449 [D loss: 1.393028, acc.: 50.00%] [G loss: 0.091146] [Loss difference: 0.007, iterations with loss: 0]\n",
      "450 [D loss: 1.376262, acc.: 50.00%] [G loss: 0.081015] [Loss difference: -0.010, iterations with loss: 1]\n",
      "451 [D loss: 1.404787, acc.: 50.00%] [G loss: 0.081541] [Loss difference: 0.001, iterations with loss: 0]\n",
      "452 [D loss: 1.416659, acc.: 49.90%] [G loss: 0.078744] [Loss difference: -0.003, iterations with loss: 1]\n",
      "453 [D loss: 1.415256, acc.: 49.90%] [G loss: 0.084620] [Loss difference: 0.006, iterations with loss: 0]\n",
      "454 [D loss: 1.417911, acc.: 50.00%] [G loss: 0.084751] [Loss difference: 0.000, iterations with loss: 1]\n",
      "455 [D loss: 1.406144, acc.: 50.00%] [G loss: 0.079143] [Loss difference: -0.006, iterations with loss: 2]\n",
      "456 [D loss: 1.383989, acc.: 50.00%] [G loss: 0.083434] [Loss difference: 0.004, iterations with loss: 0]\n",
      "457 [D loss: 1.390217, acc.: 50.00%] [G loss: 0.086606] [Loss difference: 0.003, iterations with loss: 1]\n",
      "458 [D loss: 1.399900, acc.: 50.00%] [G loss: 0.090536] [Loss difference: 0.004, iterations with loss: 2]\n",
      "459 [D loss: 1.417059, acc.: 50.00%] [G loss: 0.083173] [Loss difference: -0.007, iterations with loss: 3]\n",
      "460 [D loss: 1.399352, acc.: 49.90%] [G loss: 0.087132] [Loss difference: 0.004, iterations with loss: 0]\n",
      "461 [D loss: 1.415487, acc.: 50.00%] [G loss: 0.085670] [Loss difference: -0.001, iterations with loss: 1]\n",
      "462 [D loss: 1.416789, acc.: 50.00%] [G loss: 0.085926] [Loss difference: 0.000, iterations with loss: 0]\n",
      "463 [D loss: 1.386342, acc.: 50.00%] [G loss: 0.083782] [Loss difference: -0.002, iterations with loss: 1]\n",
      "464 [D loss: 1.404003, acc.: 50.00%] [G loss: 0.082607] [Loss difference: -0.001, iterations with loss: 0]\n",
      "465 [D loss: 1.410116, acc.: 50.00%] [G loss: 0.078876] [Loss difference: -0.004, iterations with loss: 0]\n",
      "466 [D loss: 1.413744, acc.: 50.00%] [G loss: 0.089320] [Loss difference: 0.010, iterations with loss: 0]\n",
      "467 [D loss: 1.391283, acc.: 50.00%] [G loss: 0.080261] [Loss difference: -0.009, iterations with loss: 1]\n",
      "468 [D loss: 1.405845, acc.: 50.00%] [G loss: 0.086638] [Loss difference: 0.006, iterations with loss: 0]\n",
      "469 [D loss: 1.392832, acc.: 50.00%] [G loss: 0.087993] [Loss difference: 0.001, iterations with loss: 1]\n",
      "470 [D loss: 1.382465, acc.: 49.90%] [G loss: 0.082886] [Loss difference: -0.005, iterations with loss: 2]\n",
      "471 [D loss: 1.416633, acc.: 50.00%] [G loss: 0.080567] [Loss difference: -0.002, iterations with loss: 0]\n",
      "472 [D loss: 1.438772, acc.: 49.71%] [G loss: 0.078622] [Loss difference: -0.002, iterations with loss: 0]\n",
      "473 [D loss: 1.406480, acc.: 50.00%] [G loss: 0.081201] [Loss difference: 0.003, iterations with loss: 0]\n",
      "474 [D loss: 1.397679, acc.: 50.00%] [G loss: 0.088399] [Loss difference: 0.007, iterations with loss: 1]\n",
      "475 [D loss: 1.382269, acc.: 49.90%] [G loss: 0.091319] [Loss difference: 0.003, iterations with loss: 2]\n",
      "476 [D loss: 1.376195, acc.: 50.00%] [G loss: 0.090417] [Loss difference: -0.001, iterations with loss: 3]\n",
      "477 [D loss: 1.399301, acc.: 49.90%] [G loss: 0.085744] [Loss difference: -0.005, iterations with loss: 0]\n",
      "478 [D loss: 1.414828, acc.: 50.00%] [G loss: 0.082790] [Loss difference: -0.003, iterations with loss: 0]\n",
      "479 [D loss: 1.408974, acc.: 49.80%] [G loss: 0.079265] [Loss difference: -0.004, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 [D loss: 1.393924, acc.: 49.90%] [G loss: 0.084226] [Loss difference: 0.005, iterations with loss: 0]\n",
      "481 [D loss: 1.398120, acc.: 50.00%] [G loss: 0.086317] [Loss difference: 0.002, iterations with loss: 1]\n",
      "482 [D loss: 1.386505, acc.: 50.00%] [G loss: 0.082355] [Loss difference: -0.004, iterations with loss: 2]\n",
      "483 [D loss: 1.409482, acc.: 49.90%] [G loss: 0.088842] [Loss difference: 0.006, iterations with loss: 0]\n",
      "484 [D loss: 1.401953, acc.: 50.00%] [G loss: 0.087706] [Loss difference: -0.001, iterations with loss: 1]\n",
      "485 [D loss: 1.388712, acc.: 49.90%] [G loss: 0.087199] [Loss difference: -0.001, iterations with loss: 0]\n",
      "486 [D loss: 1.423335, acc.: 50.00%] [G loss: 0.085505] [Loss difference: -0.002, iterations with loss: 0]\n",
      "487 [D loss: 1.388608, acc.: 50.00%] [G loss: 0.082339] [Loss difference: -0.003, iterations with loss: 0]\n",
      "488 [D loss: 1.379850, acc.: 50.00%] [G loss: 0.085041] [Loss difference: 0.003, iterations with loss: 0]\n",
      "489 [D loss: 1.379704, acc.: 50.00%] [G loss: 0.082528] [Loss difference: -0.003, iterations with loss: 1]\n",
      "490 [D loss: 1.382171, acc.: 49.90%] [G loss: 0.086537] [Loss difference: 0.004, iterations with loss: 0]\n",
      "491 [D loss: 1.402378, acc.: 50.00%] [G loss: 0.085643] [Loss difference: -0.001, iterations with loss: 1]\n",
      "492 [D loss: 1.397304, acc.: 50.00%] [G loss: 0.088286] [Loss difference: 0.003, iterations with loss: 0]\n",
      "493 [D loss: 1.408852, acc.: 49.90%] [G loss: 0.091513] [Loss difference: 0.003, iterations with loss: 1]\n",
      "494 [D loss: 1.395955, acc.: 50.00%] [G loss: 0.081102] [Loss difference: -0.010, iterations with loss: 2]\n",
      "495 [D loss: 1.378886, acc.: 50.00%] [G loss: 0.086089] [Loss difference: 0.005, iterations with loss: 0]\n",
      "496 [D loss: 1.402048, acc.: 49.90%] [G loss: 0.085215] [Loss difference: -0.001, iterations with loss: 1]\n",
      "497 [D loss: 1.411506, acc.: 50.00%] [G loss: 0.087958] [Loss difference: 0.003, iterations with loss: 0]\n",
      "498 [D loss: 1.409796, acc.: 50.00%] [G loss: 0.088315] [Loss difference: 0.000, iterations with loss: 1]\n",
      "499 [D loss: 1.387813, acc.: 49.90%] [G loss: 0.087626] [Loss difference: -0.001, iterations with loss: 2]\n",
      "500 [D loss: 1.378920, acc.: 50.00%] [G loss: 0.082819] [Loss difference: -0.005, iterations with loss: 0]\n",
      "501 [D loss: 1.404816, acc.: 49.90%] [G loss: 0.083124] [Loss difference: 0.000, iterations with loss: 0]\n",
      "502 [D loss: 1.384338, acc.: 49.90%] [G loss: 0.082349] [Loss difference: -0.001, iterations with loss: 1]\n",
      "503 [D loss: 1.392561, acc.: 50.00%] [G loss: 0.087770] [Loss difference: 0.005, iterations with loss: 0]\n",
      "504 [D loss: 1.379642, acc.: 49.90%] [G loss: 0.090637] [Loss difference: 0.003, iterations with loss: 1]\n",
      "505 [D loss: 1.405467, acc.: 50.00%] [G loss: 0.084373] [Loss difference: -0.006, iterations with loss: 2]\n",
      "506 [D loss: 1.387214, acc.: 50.00%] [G loss: 0.086502] [Loss difference: 0.002, iterations with loss: 0]\n",
      "507 [D loss: 1.393350, acc.: 50.00%] [G loss: 0.079991] [Loss difference: -0.007, iterations with loss: 1]\n",
      "508 [D loss: 1.397635, acc.: 49.90%] [G loss: 0.085548] [Loss difference: 0.006, iterations with loss: 0]\n",
      "509 [D loss: 1.368737, acc.: 50.00%] [G loss: 0.084685] [Loss difference: -0.001, iterations with loss: 1]\n",
      "510 [D loss: 1.391805, acc.: 49.80%] [G loss: 0.083527] [Loss difference: -0.001, iterations with loss: 0]\n",
      "511 [D loss: 1.380287, acc.: 50.00%] [G loss: 0.085807] [Loss difference: 0.002, iterations with loss: 0]\n",
      "512 [D loss: 1.390341, acc.: 49.80%] [G loss: 0.084587] [Loss difference: -0.001, iterations with loss: 1]\n",
      "513 [D loss: 1.381301, acc.: 49.90%] [G loss: 0.085117] [Loss difference: 0.001, iterations with loss: 0]\n",
      "514 [D loss: 1.391880, acc.: 50.00%] [G loss: 0.086109] [Loss difference: 0.001, iterations with loss: 1]\n",
      "515 [D loss: 1.387594, acc.: 49.90%] [G loss: 0.087124] [Loss difference: 0.001, iterations with loss: 2]\n",
      "516 [D loss: 1.377701, acc.: 50.00%] [G loss: 0.083515] [Loss difference: -0.004, iterations with loss: 3]\n",
      "517 [D loss: 1.392267, acc.: 50.00%] [G loss: 0.084590] [Loss difference: 0.001, iterations with loss: 0]\n",
      "518 [D loss: 1.387593, acc.: 50.00%] [G loss: 0.088567] [Loss difference: 0.004, iterations with loss: 1]\n",
      "519 [D loss: 1.373814, acc.: 49.80%] [G loss: 0.079624] [Loss difference: -0.009, iterations with loss: 2]\n",
      "520 [D loss: 1.389255, acc.: 50.00%] [G loss: 0.082940] [Loss difference: 0.003, iterations with loss: 0]\n",
      "521 [D loss: 1.386059, acc.: 49.90%] [G loss: 0.086108] [Loss difference: 0.003, iterations with loss: 1]\n",
      "522 [D loss: 1.386497, acc.: 50.00%] [G loss: 0.082323] [Loss difference: -0.004, iterations with loss: 2]\n",
      "523 [D loss: 1.386272, acc.: 50.00%] [G loss: 0.082857] [Loss difference: 0.001, iterations with loss: 0]\n",
      "524 [D loss: 1.403247, acc.: 50.00%] [G loss: 0.087432] [Loss difference: 0.005, iterations with loss: 1]\n",
      "525 [D loss: 1.398067, acc.: 50.00%] [G loss: 0.083885] [Loss difference: -0.004, iterations with loss: 2]\n",
      "526 [D loss: 1.380763, acc.: 49.90%] [G loss: 0.083011] [Loss difference: -0.001, iterations with loss: 0]\n",
      "527 [D loss: 1.409758, acc.: 50.00%] [G loss: 0.089854] [Loss difference: 0.007, iterations with loss: 0]\n",
      "528 [D loss: 1.371779, acc.: 50.00%] [G loss: 0.093133] [Loss difference: 0.003, iterations with loss: 1]\n",
      "529 [D loss: 1.395609, acc.: 49.90%] [G loss: 0.082078] [Loss difference: -0.011, iterations with loss: 2]\n",
      "530 [D loss: 1.375437, acc.: 50.00%] [G loss: 0.086728] [Loss difference: 0.005, iterations with loss: 0]\n",
      "531 [D loss: 1.389297, acc.: 50.00%] [G loss: 0.087473] [Loss difference: 0.001, iterations with loss: 1]\n",
      "532 [D loss: 1.378276, acc.: 50.00%] [G loss: 0.084175] [Loss difference: -0.003, iterations with loss: 2]\n",
      "533 [D loss: 1.408639, acc.: 50.00%] [G loss: 0.082005] [Loss difference: -0.002, iterations with loss: 0]\n",
      "534 [D loss: 1.376657, acc.: 49.90%] [G loss: 0.086744] [Loss difference: 0.005, iterations with loss: 0]\n",
      "535 [D loss: 1.378263, acc.: 50.00%] [G loss: 0.084784] [Loss difference: -0.002, iterations with loss: 1]\n",
      "536 [D loss: 1.385694, acc.: 49.90%] [G loss: 0.098600] [Loss difference: 0.014, iterations with loss: 0]\n",
      "537 [D loss: 1.395430, acc.: 49.71%] [G loss: 0.081297] [Loss difference: -0.017, iterations with loss: 1]\n",
      "538 [D loss: 1.403485, acc.: 49.90%] [G loss: 0.083184] [Loss difference: 0.002, iterations with loss: 0]\n",
      "539 [D loss: 1.393608, acc.: 50.00%] [G loss: 0.090183] [Loss difference: 0.007, iterations with loss: 1]\n",
      "540 [D loss: 1.364194, acc.: 49.80%] [G loss: 0.083655] [Loss difference: -0.007, iterations with loss: 2]\n",
      "541 [D loss: 1.374762, acc.: 50.00%] [G loss: 0.085435] [Loss difference: 0.002, iterations with loss: 0]\n",
      "542 [D loss: 1.393506, acc.: 49.80%] [G loss: 0.087770] [Loss difference: 0.002, iterations with loss: 1]\n",
      "543 [D loss: 1.372286, acc.: 49.90%] [G loss: 0.085297] [Loss difference: -0.002, iterations with loss: 2]\n",
      "544 [D loss: 1.392317, acc.: 49.90%] [G loss: 0.089931] [Loss difference: 0.005, iterations with loss: 0]\n",
      "545 [D loss: 1.400802, acc.: 49.61%] [G loss: 0.089042] [Loss difference: -0.001, iterations with loss: 1]\n",
      "546 [D loss: 1.409871, acc.: 49.90%] [G loss: 0.083704] [Loss difference: -0.005, iterations with loss: 0]\n",
      "547 [D loss: 1.380611, acc.: 50.00%] [G loss: 0.077471] [Loss difference: -0.006, iterations with loss: 0]\n",
      "548 [D loss: 1.386544, acc.: 49.90%] [G loss: 0.084257] [Loss difference: 0.007, iterations with loss: 0]\n",
      "549 [D loss: 1.379022, acc.: 49.80%] [G loss: 0.082079] [Loss difference: -0.002, iterations with loss: 1]\n",
      "550 [D loss: 1.414696, acc.: 50.00%] [G loss: 0.085803] [Loss difference: 0.004, iterations with loss: 0]\n",
      "551 [D loss: 1.366287, acc.: 49.90%] [G loss: 0.082710] [Loss difference: -0.003, iterations with loss: 1]\n",
      "552 [D loss: 1.369458, acc.: 50.00%] [G loss: 0.086641] [Loss difference: 0.004, iterations with loss: 0]\n",
      "553 [D loss: 1.384699, acc.: 50.00%] [G loss: 0.088393] [Loss difference: 0.002, iterations with loss: 1]\n",
      "554 [D loss: 1.382922, acc.: 50.00%] [G loss: 0.088840] [Loss difference: 0.000, iterations with loss: 2]\n",
      "555 [D loss: 1.386550, acc.: 50.00%] [G loss: 0.087064] [Loss difference: -0.002, iterations with loss: 3]\n",
      "556 [D loss: 1.366243, acc.: 49.80%] [G loss: 0.081691] [Loss difference: -0.005, iterations with loss: 0]\n",
      "557 [D loss: 1.378841, acc.: 50.00%] [G loss: 0.083979] [Loss difference: 0.002, iterations with loss: 0]\n",
      "558 [D loss: 1.373897, acc.: 49.80%] [G loss: 0.087931] [Loss difference: 0.004, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 [D loss: 1.391383, acc.: 50.00%] [G loss: 0.084346] [Loss difference: -0.004, iterations with loss: 2]\n",
      "560 [D loss: 1.407099, acc.: 49.90%] [G loss: 0.086244] [Loss difference: 0.002, iterations with loss: 0]\n",
      "561 [D loss: 1.381331, acc.: 50.00%] [G loss: 0.077321] [Loss difference: -0.009, iterations with loss: 1]\n",
      "562 [D loss: 1.379955, acc.: 50.00%] [G loss: 0.085365] [Loss difference: 0.008, iterations with loss: 0]\n",
      "563 [D loss: 1.411599, acc.: 49.90%] [G loss: 0.088466] [Loss difference: 0.003, iterations with loss: 1]\n",
      "564 [D loss: 1.372339, acc.: 50.00%] [G loss: 0.082155] [Loss difference: -0.006, iterations with loss: 2]\n",
      "565 [D loss: 1.376907, acc.: 49.90%] [G loss: 0.089281] [Loss difference: 0.007, iterations with loss: 0]\n",
      "566 [D loss: 1.400226, acc.: 50.00%] [G loss: 0.089889] [Loss difference: 0.001, iterations with loss: 1]\n",
      "567 [D loss: 1.397729, acc.: 49.80%] [G loss: 0.085107] [Loss difference: -0.005, iterations with loss: 2]\n",
      "568 [D loss: 1.393595, acc.: 49.90%] [G loss: 0.087511] [Loss difference: 0.002, iterations with loss: 0]\n",
      "569 [D loss: 1.353447, acc.: 50.00%] [G loss: 0.085557] [Loss difference: -0.002, iterations with loss: 1]\n",
      "570 [D loss: 1.371135, acc.: 49.90%] [G loss: 0.086412] [Loss difference: 0.001, iterations with loss: 0]\n",
      "571 [D loss: 1.400474, acc.: 49.90%] [G loss: 0.088030] [Loss difference: 0.002, iterations with loss: 1]\n",
      "572 [D loss: 1.366890, acc.: 50.00%] [G loss: 0.085742] [Loss difference: -0.002, iterations with loss: 2]\n",
      "573 [D loss: 1.390981, acc.: 49.90%] [G loss: 0.083693] [Loss difference: -0.002, iterations with loss: 0]\n",
      "574 [D loss: 1.386130, acc.: 49.90%] [G loss: 0.084295] [Loss difference: 0.001, iterations with loss: 0]\n",
      "575 [D loss: 1.397017, acc.: 50.00%] [G loss: 0.085626] [Loss difference: 0.001, iterations with loss: 1]\n",
      "576 [D loss: 1.397332, acc.: 49.80%] [G loss: 0.083528] [Loss difference: -0.002, iterations with loss: 2]\n",
      "577 [D loss: 1.382512, acc.: 49.90%] [G loss: 0.090089] [Loss difference: 0.007, iterations with loss: 0]\n",
      "578 [D loss: 1.403978, acc.: 49.71%] [G loss: 0.085724] [Loss difference: -0.004, iterations with loss: 1]\n",
      "579 [D loss: 1.381373, acc.: 49.90%] [G loss: 0.083235] [Loss difference: -0.002, iterations with loss: 0]\n",
      "580 [D loss: 1.380705, acc.: 49.80%] [G loss: 0.083773] [Loss difference: 0.001, iterations with loss: 0]\n",
      "581 [D loss: 1.372212, acc.: 50.00%] [G loss: 0.084103] [Loss difference: 0.000, iterations with loss: 1]\n",
      "582 [D loss: 1.380827, acc.: 50.00%] [G loss: 0.084555] [Loss difference: 0.000, iterations with loss: 2]\n",
      "583 [D loss: 1.410042, acc.: 49.90%] [G loss: 0.087529] [Loss difference: 0.003, iterations with loss: 3]\n",
      "584 [D loss: 1.395272, acc.: 50.00%] [G loss: 0.085123] [Loss difference: -0.002, iterations with loss: 4]\n",
      "585 [D loss: 1.408739, acc.: 50.00%] [G loss: 0.086818] [Loss difference: 0.002, iterations with loss: 0]\n",
      "586 [D loss: 1.380068, acc.: 50.00%] [G loss: 0.087256] [Loss difference: 0.000, iterations with loss: 1]\n",
      "587 [D loss: 1.385651, acc.: 50.00%] [G loss: 0.088057] [Loss difference: 0.001, iterations with loss: 2]\n",
      "588 [D loss: 1.381186, acc.: 50.00%] [G loss: 0.090219] [Loss difference: 0.002, iterations with loss: 3]\n",
      "589 [D loss: 1.365211, acc.: 50.00%] [G loss: 0.081663] [Loss difference: -0.009, iterations with loss: 4]\n",
      "590 [D loss: 1.378965, acc.: 50.00%] [G loss: 0.082997] [Loss difference: 0.001, iterations with loss: 0]\n",
      "591 [D loss: 1.376421, acc.: 50.00%] [G loss: 0.086311] [Loss difference: 0.003, iterations with loss: 1]\n",
      "592 [D loss: 1.380397, acc.: 49.80%] [G loss: 0.086064] [Loss difference: -0.000, iterations with loss: 2]\n",
      "593 [D loss: 1.377019, acc.: 49.80%] [G loss: 0.087800] [Loss difference: 0.002, iterations with loss: 0]\n",
      "594 [D loss: 1.380977, acc.: 49.90%] [G loss: 0.091835] [Loss difference: 0.004, iterations with loss: 1]\n",
      "595 [D loss: 1.380371, acc.: 50.00%] [G loss: 0.089469] [Loss difference: -0.002, iterations with loss: 2]\n",
      "596 [D loss: 1.368126, acc.: 49.90%] [G loss: 0.086729] [Loss difference: -0.003, iterations with loss: 0]\n",
      "597 [D loss: 1.373957, acc.: 50.00%] [G loss: 0.088715] [Loss difference: 0.002, iterations with loss: 0]\n",
      "598 [D loss: 1.389119, acc.: 50.00%] [G loss: 0.091807] [Loss difference: 0.003, iterations with loss: 1]\n",
      "599 [D loss: 1.378957, acc.: 49.90%] [G loss: 0.082025] [Loss difference: -0.010, iterations with loss: 2]\n",
      "600 [D loss: 1.387830, acc.: 50.00%] [G loss: 0.085619] [Loss difference: 0.004, iterations with loss: 0]\n",
      "601 [D loss: 1.401991, acc.: 49.90%] [G loss: 0.086041] [Loss difference: 0.000, iterations with loss: 1]\n",
      "602 [D loss: 1.378867, acc.: 50.00%] [G loss: 0.085117] [Loss difference: -0.001, iterations with loss: 2]\n",
      "603 [D loss: 1.378355, acc.: 49.80%] [G loss: 0.084883] [Loss difference: -0.000, iterations with loss: 0]\n",
      "604 [D loss: 1.390585, acc.: 50.00%] [G loss: 0.090151] [Loss difference: 0.005, iterations with loss: 0]\n",
      "605 [D loss: 1.385978, acc.: 49.80%] [G loss: 0.085510] [Loss difference: -0.005, iterations with loss: 1]\n",
      "606 [D loss: 1.364389, acc.: 50.00%] [G loss: 0.088997] [Loss difference: 0.003, iterations with loss: 0]\n",
      "607 [D loss: 1.373156, acc.: 50.00%] [G loss: 0.085357] [Loss difference: -0.004, iterations with loss: 1]\n",
      "608 [D loss: 1.367570, acc.: 50.00%] [G loss: 0.085620] [Loss difference: 0.000, iterations with loss: 0]\n",
      "609 [D loss: 1.367018, acc.: 50.00%] [G loss: 0.085012] [Loss difference: -0.001, iterations with loss: 1]\n",
      "610 [D loss: 1.393690, acc.: 49.90%] [G loss: 0.086335] [Loss difference: 0.001, iterations with loss: 0]\n",
      "611 [D loss: 1.375762, acc.: 49.90%] [G loss: 0.082774] [Loss difference: -0.004, iterations with loss: 1]\n",
      "612 [D loss: 1.371722, acc.: 50.00%] [G loss: 0.085975] [Loss difference: 0.003, iterations with loss: 0]\n",
      "613 [D loss: 1.405900, acc.: 49.90%] [G loss: 0.088357] [Loss difference: 0.002, iterations with loss: 1]\n",
      "614 [D loss: 1.375366, acc.: 50.00%] [G loss: 0.082780] [Loss difference: -0.006, iterations with loss: 2]\n",
      "615 [D loss: 1.381176, acc.: 49.90%] [G loss: 0.081196] [Loss difference: -0.002, iterations with loss: 0]\n",
      "616 [D loss: 1.376648, acc.: 49.71%] [G loss: 0.086155] [Loss difference: 0.005, iterations with loss: 0]\n",
      "617 [D loss: 1.371931, acc.: 50.00%] [G loss: 0.087121] [Loss difference: 0.001, iterations with loss: 1]\n",
      "618 [D loss: 1.372455, acc.: 50.00%] [G loss: 0.090901] [Loss difference: 0.004, iterations with loss: 2]\n",
      "619 [D loss: 1.381760, acc.: 49.80%] [G loss: 0.084209] [Loss difference: -0.007, iterations with loss: 3]\n",
      "620 [D loss: 1.388775, acc.: 50.00%] [G loss: 0.084226] [Loss difference: 0.000, iterations with loss: 0]\n",
      "621 [D loss: 1.392715, acc.: 49.61%] [G loss: 0.083875] [Loss difference: -0.000, iterations with loss: 1]\n",
      "622 [D loss: 1.369493, acc.: 50.00%] [G loss: 0.088732] [Loss difference: 0.005, iterations with loss: 0]\n",
      "623 [D loss: 1.381794, acc.: 50.00%] [G loss: 0.081639] [Loss difference: -0.007, iterations with loss: 1]\n",
      "624 [D loss: 1.378048, acc.: 49.90%] [G loss: 0.081983] [Loss difference: 0.000, iterations with loss: 0]\n",
      "625 [D loss: 1.366239, acc.: 49.90%] [G loss: 0.085814] [Loss difference: 0.004, iterations with loss: 1]\n",
      "626 [D loss: 1.378147, acc.: 50.00%] [G loss: 0.090694] [Loss difference: 0.005, iterations with loss: 2]\n",
      "627 [D loss: 1.359557, acc.: 50.00%] [G loss: 0.086548] [Loss difference: -0.004, iterations with loss: 3]\n",
      "628 [D loss: 1.349352, acc.: 50.00%] [G loss: 0.083600] [Loss difference: -0.003, iterations with loss: 0]\n",
      "629 [D loss: 1.364765, acc.: 50.00%] [G loss: 0.086048] [Loss difference: 0.002, iterations with loss: 0]\n",
      "630 [D loss: 1.368736, acc.: 49.90%] [G loss: 0.086219] [Loss difference: 0.000, iterations with loss: 1]\n",
      "631 [D loss: 1.378153, acc.: 50.00%] [G loss: 0.083079] [Loss difference: -0.003, iterations with loss: 2]\n",
      "632 [D loss: 1.378867, acc.: 50.00%] [G loss: 0.084815] [Loss difference: 0.002, iterations with loss: 0]\n",
      "633 [D loss: 1.367234, acc.: 49.80%] [G loss: 0.084099] [Loss difference: -0.001, iterations with loss: 1]\n",
      "634 [D loss: 1.364674, acc.: 50.00%] [G loss: 0.089686] [Loss difference: 0.006, iterations with loss: 0]\n",
      "635 [D loss: 1.364192, acc.: 50.00%] [G loss: 0.084367] [Loss difference: -0.005, iterations with loss: 1]\n",
      "636 [D loss: 1.357430, acc.: 49.90%] [G loss: 0.087502] [Loss difference: 0.003, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637 [D loss: 1.367855, acc.: 50.00%] [G loss: 0.085015] [Loss difference: -0.002, iterations with loss: 1]\n",
      "638 [D loss: 1.369860, acc.: 50.00%] [G loss: 0.088339] [Loss difference: 0.003, iterations with loss: 0]\n",
      "639 [D loss: 1.369112, acc.: 49.80%] [G loss: 0.087919] [Loss difference: -0.000, iterations with loss: 1]\n",
      "640 [D loss: 1.361117, acc.: 50.00%] [G loss: 0.088741] [Loss difference: 0.001, iterations with loss: 0]\n",
      "641 [D loss: 1.362925, acc.: 50.00%] [G loss: 0.088746] [Loss difference: 0.000, iterations with loss: 1]\n",
      "642 [D loss: 1.380888, acc.: 49.90%] [G loss: 0.084709] [Loss difference: -0.004, iterations with loss: 2]\n",
      "643 [D loss: 1.372562, acc.: 50.00%] [G loss: 0.079629] [Loss difference: -0.005, iterations with loss: 0]\n",
      "644 [D loss: 1.359111, acc.: 50.00%] [G loss: 0.089583] [Loss difference: 0.010, iterations with loss: 0]\n",
      "645 [D loss: 1.364713, acc.: 49.90%] [G loss: 0.084228] [Loss difference: -0.005, iterations with loss: 1]\n",
      "646 [D loss: 1.372668, acc.: 50.00%] [G loss: 0.083416] [Loss difference: -0.001, iterations with loss: 0]\n",
      "647 [D loss: 1.347459, acc.: 49.80%] [G loss: 0.085805] [Loss difference: 0.002, iterations with loss: 0]\n",
      "648 [D loss: 1.357696, acc.: 50.00%] [G loss: 0.085706] [Loss difference: -0.000, iterations with loss: 1]\n",
      "649 [D loss: 1.357318, acc.: 50.00%] [G loss: 0.086778] [Loss difference: 0.001, iterations with loss: 0]\n",
      "650 [D loss: 1.356010, acc.: 49.80%] [G loss: 0.090629] [Loss difference: 0.004, iterations with loss: 1]\n",
      "651 [D loss: 1.358920, acc.: 50.00%] [G loss: 0.083860] [Loss difference: -0.007, iterations with loss: 2]\n",
      "652 [D loss: 1.358638, acc.: 50.00%] [G loss: 0.091235] [Loss difference: 0.007, iterations with loss: 0]\n",
      "653 [D loss: 1.365811, acc.: 49.90%] [G loss: 0.087573] [Loss difference: -0.004, iterations with loss: 1]\n",
      "654 [D loss: 1.370655, acc.: 49.90%] [G loss: 0.089605] [Loss difference: 0.002, iterations with loss: 0]\n",
      "655 [D loss: 1.375647, acc.: 50.00%] [G loss: 0.088251] [Loss difference: -0.001, iterations with loss: 1]\n",
      "656 [D loss: 1.365630, acc.: 49.90%] [G loss: 0.080401] [Loss difference: -0.008, iterations with loss: 0]\n",
      "657 [D loss: 1.368173, acc.: 49.90%] [G loss: 0.086093] [Loss difference: 0.006, iterations with loss: 0]\n",
      "658 [D loss: 1.369977, acc.: 50.00%] [G loss: 0.091318] [Loss difference: 0.005, iterations with loss: 1]\n",
      "659 [D loss: 1.357360, acc.: 50.00%] [G loss: 0.085136] [Loss difference: -0.006, iterations with loss: 2]\n",
      "660 [D loss: 1.394467, acc.: 50.00%] [G loss: 0.083615] [Loss difference: -0.002, iterations with loss: 0]\n",
      "661 [D loss: 1.365984, acc.: 49.90%] [G loss: 0.087283] [Loss difference: 0.004, iterations with loss: 0]\n",
      "662 [D loss: 1.366314, acc.: 49.90%] [G loss: 0.089626] [Loss difference: 0.002, iterations with loss: 1]\n",
      "663 [D loss: 1.337248, acc.: 50.00%] [G loss: 0.083624] [Loss difference: -0.006, iterations with loss: 2]\n",
      "664 [D loss: 1.372125, acc.: 49.61%] [G loss: 0.081466] [Loss difference: -0.002, iterations with loss: 0]\n",
      "665 [D loss: 1.392792, acc.: 49.80%] [G loss: 0.080432] [Loss difference: -0.001, iterations with loss: 0]\n",
      "666 [D loss: 1.358653, acc.: 49.90%] [G loss: 0.086608] [Loss difference: 0.006, iterations with loss: 0]\n",
      "667 [D loss: 1.360639, acc.: 49.90%] [G loss: 0.087945] [Loss difference: 0.001, iterations with loss: 1]\n",
      "668 [D loss: 1.375595, acc.: 49.71%] [G loss: 0.088645] [Loss difference: 0.001, iterations with loss: 2]\n",
      "669 [D loss: 1.367774, acc.: 49.90%] [G loss: 0.089599] [Loss difference: 0.001, iterations with loss: 3]\n",
      "670 [D loss: 1.358660, acc.: 49.90%] [G loss: 0.084877] [Loss difference: -0.005, iterations with loss: 4]\n",
      "671 [D loss: 1.371415, acc.: 49.90%] [G loss: 0.088259] [Loss difference: 0.003, iterations with loss: 0]\n",
      "672 [D loss: 1.362730, acc.: 50.00%] [G loss: 0.082906] [Loss difference: -0.005, iterations with loss: 1]\n",
      "673 [D loss: 1.369741, acc.: 49.90%] [G loss: 0.094184] [Loss difference: 0.011, iterations with loss: 0]\n",
      "674 [D loss: 1.368260, acc.: 50.00%] [G loss: 0.088201] [Loss difference: -0.006, iterations with loss: 1]\n",
      "675 [D loss: 1.370519, acc.: 49.90%] [G loss: 0.090424] [Loss difference: 0.002, iterations with loss: 0]\n",
      "676 [D loss: 1.367866, acc.: 50.00%] [G loss: 0.082888] [Loss difference: -0.008, iterations with loss: 1]\n",
      "677 [D loss: 1.342188, acc.: 49.90%] [G loss: 0.083983] [Loss difference: 0.001, iterations with loss: 0]\n",
      "678 [D loss: 1.358019, acc.: 49.90%] [G loss: 0.085112] [Loss difference: 0.001, iterations with loss: 1]\n",
      "679 [D loss: 1.370176, acc.: 49.80%] [G loss: 0.085776] [Loss difference: 0.001, iterations with loss: 2]\n",
      "680 [D loss: 1.364616, acc.: 49.90%] [G loss: 0.089921] [Loss difference: 0.004, iterations with loss: 3]\n",
      "681 [D loss: 1.369522, acc.: 49.80%] [G loss: 0.084690] [Loss difference: -0.005, iterations with loss: 4]\n",
      "682 [D loss: 1.372729, acc.: 50.00%] [G loss: 0.086404] [Loss difference: 0.002, iterations with loss: 0]\n",
      "683 [D loss: 1.392599, acc.: 49.90%] [G loss: 0.089678] [Loss difference: 0.003, iterations with loss: 1]\n",
      "684 [D loss: 1.340080, acc.: 50.00%] [G loss: 0.086697] [Loss difference: -0.003, iterations with loss: 2]\n",
      "685 [D loss: 1.367840, acc.: 49.90%] [G loss: 0.080689] [Loss difference: -0.006, iterations with loss: 0]\n",
      "686 [D loss: 1.364885, acc.: 49.90%] [G loss: 0.090380] [Loss difference: 0.010, iterations with loss: 0]\n",
      "687 [D loss: 1.347939, acc.: 50.00%] [G loss: 0.084002] [Loss difference: -0.006, iterations with loss: 1]\n",
      "688 [D loss: 1.359543, acc.: 50.00%] [G loss: 0.088319] [Loss difference: 0.004, iterations with loss: 0]\n",
      "689 [D loss: 1.366323, acc.: 49.80%] [G loss: 0.089986] [Loss difference: 0.002, iterations with loss: 1]\n",
      "690 [D loss: 1.355912, acc.: 50.00%] [G loss: 0.088563] [Loss difference: -0.001, iterations with loss: 2]\n",
      "691 [D loss: 1.352321, acc.: 49.80%] [G loss: 0.090401] [Loss difference: 0.002, iterations with loss: 0]\n",
      "692 [D loss: 1.359387, acc.: 50.00%] [G loss: 0.087504] [Loss difference: -0.003, iterations with loss: 1]\n",
      "693 [D loss: 1.361433, acc.: 49.90%] [G loss: 0.089007] [Loss difference: 0.002, iterations with loss: 0]\n",
      "694 [D loss: 1.361250, acc.: 49.90%] [G loss: 0.086433] [Loss difference: -0.003, iterations with loss: 1]\n",
      "695 [D loss: 1.356279, acc.: 49.90%] [G loss: 0.090149] [Loss difference: 0.004, iterations with loss: 0]\n",
      "696 [D loss: 1.369771, acc.: 49.80%] [G loss: 0.083061] [Loss difference: -0.007, iterations with loss: 1]\n",
      "697 [D loss: 1.360310, acc.: 49.90%] [G loss: 0.084886] [Loss difference: 0.002, iterations with loss: 0]\n",
      "698 [D loss: 1.358343, acc.: 49.90%] [G loss: 0.086352] [Loss difference: 0.001, iterations with loss: 1]\n",
      "699 [D loss: 1.370922, acc.: 49.90%] [G loss: 0.083521] [Loss difference: -0.003, iterations with loss: 2]\n",
      "700 [D loss: 1.354583, acc.: 50.00%] [G loss: 0.084758] [Loss difference: 0.001, iterations with loss: 0]\n",
      "701 [D loss: 1.352173, acc.: 50.00%] [G loss: 0.088496] [Loss difference: 0.004, iterations with loss: 1]\n",
      "702 [D loss: 1.355952, acc.: 49.90%] [G loss: 0.084779] [Loss difference: -0.004, iterations with loss: 2]\n",
      "703 [D loss: 1.354450, acc.: 49.90%] [G loss: 0.090052] [Loss difference: 0.005, iterations with loss: 0]\n",
      "704 [D loss: 1.378466, acc.: 49.90%] [G loss: 0.088862] [Loss difference: -0.001, iterations with loss: 1]\n",
      "705 [D loss: 1.359891, acc.: 49.90%] [G loss: 0.088195] [Loss difference: -0.001, iterations with loss: 0]\n",
      "706 [D loss: 1.370000, acc.: 50.00%] [G loss: 0.082827] [Loss difference: -0.005, iterations with loss: 0]\n",
      "707 [D loss: 1.359220, acc.: 49.90%] [G loss: 0.084581] [Loss difference: 0.002, iterations with loss: 0]\n",
      "708 [D loss: 1.367191, acc.: 50.00%] [G loss: 0.088600] [Loss difference: 0.004, iterations with loss: 1]\n",
      "709 [D loss: 1.345314, acc.: 49.80%] [G loss: 0.085087] [Loss difference: -0.004, iterations with loss: 2]\n",
      "710 [D loss: 1.348208, acc.: 50.00%] [G loss: 0.093094] [Loss difference: 0.008, iterations with loss: 0]\n",
      "711 [D loss: 1.349676, acc.: 50.00%] [G loss: 0.087540] [Loss difference: -0.006, iterations with loss: 1]\n",
      "712 [D loss: 1.361040, acc.: 50.00%] [G loss: 0.089092] [Loss difference: 0.002, iterations with loss: 0]\n",
      "713 [D loss: 1.349815, acc.: 49.80%] [G loss: 0.093848] [Loss difference: 0.005, iterations with loss: 1]\n",
      "714 [D loss: 1.366987, acc.: 49.80%] [G loss: 0.085533] [Loss difference: -0.008, iterations with loss: 2]\n",
      "715 [D loss: 1.381219, acc.: 49.90%] [G loss: 0.084925] [Loss difference: -0.001, iterations with loss: 0]\n",
      "716 [D loss: 1.354466, acc.: 49.90%] [G loss: 0.087045] [Loss difference: 0.002, iterations with loss: 0]\n",
      "717 [D loss: 1.385605, acc.: 49.80%] [G loss: 0.088339] [Loss difference: 0.001, iterations with loss: 1]\n",
      "718 [D loss: 1.374843, acc.: 49.71%] [G loss: 0.081773] [Loss difference: -0.007, iterations with loss: 2]\n",
      "719 [D loss: 1.366459, acc.: 50.00%] [G loss: 0.089331] [Loss difference: 0.008, iterations with loss: 0]\n",
      "720 [D loss: 1.369213, acc.: 49.90%] [G loss: 0.086702] [Loss difference: -0.003, iterations with loss: 1]\n",
      "721 [D loss: 1.351904, acc.: 50.00%] [G loss: 0.087256] [Loss difference: 0.001, iterations with loss: 0]\n",
      "722 [D loss: 1.374351, acc.: 49.90%] [G loss: 0.088390] [Loss difference: 0.001, iterations with loss: 1]\n",
      "723 [D loss: 1.361006, acc.: 49.80%] [G loss: 0.087906] [Loss difference: -0.000, iterations with loss: 2]\n",
      "724 [D loss: 1.354389, acc.: 49.90%] [G loss: 0.086277] [Loss difference: -0.002, iterations with loss: 0]\n",
      "725 [D loss: 1.356392, acc.: 50.00%] [G loss: 0.085367] [Loss difference: -0.001, iterations with loss: 0]\n",
      "726 [D loss: 1.376743, acc.: 49.90%] [G loss: 0.085723] [Loss difference: 0.000, iterations with loss: 0]\n",
      "727 [D loss: 1.378685, acc.: 49.90%] [G loss: 0.088252] [Loss difference: 0.003, iterations with loss: 1]\n",
      "728 [D loss: 1.357404, acc.: 49.90%] [G loss: 0.084633] [Loss difference: -0.004, iterations with loss: 2]\n",
      "729 [D loss: 1.376223, acc.: 49.80%] [G loss: 0.086035] [Loss difference: 0.001, iterations with loss: 0]\n",
      "730 [D loss: 1.364644, acc.: 49.90%] [G loss: 0.081981] [Loss difference: -0.004, iterations with loss: 1]\n",
      "731 [D loss: 1.369117, acc.: 49.90%] [G loss: 0.087383] [Loss difference: 0.005, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732 [D loss: 1.372850, acc.: 49.80%] [G loss: 0.085161] [Loss difference: -0.002, iterations with loss: 1]\n",
      "733 [D loss: 1.351017, acc.: 49.80%] [G loss: 0.082734] [Loss difference: -0.002, iterations with loss: 0]\n",
      "734 [D loss: 1.366263, acc.: 49.90%] [G loss: 0.085198] [Loss difference: 0.002, iterations with loss: 0]\n",
      "735 [D loss: 1.362075, acc.: 49.90%] [G loss: 0.085288] [Loss difference: 0.000, iterations with loss: 1]\n",
      "736 [D loss: 1.366739, acc.: 50.00%] [G loss: 0.084139] [Loss difference: -0.001, iterations with loss: 2]\n",
      "737 [D loss: 1.364956, acc.: 49.71%] [G loss: 0.087631] [Loss difference: 0.003, iterations with loss: 0]\n",
      "738 [D loss: 1.378815, acc.: 49.90%] [G loss: 0.090032] [Loss difference: 0.002, iterations with loss: 1]\n",
      "739 [D loss: 1.363310, acc.: 49.80%] [G loss: 0.086440] [Loss difference: -0.004, iterations with loss: 2]\n",
      "740 [D loss: 1.366086, acc.: 50.00%] [G loss: 0.084949] [Loss difference: -0.001, iterations with loss: 0]\n",
      "741 [D loss: 1.377021, acc.: 49.90%] [G loss: 0.083472] [Loss difference: -0.001, iterations with loss: 0]\n",
      "742 [D loss: 1.381662, acc.: 49.90%] [G loss: 0.083099] [Loss difference: -0.000, iterations with loss: 0]\n",
      "743 [D loss: 1.380064, acc.: 49.80%] [G loss: 0.085130] [Loss difference: 0.002, iterations with loss: 0]\n",
      "744 [D loss: 1.349668, acc.: 49.90%] [G loss: 0.090025] [Loss difference: 0.005, iterations with loss: 1]\n",
      "745 [D loss: 1.354955, acc.: 49.90%] [G loss: 0.087436] [Loss difference: -0.003, iterations with loss: 2]\n",
      "746 [D loss: 1.358953, acc.: 50.00%] [G loss: 0.082075] [Loss difference: -0.005, iterations with loss: 0]\n",
      "747 [D loss: 1.356737, acc.: 49.80%] [G loss: 0.087789] [Loss difference: 0.006, iterations with loss: 0]\n",
      "748 [D loss: 1.370771, acc.: 49.90%] [G loss: 0.086379] [Loss difference: -0.001, iterations with loss: 1]\n",
      "749 [D loss: 1.351569, acc.: 49.90%] [G loss: 0.083961] [Loss difference: -0.002, iterations with loss: 0]\n",
      "750 [D loss: 1.361551, acc.: 49.90%] [G loss: 0.085860] [Loss difference: 0.002, iterations with loss: 0]\n",
      "751 [D loss: 1.362682, acc.: 50.00%] [G loss: 0.087237] [Loss difference: 0.001, iterations with loss: 1]\n",
      "752 [D loss: 1.376530, acc.: 49.71%] [G loss: 0.088218] [Loss difference: 0.001, iterations with loss: 2]\n",
      "753 [D loss: 1.345595, acc.: 50.00%] [G loss: 0.085531] [Loss difference: -0.003, iterations with loss: 3]\n",
      "754 [D loss: 1.368836, acc.: 49.80%] [G loss: 0.085655] [Loss difference: 0.000, iterations with loss: 0]\n",
      "755 [D loss: 1.369652, acc.: 49.90%] [G loss: 0.085003] [Loss difference: -0.001, iterations with loss: 1]\n",
      "756 [D loss: 1.348490, acc.: 50.00%] [G loss: 0.082172] [Loss difference: -0.003, iterations with loss: 0]\n",
      "757 [D loss: 1.351557, acc.: 49.90%] [G loss: 0.089066] [Loss difference: 0.007, iterations with loss: 0]\n",
      "758 [D loss: 1.352364, acc.: 49.71%] [G loss: 0.089302] [Loss difference: 0.000, iterations with loss: 1]\n",
      "759 [D loss: 1.349791, acc.: 50.00%] [G loss: 0.083497] [Loss difference: -0.006, iterations with loss: 2]\n",
      "760 [D loss: 1.355546, acc.: 50.00%] [G loss: 0.088151] [Loss difference: 0.005, iterations with loss: 0]\n",
      "761 [D loss: 1.344358, acc.: 50.00%] [G loss: 0.086233] [Loss difference: -0.002, iterations with loss: 1]\n",
      "762 [D loss: 1.348881, acc.: 49.90%] [G loss: 0.084336] [Loss difference: -0.002, iterations with loss: 0]\n",
      "763 [D loss: 1.349285, acc.: 50.00%] [G loss: 0.086079] [Loss difference: 0.002, iterations with loss: 0]\n",
      "764 [D loss: 1.357279, acc.: 49.90%] [G loss: 0.083022] [Loss difference: -0.003, iterations with loss: 1]\n",
      "765 [D loss: 1.373914, acc.: 49.90%] [G loss: 0.088503] [Loss difference: 0.005, iterations with loss: 0]\n",
      "766 [D loss: 1.358478, acc.: 49.90%] [G loss: 0.087165] [Loss difference: -0.001, iterations with loss: 1]\n",
      "767 [D loss: 1.359071, acc.: 49.90%] [G loss: 0.084153] [Loss difference: -0.003, iterations with loss: 0]\n",
      "768 [D loss: 1.331341, acc.: 50.00%] [G loss: 0.085245] [Loss difference: 0.001, iterations with loss: 0]\n",
      "769 [D loss: 1.349300, acc.: 49.90%] [G loss: 0.088195] [Loss difference: 0.003, iterations with loss: 1]\n",
      "770 [D loss: 1.349480, acc.: 49.90%] [G loss: 0.087660] [Loss difference: -0.001, iterations with loss: 2]\n",
      "771 [D loss: 1.345171, acc.: 50.00%] [G loss: 0.087761] [Loss difference: 0.000, iterations with loss: 0]\n",
      "772 [D loss: 1.352903, acc.: 50.00%] [G loss: 0.084207] [Loss difference: -0.004, iterations with loss: 1]\n",
      "773 [D loss: 1.366150, acc.: 49.80%] [G loss: 0.086075] [Loss difference: 0.002, iterations with loss: 0]\n",
      "774 [D loss: 1.364553, acc.: 49.90%] [G loss: 0.085397] [Loss difference: -0.001, iterations with loss: 1]\n",
      "775 [D loss: 1.367640, acc.: 49.90%] [G loss: 0.084544] [Loss difference: -0.001, iterations with loss: 0]\n",
      "776 [D loss: 1.380701, acc.: 49.90%] [G loss: 0.089059] [Loss difference: 0.005, iterations with loss: 0]\n",
      "777 [D loss: 1.356480, acc.: 49.90%] [G loss: 0.092642] [Loss difference: 0.004, iterations with loss: 1]\n",
      "778 [D loss: 1.347196, acc.: 49.90%] [G loss: 0.085009] [Loss difference: -0.008, iterations with loss: 2]\n",
      "779 [D loss: 1.341061, acc.: 49.80%] [G loss: 0.082316] [Loss difference: -0.003, iterations with loss: 0]\n",
      "780 [D loss: 1.354650, acc.: 49.90%] [G loss: 0.084294] [Loss difference: 0.002, iterations with loss: 0]\n",
      "781 [D loss: 1.342654, acc.: 50.00%] [G loss: 0.089302] [Loss difference: 0.005, iterations with loss: 1]\n",
      "782 [D loss: 1.353072, acc.: 49.80%] [G loss: 0.081571] [Loss difference: -0.008, iterations with loss: 2]\n",
      "783 [D loss: 1.365875, acc.: 49.90%] [G loss: 0.088937] [Loss difference: 0.007, iterations with loss: 0]\n",
      "784 [D loss: 1.355612, acc.: 50.00%] [G loss: 0.087800] [Loss difference: -0.001, iterations with loss: 1]\n",
      "785 [D loss: 1.362879, acc.: 49.71%] [G loss: 0.089306] [Loss difference: 0.002, iterations with loss: 0]\n",
      "786 [D loss: 1.371798, acc.: 49.80%] [G loss: 0.085360] [Loss difference: -0.004, iterations with loss: 1]\n",
      "787 [D loss: 1.359260, acc.: 49.80%] [G loss: 0.083001] [Loss difference: -0.002, iterations with loss: 0]\n",
      "788 [D loss: 1.364093, acc.: 49.90%] [G loss: 0.083620] [Loss difference: 0.001, iterations with loss: 0]\n",
      "789 [D loss: 1.361410, acc.: 49.90%] [G loss: 0.088277] [Loss difference: 0.005, iterations with loss: 1]\n",
      "790 [D loss: 1.352618, acc.: 49.90%] [G loss: 0.085607] [Loss difference: -0.003, iterations with loss: 2]\n",
      "791 [D loss: 1.363009, acc.: 49.90%] [G loss: 0.084159] [Loss difference: -0.001, iterations with loss: 0]\n",
      "792 [D loss: 1.358969, acc.: 49.61%] [G loss: 0.088606] [Loss difference: 0.004, iterations with loss: 0]\n",
      "793 [D loss: 1.374373, acc.: 49.80%] [G loss: 0.089595] [Loss difference: 0.001, iterations with loss: 1]\n",
      "794 [D loss: 1.369618, acc.: 49.90%] [G loss: 0.084228] [Loss difference: -0.005, iterations with loss: 2]\n",
      "795 [D loss: 1.346305, acc.: 49.90%] [G loss: 0.086537] [Loss difference: 0.002, iterations with loss: 0]\n",
      "796 [D loss: 1.343336, acc.: 50.00%] [G loss: 0.087252] [Loss difference: 0.001, iterations with loss: 1]\n",
      "797 [D loss: 1.349457, acc.: 50.00%] [G loss: 0.088748] [Loss difference: 0.001, iterations with loss: 2]\n",
      "798 [D loss: 1.338352, acc.: 49.90%] [G loss: 0.089094] [Loss difference: 0.000, iterations with loss: 3]\n",
      "799 [D loss: 1.370274, acc.: 49.80%] [G loss: 0.087419] [Loss difference: -0.002, iterations with loss: 4]\n",
      "800 [D loss: 1.355664, acc.: 49.90%] [G loss: 0.091679] [Loss difference: 0.004, iterations with loss: 0]\n",
      "801 [D loss: 1.356617, acc.: 49.90%] [G loss: 0.084991] [Loss difference: -0.007, iterations with loss: 1]\n",
      "802 [D loss: 1.345234, acc.: 49.80%] [G loss: 0.088734] [Loss difference: 0.004, iterations with loss: 0]\n",
      "803 [D loss: 1.365115, acc.: 49.80%] [G loss: 0.087785] [Loss difference: -0.001, iterations with loss: 1]\n",
      "804 [D loss: 1.360308, acc.: 49.71%] [G loss: 0.089568] [Loss difference: 0.002, iterations with loss: 0]\n",
      "805 [D loss: 1.354784, acc.: 49.80%] [G loss: 0.083663] [Loss difference: -0.006, iterations with loss: 1]\n",
      "806 [D loss: 1.358939, acc.: 49.80%] [G loss: 0.086627] [Loss difference: 0.003, iterations with loss: 0]\n",
      "807 [D loss: 1.363509, acc.: 49.80%] [G loss: 0.083430] [Loss difference: -0.003, iterations with loss: 1]\n",
      "808 [D loss: 1.344525, acc.: 50.00%] [G loss: 0.086828] [Loss difference: 0.003, iterations with loss: 0]\n",
      "809 [D loss: 1.346888, acc.: 49.80%] [G loss: 0.086286] [Loss difference: -0.001, iterations with loss: 1]\n",
      "810 [D loss: 1.371448, acc.: 49.80%] [G loss: 0.084737] [Loss difference: -0.002, iterations with loss: 0]\n",
      "811 [D loss: 1.366895, acc.: 49.80%] [G loss: 0.089722] [Loss difference: 0.005, iterations with loss: 0]\n",
      "812 [D loss: 1.357888, acc.: 49.90%] [G loss: 0.085039] [Loss difference: -0.005, iterations with loss: 1]\n",
      "813 [D loss: 1.348203, acc.: 49.90%] [G loss: 0.094257] [Loss difference: 0.009, iterations with loss: 0]\n",
      "814 [D loss: 1.350841, acc.: 50.00%] [G loss: 0.086331] [Loss difference: -0.008, iterations with loss: 1]\n",
      "815 [D loss: 1.337227, acc.: 50.00%] [G loss: 0.087507] [Loss difference: 0.001, iterations with loss: 0]\n",
      "816 [D loss: 1.345530, acc.: 49.90%] [G loss: 0.091655] [Loss difference: 0.004, iterations with loss: 1]\n",
      "817 [D loss: 1.368419, acc.: 49.90%] [G loss: 0.086463] [Loss difference: -0.005, iterations with loss: 2]\n",
      "818 [D loss: 1.339576, acc.: 49.80%] [G loss: 0.086905] [Loss difference: 0.000, iterations with loss: 0]\n",
      "819 [D loss: 1.340083, acc.: 49.90%] [G loss: 0.090646] [Loss difference: 0.004, iterations with loss: 1]\n",
      "820 [D loss: 1.342812, acc.: 49.80%] [G loss: 0.090746] [Loss difference: 0.000, iterations with loss: 2]\n",
      "821 [D loss: 1.326892, acc.: 50.00%] [G loss: 0.090825] [Loss difference: 0.000, iterations with loss: 3]\n",
      "822 [D loss: 1.354080, acc.: 49.71%] [G loss: 0.091864] [Loss difference: 0.001, iterations with loss: 4]\n",
      "823 [D loss: 1.348397, acc.: 49.90%] [G loss: 0.086933] [Loss difference: -0.005, iterations with loss: 5]\n",
      "824 [D loss: 1.329064, acc.: 50.00%] [G loss: 0.087462] [Loss difference: 0.001, iterations with loss: 0]\n",
      "825 [D loss: 1.355532, acc.: 49.71%] [G loss: 0.088464] [Loss difference: 0.001, iterations with loss: 1]\n",
      "826 [D loss: 1.361374, acc.: 50.00%] [G loss: 0.088455] [Loss difference: -0.000, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827 [D loss: 1.367542, acc.: 49.80%] [G loss: 0.086292] [Loss difference: -0.002, iterations with loss: 0]\n",
      "828 [D loss: 1.349390, acc.: 50.00%] [G loss: 0.089019] [Loss difference: 0.003, iterations with loss: 0]\n",
      "829 [D loss: 1.369443, acc.: 49.90%] [G loss: 0.085819] [Loss difference: -0.003, iterations with loss: 1]\n",
      "830 [D loss: 1.351069, acc.: 49.71%] [G loss: 0.090727] [Loss difference: 0.005, iterations with loss: 0]\n",
      "831 [D loss: 1.345319, acc.: 49.80%] [G loss: 0.089414] [Loss difference: -0.001, iterations with loss: 1]\n",
      "832 [D loss: 1.350147, acc.: 49.90%] [G loss: 0.084192] [Loss difference: -0.005, iterations with loss: 0]\n",
      "833 [D loss: 1.361222, acc.: 49.90%] [G loss: 0.087055] [Loss difference: 0.003, iterations with loss: 0]\n",
      "834 [D loss: 1.373926, acc.: 49.71%] [G loss: 0.084686] [Loss difference: -0.002, iterations with loss: 1]\n",
      "835 [D loss: 1.375415, acc.: 49.61%] [G loss: 0.087491] [Loss difference: 0.003, iterations with loss: 0]\n",
      "836 [D loss: 1.369803, acc.: 49.80%] [G loss: 0.093486] [Loss difference: 0.006, iterations with loss: 1]\n",
      "837 [D loss: 1.352642, acc.: 49.90%] [G loss: 0.090077] [Loss difference: -0.003, iterations with loss: 2]\n",
      "838 [D loss: 1.357069, acc.: 49.90%] [G loss: 0.093373] [Loss difference: 0.003, iterations with loss: 0]\n",
      "839 [D loss: 1.325204, acc.: 50.00%] [G loss: 0.092025] [Loss difference: -0.001, iterations with loss: 1]\n",
      "840 [D loss: 1.355986, acc.: 49.80%] [G loss: 0.087095] [Loss difference: -0.005, iterations with loss: 0]\n",
      "841 [D loss: 1.346853, acc.: 49.61%] [G loss: 0.094591] [Loss difference: 0.007, iterations with loss: 0]\n",
      "842 [D loss: 1.345241, acc.: 49.80%] [G loss: 0.086939] [Loss difference: -0.008, iterations with loss: 1]\n",
      "843 [D loss: 1.354311, acc.: 49.90%] [G loss: 0.089232] [Loss difference: 0.002, iterations with loss: 0]\n",
      "844 [D loss: 1.347597, acc.: 50.00%] [G loss: 0.088581] [Loss difference: -0.001, iterations with loss: 1]\n",
      "845 [D loss: 1.350567, acc.: 49.90%] [G loss: 0.094408] [Loss difference: 0.006, iterations with loss: 0]\n",
      "846 [D loss: 1.346574, acc.: 49.90%] [G loss: 0.090228] [Loss difference: -0.004, iterations with loss: 1]\n",
      "847 [D loss: 1.341986, acc.: 50.00%] [G loss: 0.087545] [Loss difference: -0.003, iterations with loss: 0]\n",
      "848 [D loss: 1.332296, acc.: 50.00%] [G loss: 0.086228] [Loss difference: -0.001, iterations with loss: 0]\n",
      "849 [D loss: 1.336841, acc.: 49.90%] [G loss: 0.089727] [Loss difference: 0.003, iterations with loss: 0]\n",
      "850 [D loss: 1.364091, acc.: 49.90%] [G loss: 0.086903] [Loss difference: -0.003, iterations with loss: 1]\n",
      "851 [D loss: 1.332993, acc.: 49.80%] [G loss: 0.088337] [Loss difference: 0.001, iterations with loss: 0]\n",
      "852 [D loss: 1.363190, acc.: 49.90%] [G loss: 0.092356] [Loss difference: 0.004, iterations with loss: 1]\n",
      "853 [D loss: 1.354545, acc.: 49.90%] [G loss: 0.087843] [Loss difference: -0.005, iterations with loss: 2]\n",
      "854 [D loss: 1.356292, acc.: 49.90%] [G loss: 0.091409] [Loss difference: 0.004, iterations with loss: 0]\n",
      "855 [D loss: 1.364176, acc.: 49.90%] [G loss: 0.088041] [Loss difference: -0.003, iterations with loss: 1]\n",
      "856 [D loss: 1.366827, acc.: 49.80%] [G loss: 0.086544] [Loss difference: -0.001, iterations with loss: 0]\n",
      "857 [D loss: 1.340726, acc.: 50.00%] [G loss: 0.094461] [Loss difference: 0.008, iterations with loss: 0]\n",
      "858 [D loss: 1.348733, acc.: 50.00%] [G loss: 0.089053] [Loss difference: -0.005, iterations with loss: 1]\n",
      "859 [D loss: 1.347781, acc.: 49.80%] [G loss: 0.090401] [Loss difference: 0.001, iterations with loss: 0]\n",
      "860 [D loss: 1.353841, acc.: 49.80%] [G loss: 0.087205] [Loss difference: -0.003, iterations with loss: 1]\n",
      "861 [D loss: 1.342131, acc.: 49.80%] [G loss: 0.083317] [Loss difference: -0.004, iterations with loss: 0]\n",
      "862 [D loss: 1.360757, acc.: 49.80%] [G loss: 0.085317] [Loss difference: 0.002, iterations with loss: 0]\n",
      "863 [D loss: 1.353127, acc.: 49.90%] [G loss: 0.087748] [Loss difference: 0.002, iterations with loss: 1]\n",
      "864 [D loss: 1.364468, acc.: 49.90%] [G loss: 0.091030] [Loss difference: 0.003, iterations with loss: 2]\n",
      "865 [D loss: 1.353819, acc.: 49.90%] [G loss: 0.095040] [Loss difference: 0.004, iterations with loss: 3]\n",
      "866 [D loss: 1.347675, acc.: 49.90%] [G loss: 0.089501] [Loss difference: -0.006, iterations with loss: 4]\n",
      "867 [D loss: 1.339630, acc.: 49.90%] [G loss: 0.085352] [Loss difference: -0.004, iterations with loss: 0]\n",
      "868 [D loss: 1.340542, acc.: 49.90%] [G loss: 0.091494] [Loss difference: 0.006, iterations with loss: 0]\n",
      "869 [D loss: 1.347912, acc.: 49.90%] [G loss: 0.090222] [Loss difference: -0.001, iterations with loss: 1]\n",
      "870 [D loss: 1.330719, acc.: 49.90%] [G loss: 0.087672] [Loss difference: -0.003, iterations with loss: 0]\n",
      "871 [D loss: 1.342555, acc.: 49.71%] [G loss: 0.087071] [Loss difference: -0.001, iterations with loss: 0]\n",
      "872 [D loss: 1.348525, acc.: 49.71%] [G loss: 0.095678] [Loss difference: 0.009, iterations with loss: 0]\n",
      "873 [D loss: 1.333445, acc.: 50.00%] [G loss: 0.089508] [Loss difference: -0.006, iterations with loss: 1]\n",
      "874 [D loss: 1.336966, acc.: 49.90%] [G loss: 0.090676] [Loss difference: 0.001, iterations with loss: 0]\n",
      "875 [D loss: 1.345508, acc.: 49.80%] [G loss: 0.091304] [Loss difference: 0.001, iterations with loss: 1]\n",
      "876 [D loss: 1.358963, acc.: 49.90%] [G loss: 0.092063] [Loss difference: 0.001, iterations with loss: 2]\n",
      "877 [D loss: 1.365214, acc.: 49.80%] [G loss: 0.085849] [Loss difference: -0.006, iterations with loss: 3]\n",
      "878 [D loss: 1.357285, acc.: 49.90%] [G loss: 0.089096] [Loss difference: 0.003, iterations with loss: 0]\n",
      "879 [D loss: 1.333431, acc.: 50.00%] [G loss: 0.090593] [Loss difference: 0.001, iterations with loss: 1]\n",
      "880 [D loss: 1.373326, acc.: 49.71%] [G loss: 0.083448] [Loss difference: -0.007, iterations with loss: 2]\n",
      "881 [D loss: 1.342925, acc.: 49.90%] [G loss: 0.091482] [Loss difference: 0.008, iterations with loss: 0]\n",
      "882 [D loss: 1.348710, acc.: 50.00%] [G loss: 0.088630] [Loss difference: -0.003, iterations with loss: 1]\n",
      "883 [D loss: 1.346885, acc.: 50.00%] [G loss: 0.091680] [Loss difference: 0.003, iterations with loss: 0]\n",
      "884 [D loss: 1.345793, acc.: 49.90%] [G loss: 0.095428] [Loss difference: 0.004, iterations with loss: 1]\n",
      "885 [D loss: 1.336511, acc.: 49.90%] [G loss: 0.088716] [Loss difference: -0.007, iterations with loss: 2]\n",
      "886 [D loss: 1.344446, acc.: 50.00%] [G loss: 0.088822] [Loss difference: 0.000, iterations with loss: 0]\n",
      "887 [D loss: 1.361937, acc.: 50.00%] [G loss: 0.085190] [Loss difference: -0.004, iterations with loss: 1]\n",
      "888 [D loss: 1.371491, acc.: 49.71%] [G loss: 0.090747] [Loss difference: 0.006, iterations with loss: 0]\n",
      "889 [D loss: 1.354565, acc.: 49.80%] [G loss: 0.087834] [Loss difference: -0.003, iterations with loss: 1]\n",
      "890 [D loss: 1.353004, acc.: 49.90%] [G loss: 0.097184] [Loss difference: 0.009, iterations with loss: 0]\n",
      "891 [D loss: 1.359559, acc.: 49.80%] [G loss: 0.091809] [Loss difference: -0.005, iterations with loss: 1]\n",
      "892 [D loss: 1.332187, acc.: 49.90%] [G loss: 0.088073] [Loss difference: -0.004, iterations with loss: 0]\n",
      "893 [D loss: 1.352484, acc.: 49.71%] [G loss: 0.090382] [Loss difference: 0.002, iterations with loss: 0]\n",
      "894 [D loss: 1.343417, acc.: 49.71%] [G loss: 0.089797] [Loss difference: -0.001, iterations with loss: 1]\n",
      "895 [D loss: 1.338488, acc.: 49.80%] [G loss: 0.088446] [Loss difference: -0.001, iterations with loss: 0]\n",
      "896 [D loss: 1.348810, acc.: 49.90%] [G loss: 0.094785] [Loss difference: 0.006, iterations with loss: 0]\n",
      "897 [D loss: 1.337145, acc.: 49.90%] [G loss: 0.094903] [Loss difference: 0.000, iterations with loss: 1]\n",
      "898 [D loss: 1.329701, acc.: 50.00%] [G loss: 0.087256] [Loss difference: -0.008, iterations with loss: 2]\n",
      "899 [D loss: 1.327833, acc.: 49.90%] [G loss: 0.093112] [Loss difference: 0.006, iterations with loss: 0]\n",
      "900 [D loss: 1.338261, acc.: 49.90%] [G loss: 0.091621] [Loss difference: -0.001, iterations with loss: 1]\n",
      "901 [D loss: 1.333426, acc.: 49.80%] [G loss: 0.088142] [Loss difference: -0.003, iterations with loss: 0]\n",
      "902 [D loss: 1.335170, acc.: 49.90%] [G loss: 0.090122] [Loss difference: 0.002, iterations with loss: 0]\n",
      "903 [D loss: 1.347147, acc.: 49.90%] [G loss: 0.092268] [Loss difference: 0.002, iterations with loss: 1]\n",
      "904 [D loss: 1.341577, acc.: 49.80%] [G loss: 0.091912] [Loss difference: -0.000, iterations with loss: 2]\n",
      "905 [D loss: 1.320061, acc.: 50.00%] [G loss: 0.096192] [Loss difference: 0.004, iterations with loss: 0]\n",
      "906 [D loss: 1.336661, acc.: 49.90%] [G loss: 0.092942] [Loss difference: -0.003, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907 [D loss: 1.353170, acc.: 49.90%] [G loss: 0.092246] [Loss difference: -0.001, iterations with loss: 0]\n",
      "908 [D loss: 1.334467, acc.: 50.00%] [G loss: 0.092562] [Loss difference: 0.000, iterations with loss: 0]\n",
      "909 [D loss: 1.358833, acc.: 49.71%] [G loss: 0.092584] [Loss difference: 0.000, iterations with loss: 1]\n",
      "910 [D loss: 1.341490, acc.: 49.80%] [G loss: 0.090815] [Loss difference: -0.002, iterations with loss: 2]\n",
      "911 [D loss: 1.340924, acc.: 49.90%] [G loss: 0.088281] [Loss difference: -0.003, iterations with loss: 0]\n",
      "912 [D loss: 1.362074, acc.: 49.80%] [G loss: 0.092913] [Loss difference: 0.005, iterations with loss: 0]\n",
      "913 [D loss: 1.357231, acc.: 49.80%] [G loss: 0.094293] [Loss difference: 0.001, iterations with loss: 1]\n",
      "914 [D loss: 1.349989, acc.: 49.90%] [G loss: 0.092819] [Loss difference: -0.001, iterations with loss: 2]\n",
      "915 [D loss: 1.343396, acc.: 49.80%] [G loss: 0.093941] [Loss difference: 0.001, iterations with loss: 0]\n",
      "916 [D loss: 1.332006, acc.: 49.90%] [G loss: 0.085070] [Loss difference: -0.009, iterations with loss: 1]\n",
      "917 [D loss: 1.340480, acc.: 50.00%] [G loss: 0.088916] [Loss difference: 0.004, iterations with loss: 0]\n",
      "918 [D loss: 1.361120, acc.: 49.61%] [G loss: 0.089896] [Loss difference: 0.001, iterations with loss: 1]\n",
      "919 [D loss: 1.334409, acc.: 49.80%] [G loss: 0.092931] [Loss difference: 0.003, iterations with loss: 2]\n",
      "920 [D loss: 1.328954, acc.: 49.90%] [G loss: 0.092286] [Loss difference: -0.001, iterations with loss: 3]\n",
      "921 [D loss: 1.335628, acc.: 50.00%] [G loss: 0.092923] [Loss difference: 0.001, iterations with loss: 0]\n",
      "922 [D loss: 1.347703, acc.: 49.71%] [G loss: 0.089943] [Loss difference: -0.003, iterations with loss: 1]\n",
      "923 [D loss: 1.335179, acc.: 49.90%] [G loss: 0.093562] [Loss difference: 0.004, iterations with loss: 0]\n",
      "924 [D loss: 1.324086, acc.: 49.90%] [G loss: 0.092677] [Loss difference: -0.001, iterations with loss: 1]\n",
      "925 [D loss: 1.348020, acc.: 50.00%] [G loss: 0.091085] [Loss difference: -0.002, iterations with loss: 0]\n",
      "926 [D loss: 1.345679, acc.: 49.90%] [G loss: 0.091122] [Loss difference: 0.000, iterations with loss: 0]\n",
      "927 [D loss: 1.344409, acc.: 50.00%] [G loss: 0.093387] [Loss difference: 0.002, iterations with loss: 1]\n",
      "928 [D loss: 1.316885, acc.: 50.00%] [G loss: 0.092136] [Loss difference: -0.001, iterations with loss: 2]\n",
      "929 [D loss: 1.325339, acc.: 49.90%] [G loss: 0.091730] [Loss difference: -0.000, iterations with loss: 0]\n",
      "930 [D loss: 1.344517, acc.: 49.71%] [G loss: 0.087417] [Loss difference: -0.004, iterations with loss: 0]\n",
      "931 [D loss: 1.329287, acc.: 49.90%] [G loss: 0.090548] [Loss difference: 0.003, iterations with loss: 0]\n",
      "932 [D loss: 1.349813, acc.: 49.80%] [G loss: 0.091024] [Loss difference: 0.000, iterations with loss: 1]\n",
      "933 [D loss: 1.364442, acc.: 49.71%] [G loss: 0.090905] [Loss difference: -0.000, iterations with loss: 2]\n",
      "934 [D loss: 1.339000, acc.: 49.90%] [G loss: 0.090789] [Loss difference: -0.000, iterations with loss: 0]\n",
      "935 [D loss: 1.334337, acc.: 50.00%] [G loss: 0.093419] [Loss difference: 0.003, iterations with loss: 0]\n",
      "936 [D loss: 1.342278, acc.: 49.90%] [G loss: 0.086962] [Loss difference: -0.006, iterations with loss: 1]\n",
      "937 [D loss: 1.339681, acc.: 49.80%] [G loss: 0.097326] [Loss difference: 0.010, iterations with loss: 0]\n",
      "938 [D loss: 1.339176, acc.: 49.90%] [G loss: 0.101556] [Loss difference: 0.004, iterations with loss: 1]\n",
      "939 [D loss: 1.337508, acc.: 49.80%] [G loss: 0.091490] [Loss difference: -0.010, iterations with loss: 2]\n",
      "940 [D loss: 1.340720, acc.: 49.71%] [G loss: 0.089907] [Loss difference: -0.002, iterations with loss: 0]\n",
      "941 [D loss: 1.337221, acc.: 49.90%] [G loss: 0.090190] [Loss difference: 0.000, iterations with loss: 0]\n",
      "942 [D loss: 1.378250, acc.: 49.71%] [G loss: 0.089587] [Loss difference: -0.001, iterations with loss: 1]\n",
      "943 [D loss: 1.334782, acc.: 49.80%] [G loss: 0.093585] [Loss difference: 0.004, iterations with loss: 0]\n",
      "944 [D loss: 1.334323, acc.: 49.90%] [G loss: 0.093860] [Loss difference: 0.000, iterations with loss: 1]\n",
      "945 [D loss: 1.332682, acc.: 50.00%] [G loss: 0.093642] [Loss difference: -0.000, iterations with loss: 2]\n",
      "946 [D loss: 1.325349, acc.: 49.71%] [G loss: 0.091756] [Loss difference: -0.002, iterations with loss: 0]\n",
      "947 [D loss: 1.328844, acc.: 50.00%] [G loss: 0.093977] [Loss difference: 0.002, iterations with loss: 0]\n",
      "948 [D loss: 1.326798, acc.: 50.00%] [G loss: 0.091238] [Loss difference: -0.003, iterations with loss: 1]\n",
      "949 [D loss: 1.318574, acc.: 50.00%] [G loss: 0.095583] [Loss difference: 0.004, iterations with loss: 0]\n",
      "950 [D loss: 1.321459, acc.: 50.00%] [G loss: 0.093098] [Loss difference: -0.002, iterations with loss: 1]\n",
      "951 [D loss: 1.361579, acc.: 49.51%] [G loss: 0.092221] [Loss difference: -0.001, iterations with loss: 0]\n",
      "952 [D loss: 1.316804, acc.: 50.00%] [G loss: 0.093277] [Loss difference: 0.001, iterations with loss: 0]\n",
      "953 [D loss: 1.323516, acc.: 50.00%] [G loss: 0.093390] [Loss difference: 0.000, iterations with loss: 1]\n",
      "954 [D loss: 1.333533, acc.: 49.90%] [G loss: 0.093822] [Loss difference: 0.000, iterations with loss: 2]\n",
      "955 [D loss: 1.333395, acc.: 49.90%] [G loss: 0.097137] [Loss difference: 0.003, iterations with loss: 3]\n",
      "956 [D loss: 1.330876, acc.: 49.80%] [G loss: 0.098549] [Loss difference: 0.001, iterations with loss: 4]\n",
      "957 [D loss: 1.316701, acc.: 49.71%] [G loss: 0.095503] [Loss difference: -0.003, iterations with loss: 5]\n",
      "958 [D loss: 1.343596, acc.: 49.90%] [G loss: 0.090515] [Loss difference: -0.005, iterations with loss: 0]\n",
      "959 [D loss: 1.331147, acc.: 49.80%] [G loss: 0.096566] [Loss difference: 0.006, iterations with loss: 0]\n",
      "960 [D loss: 1.323454, acc.: 49.80%] [G loss: 0.093356] [Loss difference: -0.003, iterations with loss: 1]\n",
      "961 [D loss: 1.343179, acc.: 49.90%] [G loss: 0.091547] [Loss difference: -0.002, iterations with loss: 0]\n",
      "962 [D loss: 1.316913, acc.: 49.80%] [G loss: 0.098052] [Loss difference: 0.007, iterations with loss: 0]\n",
      "963 [D loss: 1.339819, acc.: 49.80%] [G loss: 0.102312] [Loss difference: 0.004, iterations with loss: 1]\n",
      "964 [D loss: 1.302454, acc.: 49.80%] [G loss: 0.089940] [Loss difference: -0.012, iterations with loss: 2]\n",
      "965 [D loss: 1.339293, acc.: 49.90%] [G loss: 0.093488] [Loss difference: 0.004, iterations with loss: 0]\n",
      "966 [D loss: 1.344073, acc.: 49.80%] [G loss: 0.088821] [Loss difference: -0.005, iterations with loss: 1]\n",
      "967 [D loss: 1.337500, acc.: 50.00%] [G loss: 0.093397] [Loss difference: 0.005, iterations with loss: 0]\n",
      "968 [D loss: 1.346534, acc.: 49.80%] [G loss: 0.092564] [Loss difference: -0.001, iterations with loss: 1]\n",
      "969 [D loss: 1.326145, acc.: 49.90%] [G loss: 0.096567] [Loss difference: 0.004, iterations with loss: 0]\n",
      "970 [D loss: 1.354811, acc.: 49.71%] [G loss: 0.095510] [Loss difference: -0.001, iterations with loss: 1]\n",
      "971 [D loss: 1.336260, acc.: 49.90%] [G loss: 0.092176] [Loss difference: -0.003, iterations with loss: 0]\n",
      "972 [D loss: 1.310907, acc.: 50.00%] [G loss: 0.091630] [Loss difference: -0.001, iterations with loss: 0]\n",
      "973 [D loss: 1.324355, acc.: 49.80%] [G loss: 0.097392] [Loss difference: 0.006, iterations with loss: 0]\n",
      "974 [D loss: 1.320802, acc.: 50.00%] [G loss: 0.100393] [Loss difference: 0.003, iterations with loss: 1]\n",
      "975 [D loss: 1.322769, acc.: 50.00%] [G loss: 0.091362] [Loss difference: -0.009, iterations with loss: 2]\n",
      "976 [D loss: 1.326233, acc.: 49.90%] [G loss: 0.092556] [Loss difference: 0.001, iterations with loss: 0]\n",
      "977 [D loss: 1.342853, acc.: 49.90%] [G loss: 0.090947] [Loss difference: -0.002, iterations with loss: 1]\n",
      "978 [D loss: 1.334140, acc.: 50.00%] [G loss: 0.092233] [Loss difference: 0.001, iterations with loss: 0]\n",
      "979 [D loss: 1.330868, acc.: 50.00%] [G loss: 0.093418] [Loss difference: 0.001, iterations with loss: 1]\n",
      "980 [D loss: 1.339265, acc.: 49.90%] [G loss: 0.094743] [Loss difference: 0.001, iterations with loss: 2]\n",
      "981 [D loss: 1.326043, acc.: 49.80%] [G loss: 0.098239] [Loss difference: 0.003, iterations with loss: 3]\n",
      "982 [D loss: 1.324769, acc.: 49.90%] [G loss: 0.094609] [Loss difference: -0.004, iterations with loss: 4]\n",
      "983 [D loss: 1.333590, acc.: 49.71%] [G loss: 0.093349] [Loss difference: -0.001, iterations with loss: 0]\n",
      "984 [D loss: 1.319983, acc.: 50.00%] [G loss: 0.091854] [Loss difference: -0.001, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985 [D loss: 1.337932, acc.: 49.80%] [G loss: 0.094030] [Loss difference: 0.002, iterations with loss: 0]\n",
      "986 [D loss: 1.354731, acc.: 49.80%] [G loss: 0.095129] [Loss difference: 0.001, iterations with loss: 1]\n",
      "987 [D loss: 1.357318, acc.: 49.80%] [G loss: 0.094302] [Loss difference: -0.001, iterations with loss: 2]\n",
      "988 [D loss: 1.340505, acc.: 50.00%] [G loss: 0.096048] [Loss difference: 0.002, iterations with loss: 0]\n",
      "989 [D loss: 1.339350, acc.: 49.90%] [G loss: 0.096788] [Loss difference: 0.001, iterations with loss: 1]\n",
      "990 [D loss: 1.353307, acc.: 49.90%] [G loss: 0.091849] [Loss difference: -0.005, iterations with loss: 2]\n",
      "991 [D loss: 1.321840, acc.: 50.00%] [G loss: 0.094563] [Loss difference: 0.003, iterations with loss: 0]\n",
      "992 [D loss: 1.340584, acc.: 49.71%] [G loss: 0.095197] [Loss difference: 0.001, iterations with loss: 1]\n",
      "993 [D loss: 1.352284, acc.: 49.61%] [G loss: 0.094015] [Loss difference: -0.001, iterations with loss: 2]\n",
      "994 [D loss: 1.332659, acc.: 49.80%] [G loss: 0.095925] [Loss difference: 0.002, iterations with loss: 0]\n",
      "995 [D loss: 1.344525, acc.: 49.61%] [G loss: 0.096055] [Loss difference: 0.000, iterations with loss: 1]\n",
      "996 [D loss: 1.311687, acc.: 50.00%] [G loss: 0.091460] [Loss difference: -0.005, iterations with loss: 2]\n",
      "997 [D loss: 1.330801, acc.: 49.90%] [G loss: 0.096462] [Loss difference: 0.005, iterations with loss: 0]\n",
      "998 [D loss: 1.318405, acc.: 49.90%] [G loss: 0.096546] [Loss difference: 0.000, iterations with loss: 1]\n",
      "999 [D loss: 1.358968, acc.: 49.71%] [G loss: 0.094061] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1000 [D loss: 1.335112, acc.: 49.71%] [G loss: 0.094466] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1001 [D loss: 1.322786, acc.: 49.71%] [G loss: 0.098568] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1002 [D loss: 1.338730, acc.: 49.71%] [G loss: 0.094664] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1003 [D loss: 1.322653, acc.: 50.00%] [G loss: 0.093657] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1004 [D loss: 1.328516, acc.: 49.90%] [G loss: 0.099312] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1005 [D loss: 1.368856, acc.: 49.32%] [G loss: 0.100365] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1006 [D loss: 1.358053, acc.: 49.80%] [G loss: 0.093831] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1007 [D loss: 1.342054, acc.: 49.71%] [G loss: 0.094643] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1008 [D loss: 1.332880, acc.: 50.00%] [G loss: 0.096852] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1009 [D loss: 1.361339, acc.: 49.71%] [G loss: 0.095923] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1010 [D loss: 1.326034, acc.: 49.90%] [G loss: 0.099102] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1011 [D loss: 1.344074, acc.: 49.61%] [G loss: 0.093974] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1012 [D loss: 1.332706, acc.: 49.90%] [G loss: 0.095927] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1013 [D loss: 1.339125, acc.: 49.80%] [G loss: 0.091644] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1014 [D loss: 1.347683, acc.: 49.71%] [G loss: 0.091826] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1015 [D loss: 1.363664, acc.: 49.61%] [G loss: 0.098729] [Loss difference: 0.007, iterations with loss: 1]\n",
      "1016 [D loss: 1.352473, acc.: 49.61%] [G loss: 0.095562] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1017 [D loss: 1.335217, acc.: 49.90%] [G loss: 0.090468] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1018 [D loss: 1.317990, acc.: 50.00%] [G loss: 0.090433] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1019 [D loss: 1.338477, acc.: 49.80%] [G loss: 0.100499] [Loss difference: 0.010, iterations with loss: 0]\n",
      "1020 [D loss: 1.326389, acc.: 49.90%] [G loss: 0.093745] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1021 [D loss: 1.342629, acc.: 49.80%] [G loss: 0.100504] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1022 [D loss: 1.326555, acc.: 49.61%] [G loss: 0.091368] [Loss difference: -0.009, iterations with loss: 1]\n",
      "1023 [D loss: 1.333407, acc.: 50.00%] [G loss: 0.090169] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1024 [D loss: 1.332365, acc.: 49.71%] [G loss: 0.096349] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1025 [D loss: 1.319065, acc.: 49.90%] [G loss: 0.092418] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1026 [D loss: 1.344942, acc.: 49.80%] [G loss: 0.104386] [Loss difference: 0.012, iterations with loss: 0]\n",
      "1027 [D loss: 1.323573, acc.: 49.80%] [G loss: 0.094631] [Loss difference: -0.010, iterations with loss: 1]\n",
      "1028 [D loss: 1.327355, acc.: 49.80%] [G loss: 0.094568] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1029 [D loss: 1.323232, acc.: 49.71%] [G loss: 0.096369] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1030 [D loss: 1.333433, acc.: 49.80%] [G loss: 0.094961] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1031 [D loss: 1.336791, acc.: 49.71%] [G loss: 0.096276] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1032 [D loss: 1.326938, acc.: 49.90%] [G loss: 0.101049] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1033 [D loss: 1.325974, acc.: 49.80%] [G loss: 0.095436] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1034 [D loss: 1.339641, acc.: 49.80%] [G loss: 0.091382] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1035 [D loss: 1.330174, acc.: 49.90%] [G loss: 0.094986] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1036 [D loss: 1.333174, acc.: 49.90%] [G loss: 0.095962] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1037 [D loss: 1.323429, acc.: 49.80%] [G loss: 0.094393] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1038 [D loss: 1.318588, acc.: 49.80%] [G loss: 0.095086] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1039 [D loss: 1.318778, acc.: 49.90%] [G loss: 0.098339] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1040 [D loss: 1.342041, acc.: 49.80%] [G loss: 0.099083] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1041 [D loss: 1.322626, acc.: 50.00%] [G loss: 0.095571] [Loss difference: -0.004, iterations with loss: 3]\n",
      "1042 [D loss: 1.333390, acc.: 49.71%] [G loss: 0.092402] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1043 [D loss: 1.316191, acc.: 49.80%] [G loss: 0.096095] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1044 [D loss: 1.336226, acc.: 49.90%] [G loss: 0.099463] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1045 [D loss: 1.323882, acc.: 49.90%] [G loss: 0.101328] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1046 [D loss: 1.308812, acc.: 49.90%] [G loss: 0.096133] [Loss difference: -0.005, iterations with loss: 3]\n",
      "1047 [D loss: 1.325353, acc.: 50.00%] [G loss: 0.097939] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1048 [D loss: 1.317259, acc.: 49.90%] [G loss: 0.095747] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1049 [D loss: 1.339107, acc.: 49.80%] [G loss: 0.096814] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1050 [D loss: 1.327347, acc.: 49.90%] [G loss: 0.099075] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1051 [D loss: 1.342911, acc.: 49.61%] [G loss: 0.091571] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1052 [D loss: 1.340848, acc.: 50.00%] [G loss: 0.096028] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1053 [D loss: 1.332307, acc.: 50.00%] [G loss: 0.095939] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1054 [D loss: 1.311987, acc.: 50.00%] [G loss: 0.103172] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1055 [D loss: 1.300713, acc.: 49.80%] [G loss: 0.096071] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1056 [D loss: 1.292441, acc.: 49.80%] [G loss: 0.100938] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1057 [D loss: 1.315675, acc.: 49.71%] [G loss: 0.095765] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1058 [D loss: 1.344532, acc.: 49.41%] [G loss: 0.099989] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1059 [D loss: 1.317238, acc.: 49.90%] [G loss: 0.099472] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1060 [D loss: 1.309753, acc.: 50.00%] [G loss: 0.094142] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1061 [D loss: 1.331451, acc.: 50.00%] [G loss: 0.097042] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1062 [D loss: 1.318018, acc.: 49.90%] [G loss: 0.098425] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1063 [D loss: 1.307980, acc.: 49.90%] [G loss: 0.097175] [Loss difference: -0.001, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064 [D loss: 1.321104, acc.: 49.90%] [G loss: 0.098592] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1065 [D loss: 1.310082, acc.: 49.80%] [G loss: 0.096566] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1066 [D loss: 1.311652, acc.: 49.71%] [G loss: 0.096302] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1067 [D loss: 1.310467, acc.: 49.80%] [G loss: 0.095596] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1068 [D loss: 1.315891, acc.: 49.90%] [G loss: 0.096978] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1069 [D loss: 1.321859, acc.: 49.90%] [G loss: 0.100444] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1070 [D loss: 1.309318, acc.: 50.00%] [G loss: 0.100788] [Loss difference: 0.000, iterations with loss: 2]\n",
      "1071 [D loss: 1.322211, acc.: 49.80%] [G loss: 0.097188] [Loss difference: -0.004, iterations with loss: 3]\n",
      "1072 [D loss: 1.312971, acc.: 49.80%] [G loss: 0.095243] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1073 [D loss: 1.326685, acc.: 49.71%] [G loss: 0.097088] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1074 [D loss: 1.324934, acc.: 49.80%] [G loss: 0.100210] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1075 [D loss: 1.312913, acc.: 49.90%] [G loss: 0.098089] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1076 [D loss: 1.326901, acc.: 49.61%] [G loss: 0.103463] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1077 [D loss: 1.324672, acc.: 49.90%] [G loss: 0.099916] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1078 [D loss: 1.326363, acc.: 49.71%] [G loss: 0.097492] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1079 [D loss: 1.341100, acc.: 49.71%] [G loss: 0.094969] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1080 [D loss: 1.319563, acc.: 49.90%] [G loss: 0.097605] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1081 [D loss: 1.315877, acc.: 49.90%] [G loss: 0.098617] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1082 [D loss: 1.333140, acc.: 49.90%] [G loss: 0.094546] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1083 [D loss: 1.313308, acc.: 50.00%] [G loss: 0.101728] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1084 [D loss: 1.330530, acc.: 49.80%] [G loss: 0.094539] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1085 [D loss: 1.324930, acc.: 49.90%] [G loss: 0.096119] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1086 [D loss: 1.325643, acc.: 50.00%] [G loss: 0.101695] [Loss difference: 0.006, iterations with loss: 1]\n",
      "1087 [D loss: 1.327179, acc.: 49.61%] [G loss: 0.095239] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1088 [D loss: 1.307658, acc.: 49.80%] [G loss: 0.099320] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1089 [D loss: 1.315029, acc.: 49.80%] [G loss: 0.100717] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1090 [D loss: 1.300824, acc.: 49.71%] [G loss: 0.100622] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1091 [D loss: 1.308393, acc.: 49.90%] [G loss: 0.097063] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1092 [D loss: 1.310556, acc.: 50.00%] [G loss: 0.102439] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1093 [D loss: 1.307960, acc.: 49.90%] [G loss: 0.096838] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1094 [D loss: 1.307680, acc.: 50.00%] [G loss: 0.102413] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1095 [D loss: 1.292690, acc.: 49.90%] [G loss: 0.103053] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1096 [D loss: 1.347078, acc.: 49.71%] [G loss: 0.099051] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1097 [D loss: 1.312387, acc.: 49.90%] [G loss: 0.099207] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1098 [D loss: 1.319580, acc.: 49.61%] [G loss: 0.095817] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1099 [D loss: 1.327187, acc.: 50.00%] [G loss: 0.099952] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1100 [D loss: 1.321082, acc.: 49.80%] [G loss: 0.097149] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1101 [D loss: 1.301420, acc.: 49.90%] [G loss: 0.095194] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1102 [D loss: 1.317826, acc.: 49.90%] [G loss: 0.099441] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1103 [D loss: 1.306924, acc.: 50.00%] [G loss: 0.096725] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1104 [D loss: 1.303806, acc.: 49.90%] [G loss: 0.103673] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1105 [D loss: 1.306998, acc.: 49.71%] [G loss: 0.094653] [Loss difference: -0.009, iterations with loss: 1]\n",
      "1106 [D loss: 1.333263, acc.: 49.80%] [G loss: 0.095795] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1107 [D loss: 1.342304, acc.: 49.71%] [G loss: 0.101608] [Loss difference: 0.006, iterations with loss: 1]\n",
      "1108 [D loss: 1.317418, acc.: 49.90%] [G loss: 0.100418] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1109 [D loss: 1.303468, acc.: 50.00%] [G loss: 0.098568] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1110 [D loss: 1.308579, acc.: 49.80%] [G loss: 0.102037] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1111 [D loss: 1.312939, acc.: 49.80%] [G loss: 0.098627] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1112 [D loss: 1.304924, acc.: 50.00%] [G loss: 0.103142] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1113 [D loss: 1.327769, acc.: 49.80%] [G loss: 0.107632] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1114 [D loss: 1.312141, acc.: 49.71%] [G loss: 0.099306] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1115 [D loss: 1.311740, acc.: 49.80%] [G loss: 0.098467] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1116 [D loss: 1.335961, acc.: 49.80%] [G loss: 0.096567] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1117 [D loss: 1.332099, acc.: 49.71%] [G loss: 0.105846] [Loss difference: 0.009, iterations with loss: 0]\n",
      "1118 [D loss: 1.311105, acc.: 49.71%] [G loss: 0.098536] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1119 [D loss: 1.316258, acc.: 49.80%] [G loss: 0.102269] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1120 [D loss: 1.303532, acc.: 49.90%] [G loss: 0.100703] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1121 [D loss: 1.295861, acc.: 50.00%] [G loss: 0.101555] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1122 [D loss: 1.329304, acc.: 49.80%] [G loss: 0.101117] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1123 [D loss: 1.313623, acc.: 49.80%] [G loss: 0.095700] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1124 [D loss: 1.319972, acc.: 49.90%] [G loss: 0.095536] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1125 [D loss: 1.325237, acc.: 49.80%] [G loss: 0.098476] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1126 [D loss: 1.316769, acc.: 49.80%] [G loss: 0.100065] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1127 [D loss: 1.317044, acc.: 50.00%] [G loss: 0.096895] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1128 [D loss: 1.312822, acc.: 49.71%] [G loss: 0.097845] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1129 [D loss: 1.320924, acc.: 49.90%] [G loss: 0.103146] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1130 [D loss: 1.315327, acc.: 49.90%] [G loss: 0.100441] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1131 [D loss: 1.311359, acc.: 49.71%] [G loss: 0.097951] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1132 [D loss: 1.304427, acc.: 49.80%] [G loss: 0.097441] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1133 [D loss: 1.302817, acc.: 49.90%] [G loss: 0.099860] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1134 [D loss: 1.313631, acc.: 49.90%] [G loss: 0.101441] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1135 [D loss: 1.312079, acc.: 49.80%] [G loss: 0.100698] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1136 [D loss: 1.314146, acc.: 49.71%] [G loss: 0.100811] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1137 [D loss: 1.316266, acc.: 49.71%] [G loss: 0.104302] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1138 [D loss: 1.319037, acc.: 49.80%] [G loss: 0.103971] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1139 [D loss: 1.307621, acc.: 50.00%] [G loss: 0.104543] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1140 [D loss: 1.313167, acc.: 49.90%] [G loss: 0.099632] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1141 [D loss: 1.311790, acc.: 49.61%] [G loss: 0.098191] [Loss difference: -0.001, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142 [D loss: 1.302219, acc.: 49.90%] [G loss: 0.098753] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1143 [D loss: 1.326603, acc.: 49.90%] [G loss: 0.094241] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1144 [D loss: 1.300882, acc.: 49.80%] [G loss: 0.102058] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1145 [D loss: 1.315322, acc.: 49.71%] [G loss: 0.100248] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1146 [D loss: 1.305415, acc.: 49.80%] [G loss: 0.098475] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1147 [D loss: 1.322407, acc.: 49.71%] [G loss: 0.104856] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1148 [D loss: 1.300654, acc.: 49.71%] [G loss: 0.101807] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1149 [D loss: 1.306474, acc.: 49.90%] [G loss: 0.104643] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1150 [D loss: 1.305174, acc.: 49.90%] [G loss: 0.100934] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1151 [D loss: 1.315195, acc.: 49.90%] [G loss: 0.101115] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1152 [D loss: 1.322810, acc.: 49.80%] [G loss: 0.105743] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1153 [D loss: 1.304127, acc.: 50.00%] [G loss: 0.099017] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1154 [D loss: 1.328081, acc.: 49.71%] [G loss: 0.100073] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1155 [D loss: 1.307118, acc.: 50.00%] [G loss: 0.110363] [Loss difference: 0.010, iterations with loss: 1]\n",
      "1156 [D loss: 1.299435, acc.: 49.80%] [G loss: 0.099672] [Loss difference: -0.011, iterations with loss: 2]\n",
      "1157 [D loss: 1.312985, acc.: 49.80%] [G loss: 0.107552] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1158 [D loss: 1.330220, acc.: 49.71%] [G loss: 0.102878] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1159 [D loss: 1.312801, acc.: 49.71%] [G loss: 0.100712] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1160 [D loss: 1.313733, acc.: 49.71%] [G loss: 0.106210] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1161 [D loss: 1.311537, acc.: 50.00%] [G loss: 0.101890] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1162 [D loss: 1.322683, acc.: 49.80%] [G loss: 0.098683] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1163 [D loss: 1.308271, acc.: 49.80%] [G loss: 0.099370] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1164 [D loss: 1.319656, acc.: 49.71%] [G loss: 0.100868] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1165 [D loss: 1.311789, acc.: 49.80%] [G loss: 0.096615] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1166 [D loss: 1.319496, acc.: 49.71%] [G loss: 0.104727] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1167 [D loss: 1.289287, acc.: 49.90%] [G loss: 0.104066] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1168 [D loss: 1.280366, acc.: 49.90%] [G loss: 0.104289] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1169 [D loss: 1.293887, acc.: 49.90%] [G loss: 0.103632] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1170 [D loss: 1.309006, acc.: 49.80%] [G loss: 0.102921] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1171 [D loss: 1.311403, acc.: 49.90%] [G loss: 0.101951] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1172 [D loss: 1.315968, acc.: 49.71%] [G loss: 0.105195] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1173 [D loss: 1.291933, acc.: 50.00%] [G loss: 0.099270] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1174 [D loss: 1.309890, acc.: 49.71%] [G loss: 0.102569] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1175 [D loss: 1.313597, acc.: 49.80%] [G loss: 0.097506] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1176 [D loss: 1.319398, acc.: 49.80%] [G loss: 0.099751] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1177 [D loss: 1.291191, acc.: 50.00%] [G loss: 0.106356] [Loss difference: 0.007, iterations with loss: 1]\n",
      "1178 [D loss: 1.304443, acc.: 50.00%] [G loss: 0.106951] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1179 [D loss: 1.291029, acc.: 49.90%] [G loss: 0.105110] [Loss difference: -0.002, iterations with loss: 3]\n",
      "1180 [D loss: 1.304728, acc.: 49.80%] [G loss: 0.109775] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1181 [D loss: 1.286339, acc.: 50.00%] [G loss: 0.102910] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1182 [D loss: 1.287610, acc.: 49.80%] [G loss: 0.098048] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1183 [D loss: 1.302933, acc.: 49.90%] [G loss: 0.102365] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1184 [D loss: 1.278524, acc.: 50.00%] [G loss: 0.099051] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1185 [D loss: 1.277139, acc.: 49.80%] [G loss: 0.101507] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1186 [D loss: 1.300255, acc.: 49.90%] [G loss: 0.106330] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1187 [D loss: 1.302909, acc.: 49.80%] [G loss: 0.106961] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1188 [D loss: 1.300743, acc.: 49.90%] [G loss: 0.105898] [Loss difference: -0.001, iterations with loss: 3]\n",
      "1189 [D loss: 1.309702, acc.: 49.51%] [G loss: 0.098221] [Loss difference: -0.008, iterations with loss: 0]\n",
      "1190 [D loss: 1.300159, acc.: 49.80%] [G loss: 0.102380] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1191 [D loss: 1.313946, acc.: 49.61%] [G loss: 0.105488] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1192 [D loss: 1.311772, acc.: 49.61%] [G loss: 0.099100] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1193 [D loss: 1.311073, acc.: 49.80%] [G loss: 0.099382] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1194 [D loss: 1.316736, acc.: 49.71%] [G loss: 0.108142] [Loss difference: 0.009, iterations with loss: 1]\n",
      "1195 [D loss: 1.296793, acc.: 50.00%] [G loss: 0.102027] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1196 [D loss: 1.288009, acc.: 49.90%] [G loss: 0.102363] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1197 [D loss: 1.310950, acc.: 50.00%] [G loss: 0.107360] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1198 [D loss: 1.298224, acc.: 49.71%] [G loss: 0.107547] [Loss difference: 0.000, iterations with loss: 2]\n",
      "1199 [D loss: 1.305489, acc.: 49.80%] [G loss: 0.104553] [Loss difference: -0.003, iterations with loss: 3]\n",
      "1200 [D loss: 1.300362, acc.: 49.71%] [G loss: 0.102115] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1201 [D loss: 1.317646, acc.: 49.71%] [G loss: 0.102606] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1202 [D loss: 1.298516, acc.: 49.90%] [G loss: 0.099113] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1203 [D loss: 1.292070, acc.: 50.00%] [G loss: 0.106702] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1204 [D loss: 1.284652, acc.: 49.90%] [G loss: 0.101601] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1205 [D loss: 1.303979, acc.: 49.90%] [G loss: 0.104434] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1206 [D loss: 1.312575, acc.: 49.61%] [G loss: 0.102459] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1207 [D loss: 1.285663, acc.: 49.80%] [G loss: 0.103864] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1208 [D loss: 1.289749, acc.: 49.90%] [G loss: 0.102559] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1209 [D loss: 1.307572, acc.: 49.80%] [G loss: 0.108375] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1210 [D loss: 1.308216, acc.: 49.90%] [G loss: 0.105158] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1211 [D loss: 1.294215, acc.: 49.61%] [G loss: 0.099450] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1212 [D loss: 1.314995, acc.: 49.80%] [G loss: 0.104375] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1213 [D loss: 1.284253, acc.: 49.71%] [G loss: 0.108449] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1214 [D loss: 1.280868, acc.: 49.80%] [G loss: 0.101824] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1215 [D loss: 1.310226, acc.: 49.61%] [G loss: 0.109114] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1216 [D loss: 1.286852, acc.: 49.90%] [G loss: 0.107532] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1217 [D loss: 1.325100, acc.: 49.51%] [G loss: 0.100743] [Loss difference: -0.007, iterations with loss: 0]\n",
      "1218 [D loss: 1.283039, acc.: 50.00%] [G loss: 0.100840] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1219 [D loss: 1.306974, acc.: 49.80%] [G loss: 0.102141] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1220 [D loss: 1.298252, acc.: 49.90%] [G loss: 0.100251] [Loss difference: -0.002, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221 [D loss: 1.286566, acc.: 50.00%] [G loss: 0.104013] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1222 [D loss: 1.305890, acc.: 49.90%] [G loss: 0.104011] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1223 [D loss: 1.274623, acc.: 49.90%] [G loss: 0.106094] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1224 [D loss: 1.289689, acc.: 49.90%] [G loss: 0.105906] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1225 [D loss: 1.286755, acc.: 49.90%] [G loss: 0.109547] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1226 [D loss: 1.288751, acc.: 50.00%] [G loss: 0.104251] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1227 [D loss: 1.291244, acc.: 50.00%] [G loss: 0.103018] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1228 [D loss: 1.279724, acc.: 50.00%] [G loss: 0.103389] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1229 [D loss: 1.271635, acc.: 49.80%] [G loss: 0.101819] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1230 [D loss: 1.278996, acc.: 49.90%] [G loss: 0.103514] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1231 [D loss: 1.281606, acc.: 49.90%] [G loss: 0.101660] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1232 [D loss: 1.287107, acc.: 49.80%] [G loss: 0.107704] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1233 [D loss: 1.288700, acc.: 49.80%] [G loss: 0.104737] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1234 [D loss: 1.311988, acc.: 49.61%] [G loss: 0.106684] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1235 [D loss: 1.299021, acc.: 49.80%] [G loss: 0.110340] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1236 [D loss: 1.285143, acc.: 49.80%] [G loss: 0.104130] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1237 [D loss: 1.275729, acc.: 49.71%] [G loss: 0.103115] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1238 [D loss: 1.291868, acc.: 49.90%] [G loss: 0.112022] [Loss difference: 0.009, iterations with loss: 0]\n",
      "1239 [D loss: 1.290551, acc.: 49.61%] [G loss: 0.104322] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1240 [D loss: 1.277674, acc.: 49.80%] [G loss: 0.106846] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1241 [D loss: 1.294325, acc.: 49.80%] [G loss: 0.108387] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1242 [D loss: 1.266780, acc.: 50.00%] [G loss: 0.106058] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1243 [D loss: 1.289732, acc.: 49.90%] [G loss: 0.105174] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1244 [D loss: 1.304595, acc.: 49.71%] [G loss: 0.107144] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1245 [D loss: 1.261666, acc.: 49.90%] [G loss: 0.112411] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1246 [D loss: 1.278957, acc.: 49.80%] [G loss: 0.106126] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1247 [D loss: 1.283822, acc.: 49.71%] [G loss: 0.105433] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1248 [D loss: 1.300929, acc.: 49.90%] [G loss: 0.105491] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1249 [D loss: 1.282296, acc.: 50.00%] [G loss: 0.103292] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1250 [D loss: 1.263362, acc.: 49.71%] [G loss: 0.104456] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1251 [D loss: 1.276933, acc.: 49.90%] [G loss: 0.107382] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1252 [D loss: 1.264164, acc.: 49.90%] [G loss: 0.104160] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1253 [D loss: 1.280370, acc.: 49.80%] [G loss: 0.104941] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1254 [D loss: 1.291441, acc.: 49.71%] [G loss: 0.114352] [Loss difference: 0.009, iterations with loss: 1]\n",
      "1255 [D loss: 1.254308, acc.: 50.00%] [G loss: 0.109152] [Loss difference: -0.005, iterations with loss: 2]\n",
      "1256 [D loss: 1.283146, acc.: 49.90%] [G loss: 0.103363] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1257 [D loss: 1.295085, acc.: 49.71%] [G loss: 0.107061] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1258 [D loss: 1.288486, acc.: 49.80%] [G loss: 0.111443] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1259 [D loss: 1.269214, acc.: 49.90%] [G loss: 0.105941] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1260 [D loss: 1.285859, acc.: 49.80%] [G loss: 0.104760] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1261 [D loss: 1.298369, acc.: 49.71%] [G loss: 0.104789] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1262 [D loss: 1.289065, acc.: 49.80%] [G loss: 0.102492] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1263 [D loss: 1.291300, acc.: 49.80%] [G loss: 0.104398] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1264 [D loss: 1.281095, acc.: 49.71%] [G loss: 0.103973] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1265 [D loss: 1.275512, acc.: 50.00%] [G loss: 0.109674] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1266 [D loss: 1.280028, acc.: 49.80%] [G loss: 0.106048] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1267 [D loss: 1.298146, acc.: 49.80%] [G loss: 0.105287] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1268 [D loss: 1.288041, acc.: 49.71%] [G loss: 0.109014] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1269 [D loss: 1.284722, acc.: 49.90%] [G loss: 0.111306] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1270 [D loss: 1.294746, acc.: 49.51%] [G loss: 0.107734] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1271 [D loss: 1.279544, acc.: 49.80%] [G loss: 0.103308] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1272 [D loss: 1.267524, acc.: 49.90%] [G loss: 0.103359] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1273 [D loss: 1.280806, acc.: 49.90%] [G loss: 0.106566] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1274 [D loss: 1.266415, acc.: 49.80%] [G loss: 0.109535] [Loss difference: 0.003, iterations with loss: 2]\n",
      "1275 [D loss: 1.274054, acc.: 50.00%] [G loss: 0.103809] [Loss difference: -0.006, iterations with loss: 3]\n",
      "1276 [D loss: 1.323997, acc.: 49.32%] [G loss: 0.102993] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1277 [D loss: 1.293655, acc.: 49.61%] [G loss: 0.103684] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1278 [D loss: 1.282819, acc.: 49.90%] [G loss: 0.107816] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1279 [D loss: 1.283264, acc.: 49.71%] [G loss: 0.103443] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1280 [D loss: 1.277180, acc.: 49.61%] [G loss: 0.109226] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1281 [D loss: 1.294865, acc.: 49.80%] [G loss: 0.105958] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1282 [D loss: 1.269599, acc.: 49.90%] [G loss: 0.111428] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1283 [D loss: 1.281528, acc.: 49.90%] [G loss: 0.107622] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1284 [D loss: 1.264439, acc.: 49.71%] [G loss: 0.110336] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1285 [D loss: 1.276868, acc.: 49.80%] [G loss: 0.103776] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1286 [D loss: 1.271585, acc.: 49.90%] [G loss: 0.110545] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1287 [D loss: 1.278724, acc.: 49.90%] [G loss: 0.115281] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1288 [D loss: 1.279158, acc.: 49.90%] [G loss: 0.110871] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1289 [D loss: 1.283388, acc.: 49.90%] [G loss: 0.105019] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1290 [D loss: 1.286491, acc.: 49.71%] [G loss: 0.103620] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1291 [D loss: 1.291626, acc.: 49.71%] [G loss: 0.106959] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1292 [D loss: 1.281634, acc.: 49.80%] [G loss: 0.102595] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1293 [D loss: 1.275635, acc.: 50.00%] [G loss: 0.106570] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1294 [D loss: 1.277218, acc.: 49.80%] [G loss: 0.106565] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1295 [D loss: 1.272037, acc.: 49.80%] [G loss: 0.106498] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1296 [D loss: 1.264774, acc.: 49.90%] [G loss: 0.111958] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1297 [D loss: 1.281104, acc.: 49.61%] [G loss: 0.110051] [Loss difference: -0.002, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298 [D loss: 1.268210, acc.: 49.90%] [G loss: 0.109502] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1299 [D loss: 1.270171, acc.: 49.90%] [G loss: 0.106334] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1300 [D loss: 1.289197, acc.: 49.51%] [G loss: 0.108771] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1301 [D loss: 1.303355, acc.: 49.61%] [G loss: 0.107507] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1302 [D loss: 1.269921, acc.: 50.00%] [G loss: 0.112245] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1303 [D loss: 1.273534, acc.: 49.90%] [G loss: 0.103618] [Loss difference: -0.009, iterations with loss: 1]\n",
      "1304 [D loss: 1.273869, acc.: 49.71%] [G loss: 0.102216] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1305 [D loss: 1.268105, acc.: 49.71%] [G loss: 0.107810] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1306 [D loss: 1.280370, acc.: 49.80%] [G loss: 0.107286] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1307 [D loss: 1.278411, acc.: 49.51%] [G loss: 0.115057] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1308 [D loss: 1.281348, acc.: 49.90%] [G loss: 0.112911] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1309 [D loss: 1.270881, acc.: 50.00%] [G loss: 0.112080] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1310 [D loss: 1.300594, acc.: 49.71%] [G loss: 0.105386] [Loss difference: -0.007, iterations with loss: 0]\n",
      "1311 [D loss: 1.287974, acc.: 49.80%] [G loss: 0.109373] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1312 [D loss: 1.267569, acc.: 49.90%] [G loss: 0.107297] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1313 [D loss: 1.280602, acc.: 49.80%] [G loss: 0.107691] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1314 [D loss: 1.278537, acc.: 49.80%] [G loss: 0.105139] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1315 [D loss: 1.280850, acc.: 49.90%] [G loss: 0.104872] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1316 [D loss: 1.261309, acc.: 49.90%] [G loss: 0.104305] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1317 [D loss: 1.270930, acc.: 49.80%] [G loss: 0.109905] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1318 [D loss: 1.266264, acc.: 49.80%] [G loss: 0.106683] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1319 [D loss: 1.285608, acc.: 49.80%] [G loss: 0.103041] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1320 [D loss: 1.287953, acc.: 49.61%] [G loss: 0.108565] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1321 [D loss: 1.283465, acc.: 49.51%] [G loss: 0.107195] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1322 [D loss: 1.263339, acc.: 49.80%] [G loss: 0.107710] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1323 [D loss: 1.275901, acc.: 49.61%] [G loss: 0.111642] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1324 [D loss: 1.258665, acc.: 49.90%] [G loss: 0.112960] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1325 [D loss: 1.269823, acc.: 49.71%] [G loss: 0.106445] [Loss difference: -0.007, iterations with loss: 3]\n",
      "1326 [D loss: 1.267822, acc.: 49.80%] [G loss: 0.108895] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1327 [D loss: 1.262810, acc.: 49.90%] [G loss: 0.114370] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1328 [D loss: 1.268643, acc.: 49.80%] [G loss: 0.109192] [Loss difference: -0.005, iterations with loss: 2]\n",
      "1329 [D loss: 1.275647, acc.: 49.80%] [G loss: 0.111822] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1330 [D loss: 1.274756, acc.: 49.90%] [G loss: 0.113719] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1331 [D loss: 1.274881, acc.: 49.61%] [G loss: 0.113897] [Loss difference: 0.000, iterations with loss: 2]\n",
      "1332 [D loss: 1.245961, acc.: 50.00%] [G loss: 0.103674] [Loss difference: -0.010, iterations with loss: 3]\n",
      "1333 [D loss: 1.268050, acc.: 49.80%] [G loss: 0.104939] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1334 [D loss: 1.264200, acc.: 49.51%] [G loss: 0.117897] [Loss difference: 0.013, iterations with loss: 1]\n",
      "1335 [D loss: 1.264609, acc.: 49.90%] [G loss: 0.110886] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1336 [D loss: 1.262494, acc.: 50.00%] [G loss: 0.115971] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1337 [D loss: 1.268079, acc.: 49.80%] [G loss: 0.114230] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1338 [D loss: 1.267751, acc.: 50.00%] [G loss: 0.111503] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1339 [D loss: 1.272824, acc.: 49.90%] [G loss: 0.107829] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1340 [D loss: 1.275683, acc.: 49.61%] [G loss: 0.106509] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1341 [D loss: 1.255405, acc.: 50.00%] [G loss: 0.106991] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1342 [D loss: 1.277853, acc.: 49.80%] [G loss: 0.111596] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1343 [D loss: 1.269830, acc.: 49.80%] [G loss: 0.108360] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1344 [D loss: 1.280702, acc.: 49.71%] [G loss: 0.111837] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1345 [D loss: 1.272476, acc.: 49.80%] [G loss: 0.111866] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1346 [D loss: 1.266285, acc.: 49.80%] [G loss: 0.107432] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1347 [D loss: 1.270817, acc.: 49.90%] [G loss: 0.104835] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1348 [D loss: 1.264633, acc.: 49.90%] [G loss: 0.106555] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1349 [D loss: 1.254256, acc.: 50.00%] [G loss: 0.117107] [Loss difference: 0.011, iterations with loss: 1]\n",
      "1350 [D loss: 1.269197, acc.: 49.90%] [G loss: 0.112447] [Loss difference: -0.005, iterations with loss: 2]\n",
      "1351 [D loss: 1.252033, acc.: 49.90%] [G loss: 0.110698] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1352 [D loss: 1.272571, acc.: 49.61%] [G loss: 0.112449] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1353 [D loss: 1.265572, acc.: 49.90%] [G loss: 0.109119] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1354 [D loss: 1.284260, acc.: 49.90%] [G loss: 0.112515] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1355 [D loss: 1.282908, acc.: 49.80%] [G loss: 0.107969] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1356 [D loss: 1.296452, acc.: 49.71%] [G loss: 0.110840] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1357 [D loss: 1.265665, acc.: 50.00%] [G loss: 0.109371] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1358 [D loss: 1.269413, acc.: 49.80%] [G loss: 0.112896] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1359 [D loss: 1.259801, acc.: 49.80%] [G loss: 0.108914] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1360 [D loss: 1.272987, acc.: 49.90%] [G loss: 0.110653] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1361 [D loss: 1.261239, acc.: 49.80%] [G loss: 0.110005] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1362 [D loss: 1.255572, acc.: 50.00%] [G loss: 0.108417] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1363 [D loss: 1.261964, acc.: 50.00%] [G loss: 0.106962] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1364 [D loss: 1.256849, acc.: 49.90%] [G loss: 0.115227] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1365 [D loss: 1.257316, acc.: 49.90%] [G loss: 0.112098] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1366 [D loss: 1.275251, acc.: 49.61%] [G loss: 0.109396] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1367 [D loss: 1.262735, acc.: 50.00%] [G loss: 0.112337] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1368 [D loss: 1.278311, acc.: 49.61%] [G loss: 0.112819] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1369 [D loss: 1.263113, acc.: 49.80%] [G loss: 0.114562] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1370 [D loss: 1.250408, acc.: 49.90%] [G loss: 0.115665] [Loss difference: 0.001, iterations with loss: 3]\n",
      "1371 [D loss: 1.264391, acc.: 49.90%] [G loss: 0.110400] [Loss difference: -0.005, iterations with loss: 4]\n",
      "1372 [D loss: 1.274839, acc.: 49.90%] [G loss: 0.109475] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1373 [D loss: 1.280524, acc.: 49.80%] [G loss: 0.110038] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1374 [D loss: 1.260042, acc.: 49.80%] [G loss: 0.108453] [Loss difference: -0.002, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375 [D loss: 1.248951, acc.: 49.90%] [G loss: 0.113799] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1376 [D loss: 1.251074, acc.: 49.90%] [G loss: 0.112828] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1377 [D loss: 1.280067, acc.: 49.61%] [G loss: 0.115501] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1378 [D loss: 1.283376, acc.: 49.61%] [G loss: 0.107196] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1379 [D loss: 1.264795, acc.: 50.00%] [G loss: 0.113118] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1380 [D loss: 1.268115, acc.: 49.80%] [G loss: 0.111968] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1381 [D loss: 1.242100, acc.: 49.80%] [G loss: 0.109706] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1382 [D loss: 1.258175, acc.: 49.90%] [G loss: 0.114308] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1383 [D loss: 1.259114, acc.: 49.90%] [G loss: 0.112274] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1384 [D loss: 1.245592, acc.: 49.71%] [G loss: 0.115287] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1385 [D loss: 1.252130, acc.: 49.80%] [G loss: 0.115564] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1386 [D loss: 1.256566, acc.: 49.90%] [G loss: 0.110020] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1387 [D loss: 1.270633, acc.: 49.80%] [G loss: 0.110236] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1388 [D loss: 1.263914, acc.: 49.71%] [G loss: 0.114334] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1389 [D loss: 1.258940, acc.: 49.90%] [G loss: 0.111582] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1390 [D loss: 1.266535, acc.: 49.90%] [G loss: 0.107824] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1391 [D loss: 1.268671, acc.: 49.90%] [G loss: 0.114916] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1392 [D loss: 1.265873, acc.: 49.90%] [G loss: 0.118909] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1393 [D loss: 1.262174, acc.: 49.71%] [G loss: 0.111251] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1394 [D loss: 1.265773, acc.: 49.80%] [G loss: 0.114568] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1395 [D loss: 1.292175, acc.: 50.00%] [G loss: 0.117410] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1396 [D loss: 1.270062, acc.: 49.61%] [G loss: 0.109169] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1397 [D loss: 1.273519, acc.: 49.71%] [G loss: 0.111155] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1398 [D loss: 1.270738, acc.: 49.90%] [G loss: 0.107210] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1399 [D loss: 1.250949, acc.: 50.00%] [G loss: 0.113399] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1400 [D loss: 1.244433, acc.: 49.80%] [G loss: 0.113803] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1401 [D loss: 1.266272, acc.: 49.71%] [G loss: 0.111024] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1402 [D loss: 1.254571, acc.: 49.90%] [G loss: 0.116650] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1403 [D loss: 1.250137, acc.: 49.61%] [G loss: 0.112269] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1404 [D loss: 1.263546, acc.: 49.80%] [G loss: 0.108770] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1405 [D loss: 1.275189, acc.: 50.00%] [G loss: 0.111070] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1406 [D loss: 1.246992, acc.: 49.90%] [G loss: 0.115984] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1407 [D loss: 1.255482, acc.: 49.80%] [G loss: 0.113976] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1408 [D loss: 1.261992, acc.: 49.90%] [G loss: 0.108646] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1409 [D loss: 1.247875, acc.: 49.90%] [G loss: 0.112140] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1410 [D loss: 1.250009, acc.: 49.90%] [G loss: 0.113746] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1411 [D loss: 1.284452, acc.: 49.51%] [G loss: 0.115417] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1412 [D loss: 1.279354, acc.: 49.61%] [G loss: 0.111175] [Loss difference: -0.004, iterations with loss: 3]\n",
      "1413 [D loss: 1.261508, acc.: 49.90%] [G loss: 0.109491] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1414 [D loss: 1.247725, acc.: 49.90%] [G loss: 0.108705] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1415 [D loss: 1.273643, acc.: 49.61%] [G loss: 0.114230] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1416 [D loss: 1.248848, acc.: 49.80%] [G loss: 0.124589] [Loss difference: 0.010, iterations with loss: 1]\n",
      "1417 [D loss: 1.268491, acc.: 49.80%] [G loss: 0.108525] [Loss difference: -0.016, iterations with loss: 2]\n",
      "1418 [D loss: 1.254720, acc.: 49.61%] [G loss: 0.108279] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1419 [D loss: 1.255185, acc.: 49.80%] [G loss: 0.109507] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1420 [D loss: 1.264613, acc.: 49.80%] [G loss: 0.111127] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1421 [D loss: 1.259079, acc.: 49.80%] [G loss: 0.119097] [Loss difference: 0.008, iterations with loss: 2]\n",
      "1422 [D loss: 1.282887, acc.: 49.80%] [G loss: 0.111470] [Loss difference: -0.008, iterations with loss: 3]\n",
      "1423 [D loss: 1.276049, acc.: 49.71%] [G loss: 0.111753] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1424 [D loss: 1.261634, acc.: 49.80%] [G loss: 0.115010] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1425 [D loss: 1.237050, acc.: 49.90%] [G loss: 0.113843] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1426 [D loss: 1.264847, acc.: 49.80%] [G loss: 0.114301] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1427 [D loss: 1.262133, acc.: 49.71%] [G loss: 0.117923] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1428 [D loss: 1.261466, acc.: 49.80%] [G loss: 0.117823] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1429 [D loss: 1.295043, acc.: 49.41%] [G loss: 0.113583] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1430 [D loss: 1.262209, acc.: 49.51%] [G loss: 0.114888] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1431 [D loss: 1.258489, acc.: 49.90%] [G loss: 0.113502] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1432 [D loss: 1.266936, acc.: 50.00%] [G loss: 0.118377] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1433 [D loss: 1.242516, acc.: 49.80%] [G loss: 0.114488] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1434 [D loss: 1.250622, acc.: 49.90%] [G loss: 0.110830] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1435 [D loss: 1.247531, acc.: 49.90%] [G loss: 0.110328] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1436 [D loss: 1.254654, acc.: 49.71%] [G loss: 0.110871] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1437 [D loss: 1.256485, acc.: 50.00%] [G loss: 0.115655] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1438 [D loss: 1.244053, acc.: 50.00%] [G loss: 0.117218] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1439 [D loss: 1.255656, acc.: 49.61%] [G loss: 0.113314] [Loss difference: -0.004, iterations with loss: 3]\n",
      "1440 [D loss: 1.264776, acc.: 49.61%] [G loss: 0.113126] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1441 [D loss: 1.234071, acc.: 49.90%] [G loss: 0.116167] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1442 [D loss: 1.264542, acc.: 49.80%] [G loss: 0.114112] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1443 [D loss: 1.246461, acc.: 49.71%] [G loss: 0.114806] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1444 [D loss: 1.234437, acc.: 49.90%] [G loss: 0.109299] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1445 [D loss: 1.243221, acc.: 50.00%] [G loss: 0.119803] [Loss difference: 0.011, iterations with loss: 0]\n",
      "1446 [D loss: 1.248788, acc.: 49.71%] [G loss: 0.116544] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1447 [D loss: 1.235290, acc.: 49.90%] [G loss: 0.115186] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1448 [D loss: 1.258973, acc.: 49.80%] [G loss: 0.113806] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1449 [D loss: 1.265269, acc.: 49.61%] [G loss: 0.109044] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1450 [D loss: 1.247817, acc.: 49.80%] [G loss: 0.114502] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1451 [D loss: 1.261334, acc.: 49.61%] [G loss: 0.112905] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1452 [D loss: 1.264014, acc.: 49.71%] [G loss: 0.113554] [Loss difference: 0.001, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453 [D loss: 1.255221, acc.: 49.90%] [G loss: 0.115903] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1454 [D loss: 1.248718, acc.: 49.80%] [G loss: 0.114959] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1455 [D loss: 1.277795, acc.: 49.71%] [G loss: 0.113788] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1456 [D loss: 1.257536, acc.: 49.71%] [G loss: 0.118014] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1457 [D loss: 1.246552, acc.: 49.90%] [G loss: 0.110998] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1458 [D loss: 1.247085, acc.: 49.80%] [G loss: 0.112947] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1459 [D loss: 1.245692, acc.: 49.90%] [G loss: 0.118116] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1460 [D loss: 1.234428, acc.: 49.80%] [G loss: 0.119702] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1461 [D loss: 1.251744, acc.: 49.71%] [G loss: 0.113930] [Loss difference: -0.006, iterations with loss: 3]\n",
      "1462 [D loss: 1.235600, acc.: 49.80%] [G loss: 0.112298] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1463 [D loss: 1.260901, acc.: 49.80%] [G loss: 0.111969] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1464 [D loss: 1.243360, acc.: 49.80%] [G loss: 0.113538] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1465 [D loss: 1.255324, acc.: 49.80%] [G loss: 0.116964] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1466 [D loss: 1.278218, acc.: 49.61%] [G loss: 0.110112] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1467 [D loss: 1.251844, acc.: 49.80%] [G loss: 0.112166] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1468 [D loss: 1.237946, acc.: 49.80%] [G loss: 0.113196] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1469 [D loss: 1.240125, acc.: 49.80%] [G loss: 0.111582] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1470 [D loss: 1.248204, acc.: 49.80%] [G loss: 0.121057] [Loss difference: 0.009, iterations with loss: 0]\n",
      "1471 [D loss: 1.245185, acc.: 49.80%] [G loss: 0.112278] [Loss difference: -0.009, iterations with loss: 1]\n",
      "1472 [D loss: 1.250304, acc.: 49.80%] [G loss: 0.112292] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1473 [D loss: 1.243505, acc.: 49.80%] [G loss: 0.115959] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1474 [D loss: 1.243002, acc.: 49.90%] [G loss: 0.117758] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1475 [D loss: 1.244526, acc.: 49.80%] [G loss: 0.111828] [Loss difference: -0.006, iterations with loss: 3]\n",
      "1476 [D loss: 1.235737, acc.: 49.90%] [G loss: 0.112300] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1477 [D loss: 1.239140, acc.: 49.61%] [G loss: 0.117073] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1478 [D loss: 1.233271, acc.: 49.61%] [G loss: 0.119321] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1479 [D loss: 1.251581, acc.: 49.71%] [G loss: 0.114965] [Loss difference: -0.004, iterations with loss: 3]\n",
      "1480 [D loss: 1.238364, acc.: 49.71%] [G loss: 0.118904] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1481 [D loss: 1.252176, acc.: 49.80%] [G loss: 0.113840] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1482 [D loss: 1.235470, acc.: 49.90%] [G loss: 0.122159] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1483 [D loss: 1.244739, acc.: 49.61%] [G loss: 0.114143] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1484 [D loss: 1.235540, acc.: 49.80%] [G loss: 0.116305] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1485 [D loss: 1.236235, acc.: 49.80%] [G loss: 0.119214] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1486 [D loss: 1.250048, acc.: 49.80%] [G loss: 0.118929] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1487 [D loss: 1.255406, acc.: 49.80%] [G loss: 0.118900] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1488 [D loss: 1.281470, acc.: 49.61%] [G loss: 0.114740] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1489 [D loss: 1.239428, acc.: 49.90%] [G loss: 0.112776] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1490 [D loss: 1.247375, acc.: 49.90%] [G loss: 0.116837] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1491 [D loss: 1.245026, acc.: 49.71%] [G loss: 0.115372] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1492 [D loss: 1.249175, acc.: 49.71%] [G loss: 0.115945] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1493 [D loss: 1.236767, acc.: 50.00%] [G loss: 0.113169] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1494 [D loss: 1.246320, acc.: 49.90%] [G loss: 0.119721] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1495 [D loss: 1.237144, acc.: 49.90%] [G loss: 0.118614] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1496 [D loss: 1.272158, acc.: 49.61%] [G loss: 0.121454] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1497 [D loss: 1.253699, acc.: 49.80%] [G loss: 0.117594] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1498 [D loss: 1.251342, acc.: 49.80%] [G loss: 0.116986] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1499 [D loss: 1.253265, acc.: 49.80%] [G loss: 0.114102] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1500 [D loss: 1.263619, acc.: 49.22%] [G loss: 0.120270] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1501 [D loss: 1.252910, acc.: 49.80%] [G loss: 0.121667] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1502 [D loss: 1.241769, acc.: 49.80%] [G loss: 0.113850] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1503 [D loss: 1.254277, acc.: 49.90%] [G loss: 0.114939] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1504 [D loss: 1.233411, acc.: 49.71%] [G loss: 0.116191] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1505 [D loss: 1.240700, acc.: 49.80%] [G loss: 0.113449] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1506 [D loss: 1.243023, acc.: 49.90%] [G loss: 0.113169] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1507 [D loss: 1.230109, acc.: 50.00%] [G loss: 0.115885] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1508 [D loss: 1.233356, acc.: 49.71%] [G loss: 0.114256] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1509 [D loss: 1.256521, acc.: 49.61%] [G loss: 0.118677] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1510 [D loss: 1.222953, acc.: 49.80%] [G loss: 0.116112] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1511 [D loss: 1.258625, acc.: 49.90%] [G loss: 0.113128] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1512 [D loss: 1.242633, acc.: 49.80%] [G loss: 0.116316] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1513 [D loss: 1.241894, acc.: 49.51%] [G loss: 0.115287] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1514 [D loss: 1.239086, acc.: 49.90%] [G loss: 0.117686] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1515 [D loss: 1.228093, acc.: 49.90%] [G loss: 0.115592] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1516 [D loss: 1.226712, acc.: 49.80%] [G loss: 0.120749] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1517 [D loss: 1.222427, acc.: 50.00%] [G loss: 0.121016] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1518 [D loss: 1.239209, acc.: 49.80%] [G loss: 0.117880] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1519 [D loss: 1.234231, acc.: 49.80%] [G loss: 0.127626] [Loss difference: 0.010, iterations with loss: 0]\n",
      "1520 [D loss: 1.245766, acc.: 49.51%] [G loss: 0.117003] [Loss difference: -0.011, iterations with loss: 1]\n",
      "1521 [D loss: 1.232637, acc.: 49.90%] [G loss: 0.116076] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1522 [D loss: 1.255152, acc.: 49.80%] [G loss: 0.115589] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1523 [D loss: 1.220470, acc.: 49.90%] [G loss: 0.113639] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1524 [D loss: 1.250922, acc.: 49.61%] [G loss: 0.117261] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1525 [D loss: 1.241793, acc.: 49.71%] [G loss: 0.117853] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1526 [D loss: 1.239889, acc.: 50.00%] [G loss: 0.115283] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1527 [D loss: 1.239743, acc.: 49.90%] [G loss: 0.117500] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1528 [D loss: 1.232682, acc.: 49.80%] [G loss: 0.116871] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1529 [D loss: 1.231034, acc.: 49.90%] [G loss: 0.119740] [Loss difference: 0.003, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530 [D loss: 1.238538, acc.: 49.61%] [G loss: 0.121769] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1531 [D loss: 1.234350, acc.: 49.61%] [G loss: 0.118759] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1532 [D loss: 1.232586, acc.: 49.90%] [G loss: 0.122777] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1533 [D loss: 1.230551, acc.: 50.00%] [G loss: 0.117661] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1534 [D loss: 1.243353, acc.: 49.80%] [G loss: 0.112587] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1535 [D loss: 1.253542, acc.: 49.41%] [G loss: 0.118055] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1536 [D loss: 1.235568, acc.: 49.80%] [G loss: 0.117995] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1537 [D loss: 1.245685, acc.: 49.80%] [G loss: 0.116958] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1538 [D loss: 1.229889, acc.: 49.80%] [G loss: 0.121648] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1539 [D loss: 1.245206, acc.: 49.80%] [G loss: 0.121828] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1540 [D loss: 1.249385, acc.: 49.90%] [G loss: 0.119225] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1541 [D loss: 1.254923, acc.: 49.80%] [G loss: 0.116383] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1542 [D loss: 1.260211, acc.: 49.51%] [G loss: 0.115485] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1543 [D loss: 1.246942, acc.: 49.90%] [G loss: 0.121116] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1544 [D loss: 1.235935, acc.: 49.80%] [G loss: 0.117402] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1545 [D loss: 1.247459, acc.: 49.71%] [G loss: 0.112845] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1546 [D loss: 1.234640, acc.: 49.90%] [G loss: 0.118211] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1547 [D loss: 1.234875, acc.: 49.80%] [G loss: 0.127010] [Loss difference: 0.009, iterations with loss: 1]\n",
      "1548 [D loss: 1.233022, acc.: 49.61%] [G loss: 0.113761] [Loss difference: -0.013, iterations with loss: 2]\n",
      "1549 [D loss: 1.230155, acc.: 49.90%] [G loss: 0.120238] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1550 [D loss: 1.236088, acc.: 50.00%] [G loss: 0.124677] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1551 [D loss: 1.228389, acc.: 49.90%] [G loss: 0.120301] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1552 [D loss: 1.231367, acc.: 49.71%] [G loss: 0.130446] [Loss difference: 0.010, iterations with loss: 0]\n",
      "1553 [D loss: 1.231811, acc.: 49.71%] [G loss: 0.129673] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1554 [D loss: 1.233877, acc.: 49.71%] [G loss: 0.119314] [Loss difference: -0.010, iterations with loss: 0]\n",
      "1555 [D loss: 1.224043, acc.: 49.90%] [G loss: 0.116347] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1556 [D loss: 1.236501, acc.: 49.80%] [G loss: 0.117066] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1557 [D loss: 1.233308, acc.: 49.80%] [G loss: 0.124365] [Loss difference: 0.007, iterations with loss: 1]\n",
      "1558 [D loss: 1.224226, acc.: 49.80%] [G loss: 0.117418] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1559 [D loss: 1.262539, acc.: 49.71%] [G loss: 0.115406] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1560 [D loss: 1.239094, acc.: 49.71%] [G loss: 0.118794] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1561 [D loss: 1.225718, acc.: 49.71%] [G loss: 0.118542] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1562 [D loss: 1.231925, acc.: 50.00%] [G loss: 0.116378] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1563 [D loss: 1.235755, acc.: 49.90%] [G loss: 0.120081] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1564 [D loss: 1.241650, acc.: 49.80%] [G loss: 0.121466] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1565 [D loss: 1.214595, acc.: 49.90%] [G loss: 0.120316] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1566 [D loss: 1.221168, acc.: 49.90%] [G loss: 0.123671] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1567 [D loss: 1.238835, acc.: 49.71%] [G loss: 0.117739] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1568 [D loss: 1.246138, acc.: 49.71%] [G loss: 0.122603] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1569 [D loss: 1.225356, acc.: 50.00%] [G loss: 0.124239] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1570 [D loss: 1.229583, acc.: 49.90%] [G loss: 0.122930] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1571 [D loss: 1.229880, acc.: 49.90%] [G loss: 0.118210] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1572 [D loss: 1.242527, acc.: 49.71%] [G loss: 0.118103] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1573 [D loss: 1.239324, acc.: 50.00%] [G loss: 0.120663] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1574 [D loss: 1.222609, acc.: 49.80%] [G loss: 0.123279] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1575 [D loss: 1.239998, acc.: 49.80%] [G loss: 0.125052] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1576 [D loss: 1.221379, acc.: 50.00%] [G loss: 0.124939] [Loss difference: -0.000, iterations with loss: 3]\n",
      "1577 [D loss: 1.245129, acc.: 50.00%] [G loss: 0.119243] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1578 [D loss: 1.222897, acc.: 50.00%] [G loss: 0.123643] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1579 [D loss: 1.232355, acc.: 49.71%] [G loss: 0.118694] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1580 [D loss: 1.218071, acc.: 49.90%] [G loss: 0.124031] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1581 [D loss: 1.216826, acc.: 49.71%] [G loss: 0.125194] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1582 [D loss: 1.242448, acc.: 49.61%] [G loss: 0.121127] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1583 [D loss: 1.226144, acc.: 50.00%] [G loss: 0.126413] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1584 [D loss: 1.228330, acc.: 49.80%] [G loss: 0.120869] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1585 [D loss: 1.221555, acc.: 49.90%] [G loss: 0.116666] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1586 [D loss: 1.248452, acc.: 49.80%] [G loss: 0.113607] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1587 [D loss: 1.235281, acc.: 49.71%] [G loss: 0.123016] [Loss difference: 0.009, iterations with loss: 0]\n",
      "1588 [D loss: 1.241801, acc.: 49.80%] [G loss: 0.124926] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1589 [D loss: 1.229416, acc.: 50.00%] [G loss: 0.126944] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1590 [D loss: 1.220865, acc.: 49.71%] [G loss: 0.124168] [Loss difference: -0.003, iterations with loss: 3]\n",
      "1591 [D loss: 1.220533, acc.: 49.80%] [G loss: 0.123754] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1592 [D loss: 1.238948, acc.: 49.71%] [G loss: 0.123365] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1593 [D loss: 1.222218, acc.: 49.80%] [G loss: 0.118712] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1594 [D loss: 1.255593, acc.: 49.51%] [G loss: 0.121202] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1595 [D loss: 1.214921, acc.: 49.80%] [G loss: 0.118083] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1596 [D loss: 1.225071, acc.: 50.00%] [G loss: 0.114648] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1597 [D loss: 1.212519, acc.: 49.90%] [G loss: 0.123637] [Loss difference: 0.009, iterations with loss: 0]\n",
      "1598 [D loss: 1.258657, acc.: 49.61%] [G loss: 0.119190] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1599 [D loss: 1.236661, acc.: 49.90%] [G loss: 0.123076] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1600 [D loss: 1.227931, acc.: 49.90%] [G loss: 0.120543] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1601 [D loss: 1.218449, acc.: 49.80%] [G loss: 0.126104] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1602 [D loss: 1.221766, acc.: 50.00%] [G loss: 0.121063] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1603 [D loss: 1.217152, acc.: 49.80%] [G loss: 0.128662] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1604 [D loss: 1.220822, acc.: 50.00%] [G loss: 0.122214] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1605 [D loss: 1.242012, acc.: 49.51%] [G loss: 0.119614] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1606 [D loss: 1.238354, acc.: 49.71%] [G loss: 0.119445] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1607 [D loss: 1.233006, acc.: 49.90%] [G loss: 0.123504] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1608 [D loss: 1.223751, acc.: 50.00%] [G loss: 0.123847] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1609 [D loss: 1.235792, acc.: 49.61%] [G loss: 0.119532] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1610 [D loss: 1.241682, acc.: 49.80%] [G loss: 0.123381] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1611 [D loss: 1.216774, acc.: 50.00%] [G loss: 0.121622] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1612 [D loss: 1.205508, acc.: 49.71%] [G loss: 0.124355] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1613 [D loss: 1.240061, acc.: 49.61%] [G loss: 0.121574] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1614 [D loss: 1.236020, acc.: 49.61%] [G loss: 0.119945] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1615 [D loss: 1.221799, acc.: 49.61%] [G loss: 0.121877] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1616 [D loss: 1.238446, acc.: 49.71%] [G loss: 0.122821] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1617 [D loss: 1.241375, acc.: 49.80%] [G loss: 0.124919] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1618 [D loss: 1.225616, acc.: 49.80%] [G loss: 0.120084] [Loss difference: -0.005, iterations with loss: 3]\n",
      "1619 [D loss: 1.231064, acc.: 49.80%] [G loss: 0.123060] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1620 [D loss: 1.225894, acc.: 49.80%] [G loss: 0.126177] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1621 [D loss: 1.227451, acc.: 49.61%] [G loss: 0.127228] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1622 [D loss: 1.220064, acc.: 49.90%] [G loss: 0.125160] [Loss difference: -0.002, iterations with loss: 3]\n",
      "1623 [D loss: 1.217426, acc.: 49.90%] [G loss: 0.123163] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1624 [D loss: 1.226534, acc.: 49.90%] [G loss: 0.121297] [Loss difference: -0.002, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625 [D loss: 1.217297, acc.: 49.80%] [G loss: 0.119002] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1626 [D loss: 1.223226, acc.: 49.80%] [G loss: 0.124953] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1627 [D loss: 1.232794, acc.: 49.80%] [G loss: 0.124670] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1628 [D loss: 1.225211, acc.: 49.90%] [G loss: 0.120196] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1629 [D loss: 1.224899, acc.: 50.00%] [G loss: 0.121771] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1630 [D loss: 1.217665, acc.: 49.90%] [G loss: 0.126538] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1631 [D loss: 1.211876, acc.: 49.80%] [G loss: 0.125528] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1632 [D loss: 1.202053, acc.: 49.80%] [G loss: 0.128643] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1633 [D loss: 1.207520, acc.: 50.00%] [G loss: 0.126751] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1634 [D loss: 1.221543, acc.: 49.90%] [G loss: 0.127980] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1635 [D loss: 1.224322, acc.: 49.80%] [G loss: 0.127461] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1636 [D loss: 1.213705, acc.: 49.61%] [G loss: 0.125958] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1637 [D loss: 1.210827, acc.: 49.90%] [G loss: 0.120212] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1638 [D loss: 1.227519, acc.: 49.80%] [G loss: 0.123711] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1639 [D loss: 1.226429, acc.: 49.71%] [G loss: 0.115997] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1640 [D loss: 1.213464, acc.: 50.00%] [G loss: 0.121072] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1641 [D loss: 1.218299, acc.: 49.80%] [G loss: 0.124391] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1642 [D loss: 1.232164, acc.: 49.51%] [G loss: 0.123902] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1643 [D loss: 1.229105, acc.: 49.80%] [G loss: 0.124938] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1644 [D loss: 1.219689, acc.: 49.80%] [G loss: 0.132393] [Loss difference: 0.007, iterations with loss: 1]\n",
      "1645 [D loss: 1.199288, acc.: 49.90%] [G loss: 0.127267] [Loss difference: -0.005, iterations with loss: 2]\n",
      "1646 [D loss: 1.206784, acc.: 49.90%] [G loss: 0.125072] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1647 [D loss: 1.214456, acc.: 49.80%] [G loss: 0.128110] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1648 [D loss: 1.218314, acc.: 49.71%] [G loss: 0.123812] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1649 [D loss: 1.208464, acc.: 50.00%] [G loss: 0.126115] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1650 [D loss: 1.231441, acc.: 49.71%] [G loss: 0.125286] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1651 [D loss: 1.221506, acc.: 49.61%] [G loss: 0.121516] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1652 [D loss: 1.218624, acc.: 49.71%] [G loss: 0.127497] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1653 [D loss: 1.226270, acc.: 49.80%] [G loss: 0.123122] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1654 [D loss: 1.213595, acc.: 49.71%] [G loss: 0.120427] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1655 [D loss: 1.205991, acc.: 49.80%] [G loss: 0.124489] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1656 [D loss: 1.221670, acc.: 49.80%] [G loss: 0.125688] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1657 [D loss: 1.218042, acc.: 49.90%] [G loss: 0.124783] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1658 [D loss: 1.200377, acc.: 49.80%] [G loss: 0.125531] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1659 [D loss: 1.234199, acc.: 49.71%] [G loss: 0.128384] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1660 [D loss: 1.218514, acc.: 49.90%] [G loss: 0.127596] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1661 [D loss: 1.217173, acc.: 50.00%] [G loss: 0.125252] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1662 [D loss: 1.223469, acc.: 49.71%] [G loss: 0.127845] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1663 [D loss: 1.209736, acc.: 50.00%] [G loss: 0.126524] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1664 [D loss: 1.215626, acc.: 49.71%] [G loss: 0.130160] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1665 [D loss: 1.229479, acc.: 49.51%] [G loss: 0.122824] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1666 [D loss: 1.226245, acc.: 49.90%] [G loss: 0.128809] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1667 [D loss: 1.212656, acc.: 50.00%] [G loss: 0.127003] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1668 [D loss: 1.233591, acc.: 49.80%] [G loss: 0.123629] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1669 [D loss: 1.220955, acc.: 49.61%] [G loss: 0.121953] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1670 [D loss: 1.217245, acc.: 49.90%] [G loss: 0.122315] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1671 [D loss: 1.213470, acc.: 49.80%] [G loss: 0.126647] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1672 [D loss: 1.208286, acc.: 49.90%] [G loss: 0.130731] [Loss difference: 0.004, iterations with loss: 2]\n",
      "1673 [D loss: 1.213691, acc.: 49.80%] [G loss: 0.127603] [Loss difference: -0.003, iterations with loss: 3]\n",
      "1674 [D loss: 1.210485, acc.: 50.00%] [G loss: 0.123925] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1675 [D loss: 1.215948, acc.: 49.80%] [G loss: 0.126858] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1676 [D loss: 1.206882, acc.: 49.90%] [G loss: 0.131110] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1677 [D loss: 1.203720, acc.: 49.90%] [G loss: 0.122616] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1678 [D loss: 1.211612, acc.: 50.00%] [G loss: 0.123809] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1679 [D loss: 1.206051, acc.: 50.00%] [G loss: 0.123667] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1680 [D loss: 1.221269, acc.: 49.71%] [G loss: 0.131877] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1681 [D loss: 1.214392, acc.: 49.80%] [G loss: 0.128013] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1682 [D loss: 1.211483, acc.: 49.90%] [G loss: 0.130828] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1683 [D loss: 1.218156, acc.: 49.71%] [G loss: 0.129688] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1684 [D loss: 1.200922, acc.: 50.00%] [G loss: 0.126360] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1685 [D loss: 1.207972, acc.: 50.00%] [G loss: 0.124254] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1686 [D loss: 1.223125, acc.: 49.71%] [G loss: 0.124484] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1687 [D loss: 1.205059, acc.: 49.80%] [G loss: 0.125283] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1688 [D loss: 1.201891, acc.: 49.90%] [G loss: 0.131203] [Loss difference: 0.006, iterations with loss: 2]\n",
      "1689 [D loss: 1.207343, acc.: 49.80%] [G loss: 0.128308] [Loss difference: -0.003, iterations with loss: 3]\n",
      "1690 [D loss: 1.208653, acc.: 49.80%] [G loss: 0.126028] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1691 [D loss: 1.204228, acc.: 49.80%] [G loss: 0.126978] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1692 [D loss: 1.190952, acc.: 49.90%] [G loss: 0.127291] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1693 [D loss: 1.207868, acc.: 49.90%] [G loss: 0.136369] [Loss difference: 0.009, iterations with loss: 2]\n",
      "1694 [D loss: 1.208729, acc.: 49.80%] [G loss: 0.127610] [Loss difference: -0.009, iterations with loss: 3]\n",
      "1695 [D loss: 1.198128, acc.: 49.80%] [G loss: 0.131092] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1696 [D loss: 1.201633, acc.: 49.90%] [G loss: 0.128895] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1697 [D loss: 1.222728, acc.: 49.71%] [G loss: 0.123871] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1698 [D loss: 1.224690, acc.: 49.61%] [G loss: 0.124865] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1699 [D loss: 1.203161, acc.: 50.00%] [G loss: 0.129024] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1700 [D loss: 1.219650, acc.: 49.61%] [G loss: 0.123017] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1701 [D loss: 1.219727, acc.: 49.80%] [G loss: 0.130882] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1702 [D loss: 1.203239, acc.: 49.71%] [G loss: 0.124161] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1703 [D loss: 1.212288, acc.: 49.80%] [G loss: 0.123418] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1704 [D loss: 1.220110, acc.: 49.61%] [G loss: 0.127968] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1705 [D loss: 1.215550, acc.: 49.90%] [G loss: 0.130397] [Loss difference: 0.002, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1706 [D loss: 1.198596, acc.: 49.90%] [G loss: 0.127965] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1707 [D loss: 1.206960, acc.: 49.90%] [G loss: 0.130222] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1708 [D loss: 1.193882, acc.: 50.00%] [G loss: 0.125518] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1709 [D loss: 1.205839, acc.: 49.80%] [G loss: 0.129408] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1710 [D loss: 1.195332, acc.: 50.00%] [G loss: 0.129888] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1711 [D loss: 1.190772, acc.: 49.90%] [G loss: 0.125944] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1712 [D loss: 1.207003, acc.: 50.00%] [G loss: 0.131034] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1713 [D loss: 1.200350, acc.: 49.80%] [G loss: 0.134696] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1714 [D loss: 1.210346, acc.: 49.80%] [G loss: 0.125852] [Loss difference: -0.009, iterations with loss: 2]\n",
      "1715 [D loss: 1.189234, acc.: 49.80%] [G loss: 0.125665] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1716 [D loss: 1.205366, acc.: 49.90%] [G loss: 0.128303] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1717 [D loss: 1.211966, acc.: 49.71%] [G loss: 0.129886] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1718 [D loss: 1.215041, acc.: 50.00%] [G loss: 0.133248] [Loss difference: 0.003, iterations with loss: 2]\n",
      "1719 [D loss: 1.201983, acc.: 49.71%] [G loss: 0.126915] [Loss difference: -0.006, iterations with loss: 3]\n",
      "1720 [D loss: 1.197425, acc.: 49.90%] [G loss: 0.130246] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1721 [D loss: 1.222028, acc.: 49.80%] [G loss: 0.128980] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1722 [D loss: 1.214214, acc.: 49.71%] [G loss: 0.129631] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1723 [D loss: 1.229822, acc.: 49.90%] [G loss: 0.133065] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1724 [D loss: 1.193630, acc.: 50.00%] [G loss: 0.130016] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1725 [D loss: 1.210588, acc.: 49.90%] [G loss: 0.127534] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1726 [D loss: 1.200481, acc.: 49.80%] [G loss: 0.130622] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1727 [D loss: 1.215823, acc.: 49.61%] [G loss: 0.124945] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1728 [D loss: 1.217274, acc.: 49.80%] [G loss: 0.128029] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1729 [D loss: 1.200429, acc.: 49.80%] [G loss: 0.130451] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1730 [D loss: 1.189103, acc.: 49.80%] [G loss: 0.133500] [Loss difference: 0.003, iterations with loss: 2]\n",
      "1731 [D loss: 1.194930, acc.: 49.90%] [G loss: 0.133112] [Loss difference: -0.000, iterations with loss: 3]\n",
      "1732 [D loss: 1.175606, acc.: 49.90%] [G loss: 0.125723] [Loss difference: -0.007, iterations with loss: 0]\n",
      "1733 [D loss: 1.200749, acc.: 49.80%] [G loss: 0.132418] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1734 [D loss: 1.192725, acc.: 50.00%] [G loss: 0.133551] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1735 [D loss: 1.206310, acc.: 49.90%] [G loss: 0.127236] [Loss difference: -0.006, iterations with loss: 2]\n",
      "1736 [D loss: 1.190708, acc.: 50.00%] [G loss: 0.125162] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1737 [D loss: 1.201508, acc.: 49.90%] [G loss: 0.129907] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1738 [D loss: 1.188843, acc.: 50.00%] [G loss: 0.137569] [Loss difference: 0.008, iterations with loss: 1]\n",
      "1739 [D loss: 1.180650, acc.: 50.00%] [G loss: 0.133025] [Loss difference: -0.005, iterations with loss: 2]\n",
      "1740 [D loss: 1.211190, acc.: 49.71%] [G loss: 0.129574] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1741 [D loss: 1.185443, acc.: 49.71%] [G loss: 0.125632] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1742 [D loss: 1.198032, acc.: 49.80%] [G loss: 0.127704] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1743 [D loss: 1.202689, acc.: 49.90%] [G loss: 0.131123] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1744 [D loss: 1.187041, acc.: 49.80%] [G loss: 0.127531] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1745 [D loss: 1.201430, acc.: 49.90%] [G loss: 0.131345] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1746 [D loss: 1.193630, acc.: 49.80%] [G loss: 0.129526] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1747 [D loss: 1.200702, acc.: 49.90%] [G loss: 0.133111] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1748 [D loss: 1.193126, acc.: 50.00%] [G loss: 0.133905] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1749 [D loss: 1.189453, acc.: 49.71%] [G loss: 0.130181] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1750 [D loss: 1.204715, acc.: 49.80%] [G loss: 0.126792] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1751 [D loss: 1.203940, acc.: 49.71%] [G loss: 0.129404] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1752 [D loss: 1.203379, acc.: 49.90%] [G loss: 0.121113] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1753 [D loss: 1.191115, acc.: 49.90%] [G loss: 0.128208] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1754 [D loss: 1.198261, acc.: 49.90%] [G loss: 0.131516] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1755 [D loss: 1.204263, acc.: 49.71%] [G loss: 0.133871] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1756 [D loss: 1.199497, acc.: 49.80%] [G loss: 0.131030] [Loss difference: -0.003, iterations with loss: 3]\n",
      "1757 [D loss: 1.204303, acc.: 49.61%] [G loss: 0.127317] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1758 [D loss: 1.195146, acc.: 49.80%] [G loss: 0.134813] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1759 [D loss: 1.201313, acc.: 50.00%] [G loss: 0.133618] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1760 [D loss: 1.207258, acc.: 49.71%] [G loss: 0.131512] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1761 [D loss: 1.195361, acc.: 50.00%] [G loss: 0.138710] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1762 [D loss: 1.192430, acc.: 49.90%] [G loss: 0.130741] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1763 [D loss: 1.185778, acc.: 49.90%] [G loss: 0.134956] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1764 [D loss: 1.182667, acc.: 50.00%] [G loss: 0.130265] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1765 [D loss: 1.200591, acc.: 49.80%] [G loss: 0.137060] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1766 [D loss: 1.198131, acc.: 49.80%] [G loss: 0.133145] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1767 [D loss: 1.204618, acc.: 49.71%] [G loss: 0.131742] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1768 [D loss: 1.192885, acc.: 49.90%] [G loss: 0.133346] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1769 [D loss: 1.198054, acc.: 50.00%] [G loss: 0.134082] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1770 [D loss: 1.209194, acc.: 49.71%] [G loss: 0.131025] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1771 [D loss: 1.191505, acc.: 50.00%] [G loss: 0.130064] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1772 [D loss: 1.197623, acc.: 49.90%] [G loss: 0.136417] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1773 [D loss: 1.196497, acc.: 49.71%] [G loss: 0.127966] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1774 [D loss: 1.190670, acc.: 49.80%] [G loss: 0.135408] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1775 [D loss: 1.201204, acc.: 49.90%] [G loss: 0.131539] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1776 [D loss: 1.197113, acc.: 49.71%] [G loss: 0.135292] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1777 [D loss: 1.203580, acc.: 49.71%] [G loss: 0.129573] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1778 [D loss: 1.185553, acc.: 49.71%] [G loss: 0.132765] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1779 [D loss: 1.194552, acc.: 49.71%] [G loss: 0.127288] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1780 [D loss: 1.195559, acc.: 50.00%] [G loss: 0.130740] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1781 [D loss: 1.212883, acc.: 49.61%] [G loss: 0.127735] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1782 [D loss: 1.185475, acc.: 49.80%] [G loss: 0.129300] [Loss difference: 0.002, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783 [D loss: 1.195691, acc.: 49.80%] [G loss: 0.131813] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1784 [D loss: 1.204096, acc.: 49.80%] [G loss: 0.135246] [Loss difference: 0.003, iterations with loss: 2]\n",
      "1785 [D loss: 1.191798, acc.: 49.90%] [G loss: 0.135307] [Loss difference: 0.000, iterations with loss: 3]\n",
      "1786 [D loss: 1.187240, acc.: 49.80%] [G loss: 0.132899] [Loss difference: -0.002, iterations with loss: 4]\n",
      "1787 [D loss: 1.180004, acc.: 49.90%] [G loss: 0.134895] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1788 [D loss: 1.184650, acc.: 49.90%] [G loss: 0.133059] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1789 [D loss: 1.182407, acc.: 49.80%] [G loss: 0.136209] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1790 [D loss: 1.184588, acc.: 50.00%] [G loss: 0.135786] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1791 [D loss: 1.184506, acc.: 49.80%] [G loss: 0.130068] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1792 [D loss: 1.185662, acc.: 49.80%] [G loss: 0.134804] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1793 [D loss: 1.201184, acc.: 49.80%] [G loss: 0.127651] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1794 [D loss: 1.206920, acc.: 49.61%] [G loss: 0.128966] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1795 [D loss: 1.202300, acc.: 49.71%] [G loss: 0.136476] [Loss difference: 0.008, iterations with loss: 1]\n",
      "1796 [D loss: 1.176053, acc.: 49.80%] [G loss: 0.132704] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1797 [D loss: 1.219217, acc.: 49.90%] [G loss: 0.134540] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1798 [D loss: 1.206893, acc.: 49.80%] [G loss: 0.126815] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1799 [D loss: 1.199921, acc.: 50.00%] [G loss: 0.130730] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1800 [D loss: 1.194382, acc.: 49.71%] [G loss: 0.137164] [Loss difference: 0.006, iterations with loss: 1]\n",
      "1801 [D loss: 1.183351, acc.: 49.90%] [G loss: 0.137055] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1802 [D loss: 1.190752, acc.: 50.00%] [G loss: 0.137953] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1803 [D loss: 1.211985, acc.: 49.61%] [G loss: 0.132058] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1804 [D loss: 1.173082, acc.: 49.90%] [G loss: 0.133190] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1805 [D loss: 1.200125, acc.: 49.80%] [G loss: 0.137270] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1806 [D loss: 1.178174, acc.: 49.90%] [G loss: 0.139645] [Loss difference: 0.002, iterations with loss: 2]\n",
      "1807 [D loss: 1.204899, acc.: 49.80%] [G loss: 0.137580] [Loss difference: -0.002, iterations with loss: 3]\n",
      "1808 [D loss: 1.177457, acc.: 49.61%] [G loss: 0.134095] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1809 [D loss: 1.174547, acc.: 50.00%] [G loss: 0.138020] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1810 [D loss: 1.174468, acc.: 49.80%] [G loss: 0.134364] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1811 [D loss: 1.181471, acc.: 50.00%] [G loss: 0.131223] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1812 [D loss: 1.202136, acc.: 49.80%] [G loss: 0.137763] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1813 [D loss: 1.185591, acc.: 49.80%] [G loss: 0.132849] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1814 [D loss: 1.195861, acc.: 49.80%] [G loss: 0.131410] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1815 [D loss: 1.216819, acc.: 49.71%] [G loss: 0.138829] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1816 [D loss: 1.195636, acc.: 49.80%] [G loss: 0.133462] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1817 [D loss: 1.189968, acc.: 49.90%] [G loss: 0.128287] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1818 [D loss: 1.194033, acc.: 50.00%] [G loss: 0.132638] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1819 [D loss: 1.214158, acc.: 49.61%] [G loss: 0.134850] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1820 [D loss: 1.175637, acc.: 50.00%] [G loss: 0.134795] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1821 [D loss: 1.169065, acc.: 50.00%] [G loss: 0.134251] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1822 [D loss: 1.178224, acc.: 50.00%] [G loss: 0.138599] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1823 [D loss: 1.195908, acc.: 49.80%] [G loss: 0.137145] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1824 [D loss: 1.191836, acc.: 49.90%] [G loss: 0.133282] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1825 [D loss: 1.171604, acc.: 49.90%] [G loss: 0.130464] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1826 [D loss: 1.195522, acc.: 50.00%] [G loss: 0.142102] [Loss difference: 0.012, iterations with loss: 0]\n",
      "1827 [D loss: 1.195530, acc.: 49.71%] [G loss: 0.133674] [Loss difference: -0.008, iterations with loss: 1]\n",
      "1828 [D loss: 1.211485, acc.: 49.61%] [G loss: 0.131246] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1829 [D loss: 1.194769, acc.: 49.71%] [G loss: 0.132155] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1830 [D loss: 1.190659, acc.: 50.00%] [G loss: 0.134215] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1831 [D loss: 1.180035, acc.: 49.80%] [G loss: 0.133434] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1832 [D loss: 1.189520, acc.: 49.90%] [G loss: 0.135877] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1833 [D loss: 1.186659, acc.: 49.71%] [G loss: 0.134686] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1834 [D loss: 1.181870, acc.: 49.80%] [G loss: 0.141321] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1835 [D loss: 1.177624, acc.: 49.80%] [G loss: 0.137060] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1836 [D loss: 1.199903, acc.: 49.71%] [G loss: 0.131127] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1837 [D loss: 1.192674, acc.: 49.80%] [G loss: 0.137790] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1838 [D loss: 1.184898, acc.: 49.90%] [G loss: 0.138152] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1839 [D loss: 1.185259, acc.: 49.80%] [G loss: 0.137582] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1840 [D loss: 1.181122, acc.: 49.80%] [G loss: 0.134661] [Loss difference: -0.003, iterations with loss: 0]\n",
      "1841 [D loss: 1.185861, acc.: 49.90%] [G loss: 0.134469] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1842 [D loss: 1.169901, acc.: 49.80%] [G loss: 0.135305] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1843 [D loss: 1.190163, acc.: 49.61%] [G loss: 0.140718] [Loss difference: 0.005, iterations with loss: 1]\n",
      "1844 [D loss: 1.184919, acc.: 49.90%] [G loss: 0.138263] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1845 [D loss: 1.184928, acc.: 49.90%] [G loss: 0.141571] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1846 [D loss: 1.195882, acc.: 49.80%] [G loss: 0.137868] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1847 [D loss: 1.181747, acc.: 49.90%] [G loss: 0.139247] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1848 [D loss: 1.187967, acc.: 49.80%] [G loss: 0.142825] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1849 [D loss: 1.164306, acc.: 49.90%] [G loss: 0.132765] [Loss difference: -0.010, iterations with loss: 2]\n",
      "1850 [D loss: 1.192633, acc.: 49.80%] [G loss: 0.133251] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1851 [D loss: 1.194715, acc.: 49.71%] [G loss: 0.136516] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1852 [D loss: 1.177450, acc.: 49.90%] [G loss: 0.132843] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1853 [D loss: 1.178910, acc.: 49.80%] [G loss: 0.135120] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1854 [D loss: 1.186114, acc.: 49.61%] [G loss: 0.138161] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1855 [D loss: 1.205275, acc.: 49.71%] [G loss: 0.136860] [Loss difference: -0.001, iterations with loss: 2]\n",
      "1856 [D loss: 1.179778, acc.: 50.00%] [G loss: 0.136496] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1857 [D loss: 1.175136, acc.: 49.90%] [G loss: 0.134665] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1858 [D loss: 1.177096, acc.: 50.00%] [G loss: 0.137540] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1859 [D loss: 1.181591, acc.: 49.90%] [G loss: 0.134128] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1860 [D loss: 1.180378, acc.: 49.71%] [G loss: 0.133991] [Loss difference: -0.000, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1861 [D loss: 1.178638, acc.: 49.80%] [G loss: 0.135118] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1862 [D loss: 1.177466, acc.: 50.00%] [G loss: 0.142657] [Loss difference: 0.008, iterations with loss: 1]\n",
      "1863 [D loss: 1.164286, acc.: 49.90%] [G loss: 0.132125] [Loss difference: -0.011, iterations with loss: 2]\n",
      "1864 [D loss: 1.186081, acc.: 50.00%] [G loss: 0.139244] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1865 [D loss: 1.191545, acc.: 49.80%] [G loss: 0.139436] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1866 [D loss: 1.200727, acc.: 49.41%] [G loss: 0.140612] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1867 [D loss: 1.169227, acc.: 50.00%] [G loss: 0.134915] [Loss difference: -0.006, iterations with loss: 3]\n",
      "1868 [D loss: 1.165981, acc.: 49.90%] [G loss: 0.140785] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1869 [D loss: 1.181362, acc.: 49.80%] [G loss: 0.139007] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1870 [D loss: 1.180674, acc.: 49.90%] [G loss: 0.137418] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1871 [D loss: 1.169161, acc.: 49.90%] [G loss: 0.137659] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1872 [D loss: 1.167248, acc.: 49.90%] [G loss: 0.143699] [Loss difference: 0.006, iterations with loss: 1]\n",
      "1873 [D loss: 1.177631, acc.: 49.90%] [G loss: 0.134616] [Loss difference: -0.009, iterations with loss: 2]\n",
      "1874 [D loss: 1.176852, acc.: 49.90%] [G loss: 0.137712] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1875 [D loss: 1.168256, acc.: 49.90%] [G loss: 0.131747] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1876 [D loss: 1.180157, acc.: 49.90%] [G loss: 0.139698] [Loss difference: 0.008, iterations with loss: 0]\n",
      "1877 [D loss: 1.181135, acc.: 49.80%] [G loss: 0.139734] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1878 [D loss: 1.169979, acc.: 49.90%] [G loss: 0.142830] [Loss difference: 0.003, iterations with loss: 2]\n",
      "1879 [D loss: 1.180993, acc.: 49.71%] [G loss: 0.143427] [Loss difference: 0.001, iterations with loss: 3]\n",
      "1880 [D loss: 1.165609, acc.: 49.90%] [G loss: 0.140838] [Loss difference: -0.003, iterations with loss: 4]\n",
      "1881 [D loss: 1.185447, acc.: 49.61%] [G loss: 0.138883] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1882 [D loss: 1.178682, acc.: 49.80%] [G loss: 0.140462] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1883 [D loss: 1.184318, acc.: 49.80%] [G loss: 0.142886] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1884 [D loss: 1.167362, acc.: 49.80%] [G loss: 0.134835] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1885 [D loss: 1.177486, acc.: 49.90%] [G loss: 0.128984] [Loss difference: -0.006, iterations with loss: 0]\n",
      "1886 [D loss: 1.178837, acc.: 49.71%] [G loss: 0.136083] [Loss difference: 0.007, iterations with loss: 0]\n",
      "1887 [D loss: 1.184750, acc.: 49.90%] [G loss: 0.145068] [Loss difference: 0.009, iterations with loss: 1]\n",
      "1888 [D loss: 1.182273, acc.: 49.90%] [G loss: 0.140818] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1889 [D loss: 1.177367, acc.: 49.90%] [G loss: 0.139733] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1890 [D loss: 1.184194, acc.: 49.71%] [G loss: 0.139885] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1891 [D loss: 1.156233, acc.: 50.00%] [G loss: 0.142831] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1892 [D loss: 1.190845, acc.: 49.71%] [G loss: 0.143487] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1893 [D loss: 1.167422, acc.: 50.00%] [G loss: 0.143426] [Loss difference: -0.000, iterations with loss: 3]\n",
      "1894 [D loss: 1.181824, acc.: 49.80%] [G loss: 0.139107] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1895 [D loss: 1.168364, acc.: 49.90%] [G loss: 0.137010] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1896 [D loss: 1.181932, acc.: 49.71%] [G loss: 0.139032] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1897 [D loss: 1.165545, acc.: 49.80%] [G loss: 0.139976] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1898 [D loss: 1.177335, acc.: 49.80%] [G loss: 0.135975] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1899 [D loss: 1.164879, acc.: 49.90%] [G loss: 0.141931] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1900 [D loss: 1.158981, acc.: 49.90%] [G loss: 0.136356] [Loss difference: -0.006, iterations with loss: 1]\n",
      "1901 [D loss: 1.182684, acc.: 49.90%] [G loss: 0.140992] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1902 [D loss: 1.164544, acc.: 49.90%] [G loss: 0.142641] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1903 [D loss: 1.164948, acc.: 49.90%] [G loss: 0.143235] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1904 [D loss: 1.169156, acc.: 49.80%] [G loss: 0.134387] [Loss difference: -0.009, iterations with loss: 3]\n",
      "1905 [D loss: 1.183313, acc.: 49.90%] [G loss: 0.143646] [Loss difference: 0.009, iterations with loss: 0]\n",
      "1906 [D loss: 1.185304, acc.: 49.71%] [G loss: 0.140662] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1907 [D loss: 1.181893, acc.: 49.90%] [G loss: 0.141445] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1908 [D loss: 1.174254, acc.: 49.90%] [G loss: 0.142039] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1909 [D loss: 1.185300, acc.: 49.61%] [G loss: 0.134878] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1910 [D loss: 1.165585, acc.: 50.00%] [G loss: 0.140809] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1911 [D loss: 1.169608, acc.: 49.80%] [G loss: 0.141692] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1912 [D loss: 1.165086, acc.: 49.80%] [G loss: 0.137832] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1913 [D loss: 1.172497, acc.: 50.00%] [G loss: 0.140806] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1914 [D loss: 1.177807, acc.: 49.51%] [G loss: 0.142962] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1915 [D loss: 1.180124, acc.: 49.71%] [G loss: 0.140583] [Loss difference: -0.002, iterations with loss: 2]\n",
      "1916 [D loss: 1.170799, acc.: 50.00%] [G loss: 0.141816] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1917 [D loss: 1.178317, acc.: 49.80%] [G loss: 0.138179] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1918 [D loss: 1.174514, acc.: 49.80%] [G loss: 0.137803] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1919 [D loss: 1.175559, acc.: 49.80%] [G loss: 0.139266] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1920 [D loss: 1.164672, acc.: 50.00%] [G loss: 0.143617] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1921 [D loss: 1.165754, acc.: 49.80%] [G loss: 0.138939] [Loss difference: -0.005, iterations with loss: 2]\n",
      "1922 [D loss: 1.178983, acc.: 49.90%] [G loss: 0.139640] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1923 [D loss: 1.177653, acc.: 49.61%] [G loss: 0.139913] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1924 [D loss: 1.171449, acc.: 49.90%] [G loss: 0.142546] [Loss difference: 0.003, iterations with loss: 2]\n",
      "1925 [D loss: 1.170176, acc.: 49.90%] [G loss: 0.139779] [Loss difference: -0.003, iterations with loss: 3]\n",
      "1926 [D loss: 1.170358, acc.: 49.80%] [G loss: 0.141745] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1927 [D loss: 1.151245, acc.: 50.00%] [G loss: 0.139945] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1928 [D loss: 1.166939, acc.: 49.80%] [G loss: 0.140298] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1929 [D loss: 1.174649, acc.: 49.80%] [G loss: 0.142979] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1930 [D loss: 1.156405, acc.: 49.90%] [G loss: 0.138524] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1931 [D loss: 1.147264, acc.: 49.90%] [G loss: 0.144940] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1932 [D loss: 1.168589, acc.: 49.41%] [G loss: 0.139765] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1933 [D loss: 1.153990, acc.: 49.90%] [G loss: 0.140938] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1934 [D loss: 1.164996, acc.: 49.80%] [G loss: 0.139768] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1935 [D loss: 1.161593, acc.: 49.90%] [G loss: 0.140389] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1936 [D loss: 1.152233, acc.: 49.71%] [G loss: 0.139995] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1937 [D loss: 1.170921, acc.: 49.41%] [G loss: 0.140008] [Loss difference: 0.000, iterations with loss: 0]\n",
      "1938 [D loss: 1.179860, acc.: 49.71%] [G loss: 0.138206] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1939 [D loss: 1.182187, acc.: 49.80%] [G loss: 0.141776] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1940 [D loss: 1.162996, acc.: 49.80%] [G loss: 0.137576] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1941 [D loss: 1.161696, acc.: 49.71%] [G loss: 0.141116] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1942 [D loss: 1.155192, acc.: 49.80%] [G loss: 0.145527] [Loss difference: 0.004, iterations with loss: 1]\n",
      "1943 [D loss: 1.173997, acc.: 49.71%] [G loss: 0.141761] [Loss difference: -0.004, iterations with loss: 2]\n",
      "1944 [D loss: 1.156304, acc.: 50.00%] [G loss: 0.143878] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1945 [D loss: 1.161022, acc.: 50.00%] [G loss: 0.144687] [Loss difference: 0.001, iterations with loss: 1]\n",
      "1946 [D loss: 1.175640, acc.: 49.71%] [G loss: 0.144467] [Loss difference: -0.000, iterations with loss: 2]\n",
      "1947 [D loss: 1.173989, acc.: 49.41%] [G loss: 0.140321] [Loss difference: -0.004, iterations with loss: 0]\n",
      "1948 [D loss: 1.180531, acc.: 49.71%] [G loss: 0.145097] [Loss difference: 0.005, iterations with loss: 0]\n",
      "1949 [D loss: 1.166585, acc.: 49.80%] [G loss: 0.141497] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1950 [D loss: 1.151371, acc.: 49.80%] [G loss: 0.142950] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1951 [D loss: 1.157400, acc.: 49.90%] [G loss: 0.139586] [Loss difference: -0.003, iterations with loss: 1]\n",
      "1952 [D loss: 1.156663, acc.: 49.90%] [G loss: 0.143125] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1953 [D loss: 1.176663, acc.: 49.71%] [G loss: 0.145100] [Loss difference: 0.002, iterations with loss: 1]\n",
      "1954 [D loss: 1.167065, acc.: 50.00%] [G loss: 0.141743] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1955 [D loss: 1.156344, acc.: 50.00%] [G loss: 0.146315] [Loss difference: 0.005, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956 [D loss: 1.153505, acc.: 49.90%] [G loss: 0.144145] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1957 [D loss: 1.163592, acc.: 49.80%] [G loss: 0.147973] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1958 [D loss: 1.149290, acc.: 49.90%] [G loss: 0.148213] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1959 [D loss: 1.151981, acc.: 49.80%] [G loss: 0.139291] [Loss difference: -0.009, iterations with loss: 2]\n",
      "1960 [D loss: 1.168354, acc.: 50.00%] [G loss: 0.140781] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1961 [D loss: 1.156153, acc.: 49.90%] [G loss: 0.140876] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1962 [D loss: 1.161883, acc.: 50.00%] [G loss: 0.148269] [Loss difference: 0.007, iterations with loss: 2]\n",
      "1963 [D loss: 1.153476, acc.: 49.90%] [G loss: 0.139740] [Loss difference: -0.009, iterations with loss: 3]\n",
      "1964 [D loss: 1.147810, acc.: 49.80%] [G loss: 0.138577] [Loss difference: -0.001, iterations with loss: 0]\n",
      "1965 [D loss: 1.171638, acc.: 49.61%] [G loss: 0.142165] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1966 [D loss: 1.166650, acc.: 50.00%] [G loss: 0.141830] [Loss difference: -0.000, iterations with loss: 1]\n",
      "1967 [D loss: 1.153033, acc.: 49.71%] [G loss: 0.141429] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1968 [D loss: 1.160668, acc.: 49.61%] [G loss: 0.145445] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1969 [D loss: 1.171496, acc.: 49.90%] [G loss: 0.141902] [Loss difference: -0.004, iterations with loss: 1]\n",
      "1970 [D loss: 1.165663, acc.: 49.90%] [G loss: 0.146112] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1971 [D loss: 1.160321, acc.: 50.00%] [G loss: 0.139199] [Loss difference: -0.007, iterations with loss: 1]\n",
      "1972 [D loss: 1.162138, acc.: 49.90%] [G loss: 0.141735] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1973 [D loss: 1.144153, acc.: 49.90%] [G loss: 0.151848] [Loss difference: 0.010, iterations with loss: 1]\n",
      "1974 [D loss: 1.142020, acc.: 50.00%] [G loss: 0.149238] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1975 [D loss: 1.147702, acc.: 50.00%] [G loss: 0.144638] [Loss difference: -0.005, iterations with loss: 0]\n",
      "1976 [D loss: 1.154541, acc.: 50.00%] [G loss: 0.144314] [Loss difference: -0.000, iterations with loss: 0]\n",
      "1977 [D loss: 1.154610, acc.: 49.90%] [G loss: 0.147098] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1978 [D loss: 1.151665, acc.: 49.90%] [G loss: 0.144709] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1979 [D loss: 1.159330, acc.: 49.71%] [G loss: 0.143105] [Loss difference: -0.002, iterations with loss: 0]\n",
      "1980 [D loss: 1.163906, acc.: 49.80%] [G loss: 0.147523] [Loss difference: 0.004, iterations with loss: 0]\n",
      "1981 [D loss: 1.144335, acc.: 50.00%] [G loss: 0.145136] [Loss difference: -0.002, iterations with loss: 1]\n",
      "1982 [D loss: 1.147966, acc.: 50.00%] [G loss: 0.146287] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1983 [D loss: 1.149322, acc.: 49.90%] [G loss: 0.146362] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1984 [D loss: 1.160655, acc.: 49.80%] [G loss: 0.142960] [Loss difference: -0.003, iterations with loss: 2]\n",
      "1985 [D loss: 1.156904, acc.: 49.71%] [G loss: 0.143699] [Loss difference: 0.001, iterations with loss: 0]\n",
      "1986 [D loss: 1.153320, acc.: 49.80%] [G loss: 0.146942] [Loss difference: 0.003, iterations with loss: 1]\n",
      "1987 [D loss: 1.163977, acc.: 49.71%] [G loss: 0.147627] [Loss difference: 0.001, iterations with loss: 2]\n",
      "1988 [D loss: 1.144799, acc.: 49.80%] [G loss: 0.143942] [Loss difference: -0.004, iterations with loss: 3]\n",
      "1989 [D loss: 1.152953, acc.: 49.80%] [G loss: 0.147434] [Loss difference: 0.003, iterations with loss: 0]\n",
      "1990 [D loss: 1.149379, acc.: 49.71%] [G loss: 0.147477] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1991 [D loss: 1.143228, acc.: 50.00%] [G loss: 0.139853] [Loss difference: -0.008, iterations with loss: 2]\n",
      "1992 [D loss: 1.140740, acc.: 50.00%] [G loss: 0.145953] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1993 [D loss: 1.166751, acc.: 49.80%] [G loss: 0.141448] [Loss difference: -0.005, iterations with loss: 1]\n",
      "1994 [D loss: 1.151063, acc.: 49.61%] [G loss: 0.143074] [Loss difference: 0.002, iterations with loss: 0]\n",
      "1995 [D loss: 1.160169, acc.: 49.80%] [G loss: 0.141992] [Loss difference: -0.001, iterations with loss: 1]\n",
      "1996 [D loss: 1.159875, acc.: 50.00%] [G loss: 0.148160] [Loss difference: 0.006, iterations with loss: 0]\n",
      "1997 [D loss: 1.178174, acc.: 49.80%] [G loss: 0.148539] [Loss difference: 0.000, iterations with loss: 1]\n",
      "1998 [D loss: 1.146938, acc.: 49.90%] [G loss: 0.141410] [Loss difference: -0.007, iterations with loss: 2]\n",
      "1999 [D loss: 1.157071, acc.: 49.90%] [G loss: 0.149090] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2000 [D loss: 1.142488, acc.: 50.00%] [G loss: 0.145176] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2001 [D loss: 1.151067, acc.: 49.90%] [G loss: 0.150323] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2002 [D loss: 1.138095, acc.: 49.90%] [G loss: 0.152730] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2003 [D loss: 1.126422, acc.: 49.90%] [G loss: 0.153830] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2004 [D loss: 1.156515, acc.: 49.90%] [G loss: 0.151243] [Loss difference: -0.003, iterations with loss: 3]\n",
      "2005 [D loss: 1.151974, acc.: 49.90%] [G loss: 0.141204] [Loss difference: -0.010, iterations with loss: 0]\n",
      "2006 [D loss: 1.173805, acc.: 49.80%] [G loss: 0.146836] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2007 [D loss: 1.166539, acc.: 49.90%] [G loss: 0.141489] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2008 [D loss: 1.150935, acc.: 49.90%] [G loss: 0.145341] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2009 [D loss: 1.136289, acc.: 50.00%] [G loss: 0.146415] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2010 [D loss: 1.148219, acc.: 50.00%] [G loss: 0.145794] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2011 [D loss: 1.145340, acc.: 49.90%] [G loss: 0.148615] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2012 [D loss: 1.151029, acc.: 49.90%] [G loss: 0.144666] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2013 [D loss: 1.145757, acc.: 50.00%] [G loss: 0.145659] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2014 [D loss: 1.149543, acc.: 49.80%] [G loss: 0.149672] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2015 [D loss: 1.146954, acc.: 50.00%] [G loss: 0.146358] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2016 [D loss: 1.143427, acc.: 49.80%] [G loss: 0.150601] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2017 [D loss: 1.140793, acc.: 50.00%] [G loss: 0.146766] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2018 [D loss: 1.143085, acc.: 50.00%] [G loss: 0.149393] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2019 [D loss: 1.149425, acc.: 49.80%] [G loss: 0.149539] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2020 [D loss: 1.146538, acc.: 49.80%] [G loss: 0.151346] [Loss difference: 0.002, iterations with loss: 2]\n",
      "2021 [D loss: 1.149986, acc.: 49.90%] [G loss: 0.150636] [Loss difference: -0.001, iterations with loss: 3]\n",
      "2022 [D loss: 1.154854, acc.: 49.61%] [G loss: 0.153524] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2023 [D loss: 1.150813, acc.: 49.61%] [G loss: 0.150863] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2024 [D loss: 1.150616, acc.: 49.61%] [G loss: 0.145909] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2025 [D loss: 1.151299, acc.: 50.00%] [G loss: 0.141613] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2026 [D loss: 1.153788, acc.: 49.80%] [G loss: 0.144893] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2027 [D loss: 1.147306, acc.: 49.90%] [G loss: 0.153110] [Loss difference: 0.008, iterations with loss: 1]\n",
      "2028 [D loss: 1.164203, acc.: 49.80%] [G loss: 0.145019] [Loss difference: -0.008, iterations with loss: 2]\n",
      "2029 [D loss: 1.135871, acc.: 49.80%] [G loss: 0.144209] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2030 [D loss: 1.155744, acc.: 49.51%] [G loss: 0.141957] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2031 [D loss: 1.137879, acc.: 49.90%] [G loss: 0.151655] [Loss difference: 0.010, iterations with loss: 0]\n",
      "2032 [D loss: 1.150768, acc.: 49.71%] [G loss: 0.149404] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2033 [D loss: 1.142740, acc.: 49.90%] [G loss: 0.147058] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2034 [D loss: 1.141680, acc.: 49.71%] [G loss: 0.148078] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2035 [D loss: 1.148469, acc.: 49.71%] [G loss: 0.147604] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2036 [D loss: 1.143507, acc.: 49.90%] [G loss: 0.154797] [Loss difference: 0.007, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037 [D loss: 1.143688, acc.: 49.90%] [G loss: 0.150199] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2038 [D loss: 1.136450, acc.: 49.80%] [G loss: 0.152573] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2039 [D loss: 1.146880, acc.: 49.80%] [G loss: 0.145313] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2040 [D loss: 1.152985, acc.: 50.00%] [G loss: 0.143459] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2041 [D loss: 1.156703, acc.: 49.51%] [G loss: 0.144162] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2042 [D loss: 1.141529, acc.: 50.00%] [G loss: 0.147036] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2043 [D loss: 1.126558, acc.: 50.00%] [G loss: 0.150417] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2044 [D loss: 1.129017, acc.: 49.71%] [G loss: 0.145225] [Loss difference: -0.005, iterations with loss: 3]\n",
      "2045 [D loss: 1.131946, acc.: 49.80%] [G loss: 0.150448] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2046 [D loss: 1.151150, acc.: 49.61%] [G loss: 0.150884] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2047 [D loss: 1.137777, acc.: 50.00%] [G loss: 0.148176] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2048 [D loss: 1.147731, acc.: 49.80%] [G loss: 0.146954] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2049 [D loss: 1.146959, acc.: 49.80%] [G loss: 0.149573] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2050 [D loss: 1.133638, acc.: 50.00%] [G loss: 0.143600] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2051 [D loss: 1.134978, acc.: 50.00%] [G loss: 0.151365] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2052 [D loss: 1.157071, acc.: 49.80%] [G loss: 0.144485] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2053 [D loss: 1.149973, acc.: 49.80%] [G loss: 0.149021] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2054 [D loss: 1.140100, acc.: 49.80%] [G loss: 0.149030] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2055 [D loss: 1.142600, acc.: 49.90%] [G loss: 0.153119] [Loss difference: 0.004, iterations with loss: 2]\n",
      "2056 [D loss: 1.127735, acc.: 49.90%] [G loss: 0.150238] [Loss difference: -0.003, iterations with loss: 3]\n",
      "2057 [D loss: 1.149757, acc.: 49.80%] [G loss: 0.154653] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2058 [D loss: 1.153434, acc.: 49.71%] [G loss: 0.150003] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2059 [D loss: 1.157680, acc.: 49.61%] [G loss: 0.144854] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2060 [D loss: 1.144415, acc.: 50.00%] [G loss: 0.148672] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2061 [D loss: 1.167574, acc.: 49.61%] [G loss: 0.147268] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2062 [D loss: 1.123856, acc.: 49.90%] [G loss: 0.147184] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2063 [D loss: 1.119223, acc.: 50.00%] [G loss: 0.152348] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2064 [D loss: 1.138813, acc.: 49.80%] [G loss: 0.151966] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2065 [D loss: 1.151478, acc.: 49.90%] [G loss: 0.148784] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2066 [D loss: 1.150232, acc.: 49.71%] [G loss: 0.149849] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2067 [D loss: 1.140179, acc.: 49.80%] [G loss: 0.158184] [Loss difference: 0.008, iterations with loss: 1]\n",
      "2068 [D loss: 1.144159, acc.: 50.00%] [G loss: 0.152778] [Loss difference: -0.005, iterations with loss: 2]\n",
      "2069 [D loss: 1.144333, acc.: 49.80%] [G loss: 0.151440] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2070 [D loss: 1.143316, acc.: 49.61%] [G loss: 0.153535] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2071 [D loss: 1.135727, acc.: 50.00%] [G loss: 0.149332] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2072 [D loss: 1.139277, acc.: 50.00%] [G loss: 0.152961] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2073 [D loss: 1.151694, acc.: 49.61%] [G loss: 0.147485] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2074 [D loss: 1.131352, acc.: 49.80%] [G loss: 0.150232] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2075 [D loss: 1.126247, acc.: 49.90%] [G loss: 0.148406] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2076 [D loss: 1.130984, acc.: 50.00%] [G loss: 0.148056] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2077 [D loss: 1.137578, acc.: 49.71%] [G loss: 0.149541] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2078 [D loss: 1.127561, acc.: 50.00%] [G loss: 0.149749] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2079 [D loss: 1.112837, acc.: 49.90%] [G loss: 0.151782] [Loss difference: 0.002, iterations with loss: 2]\n",
      "2080 [D loss: 1.119182, acc.: 50.00%] [G loss: 0.154146] [Loss difference: 0.002, iterations with loss: 3]\n",
      "2081 [D loss: 1.135742, acc.: 49.71%] [G loss: 0.153282] [Loss difference: -0.001, iterations with loss: 4]\n",
      "2082 [D loss: 1.141924, acc.: 49.90%] [G loss: 0.153882] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2083 [D loss: 1.142266, acc.: 49.90%] [G loss: 0.157715] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2084 [D loss: 1.132802, acc.: 49.80%] [G loss: 0.148831] [Loss difference: -0.009, iterations with loss: 2]\n",
      "2085 [D loss: 1.138821, acc.: 49.90%] [G loss: 0.151631] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2086 [D loss: 1.129581, acc.: 49.90%] [G loss: 0.148965] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2087 [D loss: 1.125506, acc.: 50.00%] [G loss: 0.147713] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2088 [D loss: 1.133645, acc.: 49.80%] [G loss: 0.150166] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2089 [D loss: 1.123751, acc.: 50.00%] [G loss: 0.157100] [Loss difference: 0.007, iterations with loss: 1]\n",
      "2090 [D loss: 1.120836, acc.: 49.61%] [G loss: 0.151346] [Loss difference: -0.006, iterations with loss: 2]\n",
      "2091 [D loss: 1.125963, acc.: 49.90%] [G loss: 0.153328] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2092 [D loss: 1.142994, acc.: 50.00%] [G loss: 0.151474] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2093 [D loss: 1.129872, acc.: 49.90%] [G loss: 0.151011] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2094 [D loss: 1.146224, acc.: 50.00%] [G loss: 0.155175] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2095 [D loss: 1.141534, acc.: 49.71%] [G loss: 0.156071] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2096 [D loss: 1.133719, acc.: 49.80%] [G loss: 0.146833] [Loss difference: -0.009, iterations with loss: 2]\n",
      "2097 [D loss: 1.123990, acc.: 49.80%] [G loss: 0.155072] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2098 [D loss: 1.106462, acc.: 50.00%] [G loss: 0.150414] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2099 [D loss: 1.143753, acc.: 49.80%] [G loss: 0.153602] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2100 [D loss: 1.121478, acc.: 49.90%] [G loss: 0.152987] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2101 [D loss: 1.147882, acc.: 49.90%] [G loss: 0.154741] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2102 [D loss: 1.145084, acc.: 50.00%] [G loss: 0.156360] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2103 [D loss: 1.133586, acc.: 50.00%] [G loss: 0.149919] [Loss difference: -0.006, iterations with loss: 2]\n",
      "2104 [D loss: 1.144815, acc.: 49.71%] [G loss: 0.151470] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2105 [D loss: 1.142075, acc.: 49.90%] [G loss: 0.147893] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2106 [D loss: 1.136896, acc.: 49.80%] [G loss: 0.153031] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2107 [D loss: 1.124199, acc.: 49.90%] [G loss: 0.149731] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2108 [D loss: 1.126491, acc.: 49.80%] [G loss: 0.151789] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2109 [D loss: 1.135165, acc.: 50.00%] [G loss: 0.153576] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2110 [D loss: 1.125621, acc.: 49.90%] [G loss: 0.158810] [Loss difference: 0.005, iterations with loss: 2]\n",
      "2111 [D loss: 1.137054, acc.: 49.61%] [G loss: 0.153251] [Loss difference: -0.006, iterations with loss: 3]\n",
      "2112 [D loss: 1.130182, acc.: 50.00%] [G loss: 0.156095] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2113 [D loss: 1.127984, acc.: 49.90%] [G loss: 0.147841] [Loss difference: -0.008, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114 [D loss: 1.130760, acc.: 49.90%] [G loss: 0.153188] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2115 [D loss: 1.147220, acc.: 49.71%] [G loss: 0.152298] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2116 [D loss: 1.124552, acc.: 49.90%] [G loss: 0.153062] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2117 [D loss: 1.130596, acc.: 49.80%] [G loss: 0.152763] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2118 [D loss: 1.138182, acc.: 49.80%] [G loss: 0.150870] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2119 [D loss: 1.135417, acc.: 49.90%] [G loss: 0.152835] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2120 [D loss: 1.127037, acc.: 50.00%] [G loss: 0.153908] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2121 [D loss: 1.133690, acc.: 49.90%] [G loss: 0.154600] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2122 [D loss: 1.118958, acc.: 50.00%] [G loss: 0.158216] [Loss difference: 0.004, iterations with loss: 3]\n",
      "2123 [D loss: 1.119984, acc.: 49.90%] [G loss: 0.152749] [Loss difference: -0.005, iterations with loss: 4]\n",
      "2124 [D loss: 1.136702, acc.: 50.00%] [G loss: 0.151652] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2125 [D loss: 1.112523, acc.: 49.90%] [G loss: 0.146545] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2126 [D loss: 1.134441, acc.: 49.90%] [G loss: 0.149978] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2127 [D loss: 1.122489, acc.: 50.00%] [G loss: 0.158064] [Loss difference: 0.008, iterations with loss: 1]\n",
      "2128 [D loss: 1.117801, acc.: 49.80%] [G loss: 0.152250] [Loss difference: -0.006, iterations with loss: 2]\n",
      "2129 [D loss: 1.136454, acc.: 49.90%] [G loss: 0.156291] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2130 [D loss: 1.144382, acc.: 49.90%] [G loss: 0.155512] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2131 [D loss: 1.125907, acc.: 49.90%] [G loss: 0.150555] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2132 [D loss: 1.135978, acc.: 49.90%] [G loss: 0.154857] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2133 [D loss: 1.133241, acc.: 49.90%] [G loss: 0.152710] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2134 [D loss: 1.147464, acc.: 49.71%] [G loss: 0.164391] [Loss difference: 0.012, iterations with loss: 0]\n",
      "2135 [D loss: 1.122698, acc.: 50.00%] [G loss: 0.154408] [Loss difference: -0.010, iterations with loss: 1]\n",
      "2136 [D loss: 1.128973, acc.: 49.80%] [G loss: 0.155532] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2137 [D loss: 1.134318, acc.: 49.71%] [G loss: 0.154181] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2138 [D loss: 1.122541, acc.: 50.00%] [G loss: 0.154110] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2139 [D loss: 1.120368, acc.: 50.00%] [G loss: 0.155940] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2140 [D loss: 1.128810, acc.: 50.00%] [G loss: 0.149469] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2141 [D loss: 1.119470, acc.: 50.00%] [G loss: 0.150796] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2142 [D loss: 1.118684, acc.: 50.00%] [G loss: 0.155572] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2143 [D loss: 1.121987, acc.: 50.00%] [G loss: 0.158546] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2144 [D loss: 1.126022, acc.: 50.00%] [G loss: 0.148743] [Loss difference: -0.010, iterations with loss: 3]\n",
      "2145 [D loss: 1.120316, acc.: 49.90%] [G loss: 0.159029] [Loss difference: 0.010, iterations with loss: 0]\n",
      "2146 [D loss: 1.128499, acc.: 49.80%] [G loss: 0.155811] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2147 [D loss: 1.120676, acc.: 50.00%] [G loss: 0.156212] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2148 [D loss: 1.138777, acc.: 49.90%] [G loss: 0.156711] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2149 [D loss: 1.134929, acc.: 49.80%] [G loss: 0.154744] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2150 [D loss: 1.126343, acc.: 49.80%] [G loss: 0.159168] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2151 [D loss: 1.118701, acc.: 49.80%] [G loss: 0.156570] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2152 [D loss: 1.119438, acc.: 49.90%] [G loss: 0.164374] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2153 [D loss: 1.122301, acc.: 50.00%] [G loss: 0.154329] [Loss difference: -0.010, iterations with loss: 1]\n",
      "2154 [D loss: 1.110870, acc.: 49.90%] [G loss: 0.155168] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2155 [D loss: 1.114398, acc.: 50.00%] [G loss: 0.159204] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2156 [D loss: 1.143053, acc.: 49.71%] [G loss: 0.154407] [Loss difference: -0.005, iterations with loss: 2]\n",
      "2157 [D loss: 1.119789, acc.: 49.80%] [G loss: 0.151904] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2158 [D loss: 1.124638, acc.: 49.71%] [G loss: 0.155709] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2159 [D loss: 1.114259, acc.: 50.00%] [G loss: 0.156191] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2160 [D loss: 1.117840, acc.: 49.80%] [G loss: 0.156910] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2161 [D loss: 1.119173, acc.: 49.90%] [G loss: 0.153442] [Loss difference: -0.003, iterations with loss: 3]\n",
      "2162 [D loss: 1.118234, acc.: 50.00%] [G loss: 0.159167] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2163 [D loss: 1.142192, acc.: 49.80%] [G loss: 0.158054] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2164 [D loss: 1.124467, acc.: 50.00%] [G loss: 0.157802] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2165 [D loss: 1.139494, acc.: 49.71%] [G loss: 0.163005] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2166 [D loss: 1.122003, acc.: 50.00%] [G loss: 0.160234] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2167 [D loss: 1.098001, acc.: 50.00%] [G loss: 0.156189] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2168 [D loss: 1.129717, acc.: 49.51%] [G loss: 0.161491] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2169 [D loss: 1.127597, acc.: 49.90%] [G loss: 0.157650] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2170 [D loss: 1.105654, acc.: 50.00%] [G loss: 0.157713] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2171 [D loss: 1.107953, acc.: 49.90%] [G loss: 0.157299] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2172 [D loss: 1.100146, acc.: 49.90%] [G loss: 0.158057] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2173 [D loss: 1.101713, acc.: 50.00%] [G loss: 0.160986] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2174 [D loss: 1.119666, acc.: 49.90%] [G loss: 0.160697] [Loss difference: -0.000, iterations with loss: 2]\n",
      "2175 [D loss: 1.112627, acc.: 49.80%] [G loss: 0.157867] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2176 [D loss: 1.113534, acc.: 50.00%] [G loss: 0.159241] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2177 [D loss: 1.118094, acc.: 49.71%] [G loss: 0.154153] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2178 [D loss: 1.122741, acc.: 49.90%] [G loss: 0.155632] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2179 [D loss: 1.123840, acc.: 49.90%] [G loss: 0.159394] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2180 [D loss: 1.112349, acc.: 49.80%] [G loss: 0.157967] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2181 [D loss: 1.121965, acc.: 49.90%] [G loss: 0.159410] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2182 [D loss: 1.125661, acc.: 49.80%] [G loss: 0.157039] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2183 [D loss: 1.131229, acc.: 49.71%] [G loss: 0.157289] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2184 [D loss: 1.127833, acc.: 49.90%] [G loss: 0.155917] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2185 [D loss: 1.113544, acc.: 49.90%] [G loss: 0.158154] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2186 [D loss: 1.113927, acc.: 50.00%] [G loss: 0.156520] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2187 [D loss: 1.112963, acc.: 49.80%] [G loss: 0.160156] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2188 [D loss: 1.107982, acc.: 50.00%] [G loss: 0.160742] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2189 [D loss: 1.112113, acc.: 49.90%] [G loss: 0.158177] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2190 [D loss: 1.111194, acc.: 49.80%] [G loss: 0.157864] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2191 [D loss: 1.124696, acc.: 49.71%] [G loss: 0.159977] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2192 [D loss: 1.105345, acc.: 50.00%] [G loss: 0.158520] [Loss difference: -0.001, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193 [D loss: 1.118514, acc.: 50.00%] [G loss: 0.159864] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2194 [D loss: 1.102507, acc.: 49.90%] [G loss: 0.161778] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2195 [D loss: 1.109455, acc.: 50.00%] [G loss: 0.158519] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2196 [D loss: 1.115878, acc.: 49.90%] [G loss: 0.159949] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2197 [D loss: 1.104942, acc.: 49.90%] [G loss: 0.155932] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2198 [D loss: 1.124625, acc.: 49.90%] [G loss: 0.163234] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2199 [D loss: 1.106048, acc.: 49.80%] [G loss: 0.160374] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2200 [D loss: 1.111344, acc.: 49.80%] [G loss: 0.164553] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2201 [D loss: 1.123505, acc.: 49.61%] [G loss: 0.162286] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2202 [D loss: 1.122622, acc.: 50.00%] [G loss: 0.160681] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2203 [D loss: 1.129174, acc.: 49.90%] [G loss: 0.159372] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2204 [D loss: 1.112350, acc.: 49.90%] [G loss: 0.158412] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2205 [D loss: 1.108745, acc.: 49.90%] [G loss: 0.160039] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2206 [D loss: 1.097143, acc.: 50.00%] [G loss: 0.159762] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2207 [D loss: 1.121174, acc.: 49.80%] [G loss: 0.164391] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2208 [D loss: 1.121199, acc.: 49.71%] [G loss: 0.165012] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2209 [D loss: 1.108805, acc.: 49.71%] [G loss: 0.163269] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2210 [D loss: 1.119013, acc.: 49.71%] [G loss: 0.164112] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2211 [D loss: 1.119608, acc.: 49.80%] [G loss: 0.163373] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2212 [D loss: 1.119715, acc.: 50.00%] [G loss: 0.161270] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2213 [D loss: 1.117532, acc.: 49.90%] [G loss: 0.161736] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2214 [D loss: 1.132853, acc.: 49.90%] [G loss: 0.161088] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2215 [D loss: 1.113010, acc.: 50.00%] [G loss: 0.162800] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2216 [D loss: 1.093657, acc.: 49.90%] [G loss: 0.158384] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2217 [D loss: 1.103271, acc.: 49.71%] [G loss: 0.162420] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2218 [D loss: 1.118407, acc.: 49.80%] [G loss: 0.159842] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2219 [D loss: 1.114688, acc.: 50.00%] [G loss: 0.163274] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2220 [D loss: 1.102370, acc.: 49.90%] [G loss: 0.163393] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2221 [D loss: 1.096516, acc.: 49.90%] [G loss: 0.163518] [Loss difference: 0.000, iterations with loss: 2]\n",
      "2222 [D loss: 1.111132, acc.: 49.90%] [G loss: 0.159879] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2223 [D loss: 1.119984, acc.: 49.80%] [G loss: 0.161832] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2224 [D loss: 1.116974, acc.: 49.80%] [G loss: 0.158881] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2225 [D loss: 1.109859, acc.: 49.80%] [G loss: 0.161656] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2226 [D loss: 1.112059, acc.: 50.00%] [G loss: 0.161073] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2227 [D loss: 1.115110, acc.: 49.80%] [G loss: 0.161717] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2228 [D loss: 1.118645, acc.: 49.90%] [G loss: 0.161669] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2229 [D loss: 1.112631, acc.: 49.80%] [G loss: 0.160087] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2230 [D loss: 1.103625, acc.: 50.00%] [G loss: 0.163551] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2231 [D loss: 1.099502, acc.: 50.00%] [G loss: 0.162459] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2232 [D loss: 1.101635, acc.: 49.71%] [G loss: 0.158355] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2233 [D loss: 1.116347, acc.: 50.00%] [G loss: 0.164397] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2234 [D loss: 1.117281, acc.: 50.00%] [G loss: 0.163266] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2235 [D loss: 1.100260, acc.: 50.00%] [G loss: 0.162081] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2236 [D loss: 1.098401, acc.: 49.90%] [G loss: 0.167980] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2237 [D loss: 1.108386, acc.: 49.90%] [G loss: 0.166635] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2238 [D loss: 1.104133, acc.: 49.90%] [G loss: 0.162632] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2239 [D loss: 1.108065, acc.: 49.90%] [G loss: 0.160690] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2240 [D loss: 1.110443, acc.: 50.00%] [G loss: 0.167917] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2241 [D loss: 1.123689, acc.: 50.00%] [G loss: 0.168914] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2242 [D loss: 1.106707, acc.: 49.90%] [G loss: 0.170061] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2243 [D loss: 1.106014, acc.: 49.90%] [G loss: 0.165978] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2244 [D loss: 1.094168, acc.: 50.00%] [G loss: 0.161900] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2245 [D loss: 1.099273, acc.: 50.00%] [G loss: 0.157257] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2246 [D loss: 1.113434, acc.: 49.80%] [G loss: 0.161643] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2247 [D loss: 1.093622, acc.: 50.00%] [G loss: 0.161852] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2248 [D loss: 1.109277, acc.: 49.80%] [G loss: 0.164541] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2249 [D loss: 1.098653, acc.: 49.90%] [G loss: 0.166867] [Loss difference: 0.002, iterations with loss: 3]\n",
      "2250 [D loss: 1.103260, acc.: 49.90%] [G loss: 0.161771] [Loss difference: -0.005, iterations with loss: 4]\n",
      "2251 [D loss: 1.103882, acc.: 50.00%] [G loss: 0.162888] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2252 [D loss: 1.097649, acc.: 49.90%] [G loss: 0.160286] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2253 [D loss: 1.096258, acc.: 50.00%] [G loss: 0.164497] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2254 [D loss: 1.113950, acc.: 49.80%] [G loss: 0.163090] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2255 [D loss: 1.115409, acc.: 49.80%] [G loss: 0.166779] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2256 [D loss: 1.103614, acc.: 49.71%] [G loss: 0.164004] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2257 [D loss: 1.096536, acc.: 49.90%] [G loss: 0.164560] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2258 [D loss: 1.096382, acc.: 50.00%] [G loss: 0.166656] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2259 [D loss: 1.105027, acc.: 49.90%] [G loss: 0.165869] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2260 [D loss: 1.109749, acc.: 49.71%] [G loss: 0.163219] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2261 [D loss: 1.120824, acc.: 49.71%] [G loss: 0.165531] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2262 [D loss: 1.108572, acc.: 49.80%] [G loss: 0.165859] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2263 [D loss: 1.100780, acc.: 50.00%] [G loss: 0.164295] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2264 [D loss: 1.103515, acc.: 50.00%] [G loss: 0.159531] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2265 [D loss: 1.096181, acc.: 49.80%] [G loss: 0.169430] [Loss difference: 0.010, iterations with loss: 0]\n",
      "2266 [D loss: 1.109490, acc.: 49.90%] [G loss: 0.167935] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2267 [D loss: 1.104659, acc.: 49.80%] [G loss: 0.161710] [Loss difference: -0.006, iterations with loss: 0]\n",
      "2268 [D loss: 1.094202, acc.: 50.00%] [G loss: 0.163394] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2269 [D loss: 1.100877, acc.: 50.00%] [G loss: 0.161852] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2270 [D loss: 1.110212, acc.: 49.80%] [G loss: 0.160755] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2271 [D loss: 1.109650, acc.: 49.80%] [G loss: 0.165827] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2272 [D loss: 1.106329, acc.: 49.80%] [G loss: 0.165430] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2273 [D loss: 1.100177, acc.: 50.00%] [G loss: 0.164829] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2274 [D loss: 1.103402, acc.: 50.00%] [G loss: 0.168911] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2275 [D loss: 1.089052, acc.: 49.90%] [G loss: 0.168184] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2276 [D loss: 1.098102, acc.: 50.00%] [G loss: 0.162521] [Loss difference: -0.006, iterations with loss: 0]\n",
      "2277 [D loss: 1.098234, acc.: 49.90%] [G loss: 0.169924] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2278 [D loss: 1.095243, acc.: 49.90%] [G loss: 0.164440] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2279 [D loss: 1.087227, acc.: 49.90%] [G loss: 0.166153] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2280 [D loss: 1.097507, acc.: 49.80%] [G loss: 0.161011] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2281 [D loss: 1.096960, acc.: 50.00%] [G loss: 0.167408] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2282 [D loss: 1.097669, acc.: 50.00%] [G loss: 0.169873] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2283 [D loss: 1.088808, acc.: 49.80%] [G loss: 0.167491] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2284 [D loss: 1.106041, acc.: 49.71%] [G loss: 0.171137] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2285 [D loss: 1.086075, acc.: 49.90%] [G loss: 0.166539] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2286 [D loss: 1.102991, acc.: 50.00%] [G loss: 0.166355] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2287 [D loss: 1.094356, acc.: 49.90%] [G loss: 0.164801] [Loss difference: -0.002, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288 [D loss: 1.094502, acc.: 49.90%] [G loss: 0.165040] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2289 [D loss: 1.083283, acc.: 49.90%] [G loss: 0.172884] [Loss difference: 0.008, iterations with loss: 1]\n",
      "2290 [D loss: 1.101207, acc.: 49.90%] [G loss: 0.167784] [Loss difference: -0.005, iterations with loss: 2]\n",
      "2291 [D loss: 1.110149, acc.: 49.71%] [G loss: 0.166151] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2292 [D loss: 1.099485, acc.: 49.90%] [G loss: 0.166715] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2293 [D loss: 1.093894, acc.: 50.00%] [G loss: 0.164880] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2294 [D loss: 1.080466, acc.: 50.00%] [G loss: 0.165881] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2295 [D loss: 1.106171, acc.: 49.80%] [G loss: 0.166337] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2296 [D loss: 1.103086, acc.: 49.90%] [G loss: 0.162615] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2297 [D loss: 1.110194, acc.: 49.80%] [G loss: 0.165915] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2298 [D loss: 1.091249, acc.: 49.80%] [G loss: 0.162734] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2299 [D loss: 1.096287, acc.: 49.90%] [G loss: 0.167093] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2300 [D loss: 1.112898, acc.: 49.80%] [G loss: 0.162525] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2301 [D loss: 1.113382, acc.: 49.71%] [G loss: 0.175187] [Loss difference: 0.013, iterations with loss: 0]\n",
      "2302 [D loss: 1.090533, acc.: 49.80%] [G loss: 0.163485] [Loss difference: -0.012, iterations with loss: 1]\n",
      "2303 [D loss: 1.089781, acc.: 49.90%] [G loss: 0.172154] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2304 [D loss: 1.084844, acc.: 49.90%] [G loss: 0.165425] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2305 [D loss: 1.094981, acc.: 50.00%] [G loss: 0.167138] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2306 [D loss: 1.097504, acc.: 49.90%] [G loss: 0.171784] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2307 [D loss: 1.097473, acc.: 50.00%] [G loss: 0.170489] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2308 [D loss: 1.080993, acc.: 50.00%] [G loss: 0.166558] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2309 [D loss: 1.080026, acc.: 50.00%] [G loss: 0.166307] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2310 [D loss: 1.106771, acc.: 49.71%] [G loss: 0.167320] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2311 [D loss: 1.098001, acc.: 50.00%] [G loss: 0.165482] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2312 [D loss: 1.106873, acc.: 49.71%] [G loss: 0.174044] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2313 [D loss: 1.075919, acc.: 49.90%] [G loss: 0.169152] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2314 [D loss: 1.095764, acc.: 49.90%] [G loss: 0.168776] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2315 [D loss: 1.091374, acc.: 50.00%] [G loss: 0.169690] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2316 [D loss: 1.092213, acc.: 49.90%] [G loss: 0.170026] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2317 [D loss: 1.101649, acc.: 49.71%] [G loss: 0.173715] [Loss difference: 0.004, iterations with loss: 2]\n",
      "2318 [D loss: 1.105885, acc.: 49.80%] [G loss: 0.165644] [Loss difference: -0.008, iterations with loss: 3]\n",
      "2319 [D loss: 1.088850, acc.: 49.80%] [G loss: 0.168850] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2320 [D loss: 1.096205, acc.: 50.00%] [G loss: 0.166426] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2321 [D loss: 1.095338, acc.: 49.71%] [G loss: 0.168862] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2322 [D loss: 1.093821, acc.: 50.00%] [G loss: 0.168668] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2323 [D loss: 1.089057, acc.: 49.71%] [G loss: 0.172278] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2324 [D loss: 1.078941, acc.: 49.80%] [G loss: 0.168962] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2325 [D loss: 1.080602, acc.: 50.00%] [G loss: 0.166797] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2326 [D loss: 1.082096, acc.: 49.90%] [G loss: 0.172897] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2327 [D loss: 1.084116, acc.: 49.80%] [G loss: 0.169683] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2328 [D loss: 1.083784, acc.: 49.80%] [G loss: 0.168239] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2329 [D loss: 1.078052, acc.: 50.00%] [G loss: 0.173839] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2330 [D loss: 1.104245, acc.: 49.51%] [G loss: 0.167753] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2331 [D loss: 1.079768, acc.: 49.90%] [G loss: 0.170180] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2332 [D loss: 1.079560, acc.: 50.00%] [G loss: 0.168067] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2333 [D loss: 1.089583, acc.: 49.71%] [G loss: 0.167913] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2334 [D loss: 1.092729, acc.: 50.00%] [G loss: 0.167809] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2335 [D loss: 1.082146, acc.: 50.00%] [G loss: 0.168596] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2336 [D loss: 1.092584, acc.: 49.90%] [G loss: 0.168125] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2337 [D loss: 1.072364, acc.: 50.00%] [G loss: 0.174682] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2338 [D loss: 1.075454, acc.: 49.80%] [G loss: 0.169679] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2339 [D loss: 1.073103, acc.: 50.00%] [G loss: 0.170184] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2340 [D loss: 1.073552, acc.: 49.90%] [G loss: 0.168003] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2341 [D loss: 1.091793, acc.: 49.80%] [G loss: 0.169582] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2342 [D loss: 1.098948, acc.: 49.80%] [G loss: 0.170075] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2343 [D loss: 1.095873, acc.: 49.90%] [G loss: 0.170911] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2344 [D loss: 1.081697, acc.: 49.80%] [G loss: 0.173856] [Loss difference: 0.003, iterations with loss: 3]\n",
      "2345 [D loss: 1.081691, acc.: 49.80%] [G loss: 0.166337] [Loss difference: -0.008, iterations with loss: 4]\n",
      "2346 [D loss: 1.060891, acc.: 50.00%] [G loss: 0.169453] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2347 [D loss: 1.070935, acc.: 49.90%] [G loss: 0.168871] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2348 [D loss: 1.078691, acc.: 50.00%] [G loss: 0.166111] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2349 [D loss: 1.085355, acc.: 49.90%] [G loss: 0.176125] [Loss difference: 0.010, iterations with loss: 0]\n",
      "2350 [D loss: 1.075325, acc.: 50.00%] [G loss: 0.169537] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2351 [D loss: 1.093487, acc.: 49.80%] [G loss: 0.164966] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2352 [D loss: 1.084429, acc.: 49.90%] [G loss: 0.168046] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2353 [D loss: 1.095072, acc.: 49.90%] [G loss: 0.166562] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2354 [D loss: 1.083809, acc.: 49.80%] [G loss: 0.170384] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2355 [D loss: 1.085903, acc.: 49.90%] [G loss: 0.170891] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2356 [D loss: 1.074580, acc.: 49.80%] [G loss: 0.177446] [Loss difference: 0.007, iterations with loss: 2]\n",
      "2357 [D loss: 1.073665, acc.: 49.90%] [G loss: 0.173304] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2358 [D loss: 1.075948, acc.: 49.90%] [G loss: 0.176750] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2359 [D loss: 1.087680, acc.: 50.00%] [G loss: 0.172474] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2360 [D loss: 1.083099, acc.: 49.90%] [G loss: 0.172482] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2361 [D loss: 1.088160, acc.: 50.00%] [G loss: 0.168267] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2362 [D loss: 1.072409, acc.: 50.00%] [G loss: 0.173251] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2363 [D loss: 1.074362, acc.: 49.90%] [G loss: 0.168246] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2364 [D loss: 1.075210, acc.: 49.80%] [G loss: 0.172981] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2365 [D loss: 1.079857, acc.: 49.90%] [G loss: 0.168973] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2366 [D loss: 1.070020, acc.: 49.90%] [G loss: 0.165127] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2367 [D loss: 1.100139, acc.: 49.80%] [G loss: 0.172582] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2368 [D loss: 1.064272, acc.: 49.90%] [G loss: 0.173177] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2369 [D loss: 1.066615, acc.: 50.00%] [G loss: 0.178796] [Loss difference: 0.006, iterations with loss: 2]\n",
      "2370 [D loss: 1.078309, acc.: 50.00%] [G loss: 0.174874] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2371 [D loss: 1.069009, acc.: 50.00%] [G loss: 0.173966] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2372 [D loss: 1.058348, acc.: 49.80%] [G loss: 0.174328] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2373 [D loss: 1.081951, acc.: 50.00%] [G loss: 0.171286] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2374 [D loss: 1.068361, acc.: 49.90%] [G loss: 0.173647] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2375 [D loss: 1.070453, acc.: 49.80%] [G loss: 0.171558] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2376 [D loss: 1.065340, acc.: 49.80%] [G loss: 0.175999] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2377 [D loss: 1.080008, acc.: 49.80%] [G loss: 0.174683] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2378 [D loss: 1.067491, acc.: 49.80%] [G loss: 0.173753] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2379 [D loss: 1.063472, acc.: 50.00%] [G loss: 0.180811] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2380 [D loss: 1.071354, acc.: 49.90%] [G loss: 0.174978] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2381 [D loss: 1.076175, acc.: 49.90%] [G loss: 0.173595] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2382 [D loss: 1.077410, acc.: 50.00%] [G loss: 0.173994] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2383 [D loss: 1.070753, acc.: 49.90%] [G loss: 0.178814] [Loss difference: 0.005, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2384 [D loss: 1.074015, acc.: 49.90%] [G loss: 0.175274] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2385 [D loss: 1.073213, acc.: 49.90%] [G loss: 0.173043] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2386 [D loss: 1.086385, acc.: 49.51%] [G loss: 0.175074] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2387 [D loss: 1.083710, acc.: 49.71%] [G loss: 0.167151] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2388 [D loss: 1.051763, acc.: 50.00%] [G loss: 0.172158] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2389 [D loss: 1.064289, acc.: 50.00%] [G loss: 0.172970] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2390 [D loss: 1.071325, acc.: 50.00%] [G loss: 0.177109] [Loss difference: 0.004, iterations with loss: 2]\n",
      "2391 [D loss: 1.076445, acc.: 49.90%] [G loss: 0.175945] [Loss difference: -0.001, iterations with loss: 3]\n",
      "2392 [D loss: 1.070099, acc.: 49.71%] [G loss: 0.177888] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2393 [D loss: 1.074715, acc.: 49.80%] [G loss: 0.177536] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2394 [D loss: 1.061057, acc.: 49.80%] [G loss: 0.174501] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2395 [D loss: 1.072777, acc.: 49.80%] [G loss: 0.170051] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2396 [D loss: 1.073684, acc.: 50.00%] [G loss: 0.176445] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2397 [D loss: 1.068747, acc.: 49.90%] [G loss: 0.173018] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2398 [D loss: 1.071612, acc.: 49.80%] [G loss: 0.177366] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2399 [D loss: 1.064556, acc.: 49.90%] [G loss: 0.175800] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2400 [D loss: 1.068525, acc.: 49.80%] [G loss: 0.175680] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2401 [D loss: 1.079796, acc.: 49.80%] [G loss: 0.175733] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2402 [D loss: 1.073637, acc.: 49.71%] [G loss: 0.175728] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2403 [D loss: 1.080864, acc.: 49.80%] [G loss: 0.175581] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2404 [D loss: 1.087639, acc.: 49.80%] [G loss: 0.175555] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2405 [D loss: 1.082054, acc.: 50.00%] [G loss: 0.176138] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2406 [D loss: 1.053155, acc.: 50.00%] [G loss: 0.169976] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2407 [D loss: 1.067874, acc.: 49.80%] [G loss: 0.175629] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2408 [D loss: 1.070611, acc.: 49.80%] [G loss: 0.175706] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2409 [D loss: 1.079237, acc.: 49.90%] [G loss: 0.175629] [Loss difference: -0.000, iterations with loss: 2]\n",
      "2410 [D loss: 1.067816, acc.: 49.90%] [G loss: 0.174952] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2411 [D loss: 1.068354, acc.: 50.00%] [G loss: 0.177313] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2412 [D loss: 1.067101, acc.: 49.80%] [G loss: 0.173275] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2413 [D loss: 1.073220, acc.: 49.51%] [G loss: 0.173294] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2414 [D loss: 1.060760, acc.: 49.80%] [G loss: 0.182167] [Loss difference: 0.009, iterations with loss: 1]\n",
      "2415 [D loss: 1.065364, acc.: 49.80%] [G loss: 0.175565] [Loss difference: -0.007, iterations with loss: 2]\n",
      "2416 [D loss: 1.074664, acc.: 49.80%] [G loss: 0.177607] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2417 [D loss: 1.076290, acc.: 49.80%] [G loss: 0.169420] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2418 [D loss: 1.065236, acc.: 49.90%] [G loss: 0.175172] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2419 [D loss: 1.061598, acc.: 49.90%] [G loss: 0.177309] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2420 [D loss: 1.070886, acc.: 49.90%] [G loss: 0.178215] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2421 [D loss: 1.053166, acc.: 49.90%] [G loss: 0.179613] [Loss difference: 0.001, iterations with loss: 3]\n",
      "2422 [D loss: 1.068429, acc.: 50.00%] [G loss: 0.179266] [Loss difference: -0.000, iterations with loss: 4]\n",
      "2423 [D loss: 1.058098, acc.: 50.00%] [G loss: 0.178246] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2424 [D loss: 1.066056, acc.: 49.71%] [G loss: 0.182778] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2425 [D loss: 1.061628, acc.: 49.80%] [G loss: 0.176063] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2426 [D loss: 1.051379, acc.: 50.00%] [G loss: 0.180140] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2427 [D loss: 1.055214, acc.: 50.00%] [G loss: 0.190532] [Loss difference: 0.010, iterations with loss: 1]\n",
      "2428 [D loss: 1.052011, acc.: 49.90%] [G loss: 0.180716] [Loss difference: -0.010, iterations with loss: 2]\n",
      "2429 [D loss: 1.071613, acc.: 49.90%] [G loss: 0.174118] [Loss difference: -0.007, iterations with loss: 0]\n",
      "2430 [D loss: 1.072191, acc.: 50.00%] [G loss: 0.170879] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2431 [D loss: 1.061790, acc.: 49.80%] [G loss: 0.179323] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2432 [D loss: 1.070479, acc.: 49.90%] [G loss: 0.176184] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2433 [D loss: 1.062352, acc.: 50.00%] [G loss: 0.176865] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2434 [D loss: 1.062870, acc.: 49.90%] [G loss: 0.184212] [Loss difference: 0.007, iterations with loss: 1]\n",
      "2435 [D loss: 1.057112, acc.: 49.80%] [G loss: 0.183014] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2436 [D loss: 1.054537, acc.: 49.80%] [G loss: 0.181906] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2437 [D loss: 1.052281, acc.: 49.61%] [G loss: 0.176512] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2438 [D loss: 1.062039, acc.: 50.00%] [G loss: 0.183717] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2439 [D loss: 1.056898, acc.: 49.71%] [G loss: 0.178368] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2440 [D loss: 1.047900, acc.: 49.90%] [G loss: 0.186918] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2441 [D loss: 1.060600, acc.: 49.61%] [G loss: 0.174981] [Loss difference: -0.012, iterations with loss: 1]\n",
      "2442 [D loss: 1.055045, acc.: 49.71%] [G loss: 0.176179] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2443 [D loss: 1.052101, acc.: 50.00%] [G loss: 0.178406] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2444 [D loss: 1.059983, acc.: 49.61%] [G loss: 0.175733] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2445 [D loss: 1.088218, acc.: 49.80%] [G loss: 0.175194] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2446 [D loss: 1.053631, acc.: 49.90%] [G loss: 0.175373] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2447 [D loss: 1.075867, acc.: 49.71%] [G loss: 0.176863] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2448 [D loss: 1.061731, acc.: 49.80%] [G loss: 0.181394] [Loss difference: 0.005, iterations with loss: 2]\n",
      "2449 [D loss: 1.051770, acc.: 49.80%] [G loss: 0.180756] [Loss difference: -0.001, iterations with loss: 3]\n",
      "2450 [D loss: 1.068595, acc.: 49.80%] [G loss: 0.180148] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2451 [D loss: 1.070785, acc.: 49.71%] [G loss: 0.174766] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2452 [D loss: 1.084857, acc.: 49.51%] [G loss: 0.177007] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2453 [D loss: 1.068936, acc.: 49.71%] [G loss: 0.181439] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2454 [D loss: 1.075698, acc.: 49.90%] [G loss: 0.176764] [Loss difference: -0.005, iterations with loss: 2]\n",
      "2455 [D loss: 1.048148, acc.: 49.90%] [G loss: 0.184464] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2456 [D loss: 1.073921, acc.: 49.90%] [G loss: 0.173515] [Loss difference: -0.011, iterations with loss: 1]\n",
      "2457 [D loss: 1.061666, acc.: 49.90%] [G loss: 0.177649] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2458 [D loss: 1.079190, acc.: 49.71%] [G loss: 0.180970] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2459 [D loss: 1.064271, acc.: 49.41%] [G loss: 0.181883] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2460 [D loss: 1.071423, acc.: 49.90%] [G loss: 0.179724] [Loss difference: -0.002, iterations with loss: 3]\n",
      "2461 [D loss: 1.056994, acc.: 49.61%] [G loss: 0.182525] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2462 [D loss: 1.069787, acc.: 49.51%] [G loss: 0.176287] [Loss difference: -0.006, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2463 [D loss: 1.062544, acc.: 49.71%] [G loss: 0.179975] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2464 [D loss: 1.064240, acc.: 49.71%] [G loss: 0.177221] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2465 [D loss: 1.048123, acc.: 49.71%] [G loss: 0.182149] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2466 [D loss: 1.060750, acc.: 49.80%] [G loss: 0.178041] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2467 [D loss: 1.060156, acc.: 49.90%] [G loss: 0.180298] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2468 [D loss: 1.060078, acc.: 49.90%] [G loss: 0.181849] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2469 [D loss: 1.057245, acc.: 49.90%] [G loss: 0.180449] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2470 [D loss: 1.064891, acc.: 50.00%] [G loss: 0.182303] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2471 [D loss: 1.059604, acc.: 49.90%] [G loss: 0.179424] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2472 [D loss: 1.055945, acc.: 50.00%] [G loss: 0.173485] [Loss difference: -0.006, iterations with loss: 0]\n",
      "2473 [D loss: 1.060387, acc.: 50.00%] [G loss: 0.181076] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2474 [D loss: 1.047244, acc.: 49.71%] [G loss: 0.183224] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2475 [D loss: 1.032250, acc.: 50.00%] [G loss: 0.178387] [Loss difference: -0.005, iterations with loss: 2]\n",
      "2476 [D loss: 1.060431, acc.: 49.80%] [G loss: 0.182883] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2477 [D loss: 1.059428, acc.: 49.90%] [G loss: 0.179286] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2478 [D loss: 1.049552, acc.: 50.00%] [G loss: 0.183926] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2479 [D loss: 1.043782, acc.: 50.00%] [G loss: 0.181664] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2480 [D loss: 1.073507, acc.: 49.61%] [G loss: 0.177607] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2481 [D loss: 1.040403, acc.: 49.51%] [G loss: 0.184879] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2482 [D loss: 1.048149, acc.: 49.90%] [G loss: 0.178221] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2483 [D loss: 1.042721, acc.: 50.00%] [G loss: 0.192078] [Loss difference: 0.014, iterations with loss: 0]\n",
      "2484 [D loss: 1.042738, acc.: 49.71%] [G loss: 0.187793] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2485 [D loss: 1.047505, acc.: 50.00%] [G loss: 0.183830] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2486 [D loss: 1.036221, acc.: 49.71%] [G loss: 0.184608] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2487 [D loss: 1.048383, acc.: 49.90%] [G loss: 0.183499] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2488 [D loss: 1.064642, acc.: 49.61%] [G loss: 0.181817] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2489 [D loss: 1.057254, acc.: 49.90%] [G loss: 0.183424] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2490 [D loss: 1.055614, acc.: 49.80%] [G loss: 0.181397] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2491 [D loss: 1.056561, acc.: 50.00%] [G loss: 0.180510] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2492 [D loss: 1.041294, acc.: 49.90%] [G loss: 0.179245] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2493 [D loss: 1.031486, acc.: 50.00%] [G loss: 0.185207] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2494 [D loss: 1.062025, acc.: 49.71%] [G loss: 0.181968] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2495 [D loss: 1.055113, acc.: 49.90%] [G loss: 0.185128] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2496 [D loss: 1.058092, acc.: 49.80%] [G loss: 0.180123] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2497 [D loss: 1.058215, acc.: 49.90%] [G loss: 0.185490] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2498 [D loss: 1.055440, acc.: 50.00%] [G loss: 0.180019] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2499 [D loss: 1.048715, acc.: 50.00%] [G loss: 0.181498] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2500 [D loss: 1.045534, acc.: 50.00%] [G loss: 0.192460] [Loss difference: 0.011, iterations with loss: 1]\n",
      "2501 [D loss: 1.027423, acc.: 49.90%] [G loss: 0.193873] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2502 [D loss: 1.044913, acc.: 49.71%] [G loss: 0.188540] [Loss difference: -0.005, iterations with loss: 3]\n",
      "2503 [D loss: 1.038869, acc.: 49.80%] [G loss: 0.182807] [Loss difference: -0.006, iterations with loss: 0]\n",
      "2504 [D loss: 1.052242, acc.: 49.90%] [G loss: 0.185226] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2505 [D loss: 1.057089, acc.: 50.00%] [G loss: 0.181283] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2506 [D loss: 1.051140, acc.: 49.80%] [G loss: 0.183724] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2507 [D loss: 1.045775, acc.: 49.80%] [G loss: 0.178618] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2508 [D loss: 1.045840, acc.: 49.90%] [G loss: 0.189477] [Loss difference: 0.011, iterations with loss: 0]\n",
      "2509 [D loss: 1.039660, acc.: 49.80%] [G loss: 0.187180] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2510 [D loss: 1.043682, acc.: 49.90%] [G loss: 0.188175] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2511 [D loss: 1.037455, acc.: 49.90%] [G loss: 0.188328] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2512 [D loss: 1.040457, acc.: 49.80%] [G loss: 0.184201] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2513 [D loss: 1.054130, acc.: 49.71%] [G loss: 0.185770] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2514 [D loss: 1.045928, acc.: 49.90%] [G loss: 0.185129] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2515 [D loss: 1.037292, acc.: 49.90%] [G loss: 0.185575] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2516 [D loss: 1.041504, acc.: 49.90%] [G loss: 0.183529] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2517 [D loss: 1.031044, acc.: 49.80%] [G loss: 0.185150] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2518 [D loss: 1.046883, acc.: 50.00%] [G loss: 0.184905] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2519 [D loss: 1.053649, acc.: 49.90%] [G loss: 0.183488] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2520 [D loss: 1.048690, acc.: 49.80%] [G loss: 0.183910] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2521 [D loss: 1.047499, acc.: 49.51%] [G loss: 0.183594] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2522 [D loss: 1.038569, acc.: 49.90%] [G loss: 0.187537] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2523 [D loss: 1.056116, acc.: 49.90%] [G loss: 0.188474] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2524 [D loss: 1.049920, acc.: 49.80%] [G loss: 0.189208] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2525 [D loss: 1.044037, acc.: 49.90%] [G loss: 0.190411] [Loss difference: 0.001, iterations with loss: 3]\n",
      "2526 [D loss: 1.042427, acc.: 49.90%] [G loss: 0.189135] [Loss difference: -0.001, iterations with loss: 4]\n",
      "2527 [D loss: 1.054578, acc.: 49.80%] [G loss: 0.181566] [Loss difference: -0.008, iterations with loss: 0]\n",
      "2528 [D loss: 1.074748, acc.: 50.00%] [G loss: 0.181373] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2529 [D loss: 1.046840, acc.: 49.80%] [G loss: 0.185302] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2530 [D loss: 1.052516, acc.: 49.80%] [G loss: 0.188868] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2531 [D loss: 1.059989, acc.: 49.61%] [G loss: 0.189570] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2532 [D loss: 1.039982, acc.: 49.71%] [G loss: 0.195519] [Loss difference: 0.006, iterations with loss: 3]\n",
      "2533 [D loss: 1.036054, acc.: 49.51%] [G loss: 0.188071] [Loss difference: -0.007, iterations with loss: 4]\n",
      "2534 [D loss: 1.048738, acc.: 49.90%] [G loss: 0.188854] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2535 [D loss: 1.031539, acc.: 49.41%] [G loss: 0.185509] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2536 [D loss: 1.045756, acc.: 49.90%] [G loss: 0.188116] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2537 [D loss: 1.039223, acc.: 49.90%] [G loss: 0.187620] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2538 [D loss: 1.039045, acc.: 50.00%] [G loss: 0.185652] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2539 [D loss: 1.050872, acc.: 49.61%] [G loss: 0.190965] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2540 [D loss: 1.058902, acc.: 49.80%] [G loss: 0.183960] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2541 [D loss: 1.053000, acc.: 49.61%] [G loss: 0.185760] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2542 [D loss: 1.038273, acc.: 49.90%] [G loss: 0.187776] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2543 [D loss: 1.054288, acc.: 49.90%] [G loss: 0.181198] [Loss difference: -0.007, iterations with loss: 2]\n",
      "2544 [D loss: 1.052720, acc.: 49.71%] [G loss: 0.186765] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2545 [D loss: 1.054160, acc.: 49.90%] [G loss: 0.188597] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2546 [D loss: 1.034019, acc.: 49.90%] [G loss: 0.182875] [Loss difference: -0.006, iterations with loss: 2]\n",
      "2547 [D loss: 1.058819, acc.: 50.00%] [G loss: 0.186823] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2548 [D loss: 1.035381, acc.: 50.00%] [G loss: 0.188349] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2549 [D loss: 1.049078, acc.: 49.51%] [G loss: 0.197959] [Loss difference: 0.010, iterations with loss: 2]\n",
      "2550 [D loss: 1.036756, acc.: 49.90%] [G loss: 0.188447] [Loss difference: -0.010, iterations with loss: 3]\n",
      "2551 [D loss: 1.044367, acc.: 49.71%] [G loss: 0.185500] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2552 [D loss: 1.047637, acc.: 49.51%] [G loss: 0.186020] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2553 [D loss: 1.048304, acc.: 49.90%] [G loss: 0.192781] [Loss difference: 0.007, iterations with loss: 1]\n",
      "2554 [D loss: 1.028268, acc.: 49.71%] [G loss: 0.184780] [Loss difference: -0.008, iterations with loss: 2]\n",
      "2555 [D loss: 1.039998, acc.: 49.80%] [G loss: 0.188308] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2556 [D loss: 1.043563, acc.: 50.00%] [G loss: 0.188206] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2557 [D loss: 1.050862, acc.: 49.80%] [G loss: 0.190047] [Loss difference: 0.002, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558 [D loss: 1.044639, acc.: 49.80%] [G loss: 0.191957] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2559 [D loss: 1.047850, acc.: 49.90%] [G loss: 0.188954] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2560 [D loss: 1.058924, acc.: 49.80%] [G loss: 0.185960] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2561 [D loss: 1.054830, acc.: 49.61%] [G loss: 0.188329] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2562 [D loss: 1.039265, acc.: 49.71%] [G loss: 0.187866] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2563 [D loss: 1.051057, acc.: 49.90%] [G loss: 0.196615] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2564 [D loss: 1.025582, acc.: 49.90%] [G loss: 0.189733] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2565 [D loss: 1.039996, acc.: 49.80%] [G loss: 0.188093] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2566 [D loss: 1.036100, acc.: 49.71%] [G loss: 0.187493] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2567 [D loss: 1.038958, acc.: 49.90%] [G loss: 0.187024] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2568 [D loss: 1.046290, acc.: 49.71%] [G loss: 0.188494] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2569 [D loss: 1.035261, acc.: 49.80%] [G loss: 0.191308] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2570 [D loss: 1.036440, acc.: 49.90%] [G loss: 0.188172] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2571 [D loss: 1.038153, acc.: 49.80%] [G loss: 0.187286] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2572 [D loss: 1.036465, acc.: 49.90%] [G loss: 0.193261] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2573 [D loss: 1.035638, acc.: 49.90%] [G loss: 0.194093] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2574 [D loss: 1.044075, acc.: 49.80%] [G loss: 0.191828] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2575 [D loss: 1.054204, acc.: 49.80%] [G loss: 0.193045] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2576 [D loss: 1.040450, acc.: 49.80%] [G loss: 0.193594] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2577 [D loss: 1.032322, acc.: 49.80%] [G loss: 0.186106] [Loss difference: -0.007, iterations with loss: 2]\n",
      "2578 [D loss: 1.050891, acc.: 49.80%] [G loss: 0.190553] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2579 [D loss: 1.051624, acc.: 49.80%] [G loss: 0.191157] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2580 [D loss: 1.030687, acc.: 50.00%] [G loss: 0.188750] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2581 [D loss: 1.034684, acc.: 49.90%] [G loss: 0.188155] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2582 [D loss: 1.037426, acc.: 50.00%] [G loss: 0.188730] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2583 [D loss: 1.034490, acc.: 49.80%] [G loss: 0.193910] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2584 [D loss: 1.019814, acc.: 50.00%] [G loss: 0.201748] [Loss difference: 0.008, iterations with loss: 2]\n",
      "2585 [D loss: 1.024554, acc.: 50.00%] [G loss: 0.193924] [Loss difference: -0.008, iterations with loss: 3]\n",
      "2586 [D loss: 1.047081, acc.: 49.90%] [G loss: 0.188267] [Loss difference: -0.006, iterations with loss: 0]\n",
      "2587 [D loss: 1.042339, acc.: 49.90%] [G loss: 0.191924] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2588 [D loss: 1.026965, acc.: 49.80%] [G loss: 0.192375] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2589 [D loss: 1.043199, acc.: 49.80%] [G loss: 0.182592] [Loss difference: -0.010, iterations with loss: 2]\n",
      "2590 [D loss: 1.059457, acc.: 49.71%] [G loss: 0.191954] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2591 [D loss: 1.051051, acc.: 49.71%] [G loss: 0.183861] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2592 [D loss: 1.060351, acc.: 49.80%] [G loss: 0.185398] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2593 [D loss: 1.041974, acc.: 49.90%] [G loss: 0.190706] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2594 [D loss: 1.057855, acc.: 49.71%] [G loss: 0.194552] [Loss difference: 0.004, iterations with loss: 2]\n",
      "2595 [D loss: 1.035387, acc.: 49.80%] [G loss: 0.196517] [Loss difference: 0.002, iterations with loss: 3]\n",
      "2596 [D loss: 1.035120, acc.: 49.90%] [G loss: 0.199137] [Loss difference: 0.003, iterations with loss: 4]\n",
      "2597 [D loss: 1.013690, acc.: 49.80%] [G loss: 0.198494] [Loss difference: -0.001, iterations with loss: 5]\n",
      "2598 [D loss: 1.025520, acc.: 49.90%] [G loss: 0.194406] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2599 [D loss: 1.036697, acc.: 49.90%] [G loss: 0.189002] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2600 [D loss: 1.024405, acc.: 49.90%] [G loss: 0.192592] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2601 [D loss: 1.027375, acc.: 49.90%] [G loss: 0.198613] [Loss difference: 0.006, iterations with loss: 1]\n",
      "2602 [D loss: 1.036361, acc.: 49.90%] [G loss: 0.192346] [Loss difference: -0.006, iterations with loss: 2]\n",
      "2603 [D loss: 1.027705, acc.: 49.90%] [G loss: 0.189786] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2604 [D loss: 1.019227, acc.: 49.90%] [G loss: 0.196552] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2605 [D loss: 1.042873, acc.: 49.80%] [G loss: 0.197456] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2606 [D loss: 1.032381, acc.: 49.80%] [G loss: 0.196333] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2607 [D loss: 1.025848, acc.: 50.00%] [G loss: 0.192197] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2608 [D loss: 1.022614, acc.: 49.90%] [G loss: 0.193248] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2609 [D loss: 1.023108, acc.: 49.80%] [G loss: 0.193603] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2610 [D loss: 1.028594, acc.: 49.90%] [G loss: 0.194822] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2611 [D loss: 1.036142, acc.: 49.51%] [G loss: 0.188335] [Loss difference: -0.006, iterations with loss: 3]\n",
      "2612 [D loss: 1.015443, acc.: 50.00%] [G loss: 0.190337] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2613 [D loss: 1.046459, acc.: 49.71%] [G loss: 0.195418] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2614 [D loss: 1.031200, acc.: 50.00%] [G loss: 0.195426] [Loss difference: 0.000, iterations with loss: 2]\n",
      "2615 [D loss: 1.039811, acc.: 49.71%] [G loss: 0.191445] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2616 [D loss: 1.040148, acc.: 49.61%] [G loss: 0.192762] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2617 [D loss: 1.022176, acc.: 50.00%] [G loss: 0.197061] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2618 [D loss: 1.009333, acc.: 49.80%] [G loss: 0.199779] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2619 [D loss: 1.040430, acc.: 49.71%] [G loss: 0.195752] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2620 [D loss: 1.031133, acc.: 49.80%] [G loss: 0.197304] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2621 [D loss: 1.037757, acc.: 49.71%] [G loss: 0.190507] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2622 [D loss: 1.047330, acc.: 49.80%] [G loss: 0.194011] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2623 [D loss: 1.041685, acc.: 50.00%] [G loss: 0.193433] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2624 [D loss: 1.040998, acc.: 49.80%] [G loss: 0.198372] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2625 [D loss: 1.017484, acc.: 49.90%] [G loss: 0.198268] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2626 [D loss: 1.032336, acc.: 49.90%] [G loss: 0.194651] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2627 [D loss: 1.050936, acc.: 49.71%] [G loss: 0.192895] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2628 [D loss: 1.045348, acc.: 49.80%] [G loss: 0.195942] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2629 [D loss: 1.050619, acc.: 49.41%] [G loss: 0.195559] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2630 [D loss: 1.021418, acc.: 49.71%] [G loss: 0.193791] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2631 [D loss: 1.042368, acc.: 49.32%] [G loss: 0.195640] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2632 [D loss: 1.048982, acc.: 49.80%] [G loss: 0.191138] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2633 [D loss: 1.041285, acc.: 49.90%] [G loss: 0.191536] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2634 [D loss: 1.042074, acc.: 50.00%] [G loss: 0.198092] [Loss difference: 0.007, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635 [D loss: 1.032078, acc.: 49.61%] [G loss: 0.188807] [Loss difference: -0.009, iterations with loss: 2]\n",
      "2636 [D loss: 1.038177, acc.: 50.00%] [G loss: 0.196991] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2637 [D loss: 1.013810, acc.: 49.80%] [G loss: 0.201044] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2638 [D loss: 1.015636, acc.: 49.90%] [G loss: 0.201653] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2639 [D loss: 1.028242, acc.: 49.90%] [G loss: 0.194125] [Loss difference: -0.008, iterations with loss: 3]\n",
      "2640 [D loss: 1.031841, acc.: 49.71%] [G loss: 0.196801] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2641 [D loss: 1.029622, acc.: 49.71%] [G loss: 0.191169] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2642 [D loss: 1.013501, acc.: 50.00%] [G loss: 0.194524] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2643 [D loss: 1.025334, acc.: 49.90%] [G loss: 0.199108] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2644 [D loss: 1.038804, acc.: 49.71%] [G loss: 0.199726] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2645 [D loss: 1.036617, acc.: 49.80%] [G loss: 0.192280] [Loss difference: -0.007, iterations with loss: 3]\n",
      "2646 [D loss: 1.032337, acc.: 49.90%] [G loss: 0.194184] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2647 [D loss: 1.013090, acc.: 49.71%] [G loss: 0.192647] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2648 [D loss: 1.034926, acc.: 49.71%] [G loss: 0.194484] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2649 [D loss: 1.031727, acc.: 49.90%] [G loss: 0.194934] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2650 [D loss: 1.025765, acc.: 49.80%] [G loss: 0.198963] [Loss difference: 0.004, iterations with loss: 2]\n",
      "2651 [D loss: 1.017524, acc.: 50.00%] [G loss: 0.197895] [Loss difference: -0.001, iterations with loss: 3]\n",
      "2652 [D loss: 1.016555, acc.: 49.71%] [G loss: 0.193979] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2653 [D loss: 1.027077, acc.: 50.00%] [G loss: 0.192922] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2654 [D loss: 1.046743, acc.: 49.71%] [G loss: 0.190530] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2655 [D loss: 1.026399, acc.: 49.90%] [G loss: 0.195069] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2656 [D loss: 1.032007, acc.: 49.51%] [G loss: 0.198897] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2657 [D loss: 1.045994, acc.: 49.61%] [G loss: 0.192852] [Loss difference: -0.006, iterations with loss: 2]\n",
      "2658 [D loss: 1.019951, acc.: 49.80%] [G loss: 0.200473] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2659 [D loss: 1.017329, acc.: 49.80%] [G loss: 0.198549] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2660 [D loss: 1.029879, acc.: 49.61%] [G loss: 0.196880] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2661 [D loss: 1.019291, acc.: 50.00%] [G loss: 0.206132] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2662 [D loss: 1.019321, acc.: 49.61%] [G loss: 0.198394] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2663 [D loss: 1.011384, acc.: 49.90%] [G loss: 0.193538] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2664 [D loss: 1.026685, acc.: 49.90%] [G loss: 0.191882] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2665 [D loss: 1.028858, acc.: 49.61%] [G loss: 0.191707] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2666 [D loss: 1.042960, acc.: 49.71%] [G loss: 0.200190] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2667 [D loss: 1.039274, acc.: 49.80%] [G loss: 0.198248] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2668 [D loss: 1.045002, acc.: 49.61%] [G loss: 0.197744] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2669 [D loss: 1.029905, acc.: 49.71%] [G loss: 0.199841] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2670 [D loss: 1.032957, acc.: 49.90%] [G loss: 0.201018] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2671 [D loss: 1.031093, acc.: 49.61%] [G loss: 0.200733] [Loss difference: -0.000, iterations with loss: 2]\n",
      "2672 [D loss: 1.039292, acc.: 49.71%] [G loss: 0.195381] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2673 [D loss: 1.034070, acc.: 49.80%] [G loss: 0.206047] [Loss difference: 0.011, iterations with loss: 0]\n",
      "2674 [D loss: 1.013625, acc.: 50.00%] [G loss: 0.197895] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2675 [D loss: 1.022109, acc.: 49.80%] [G loss: 0.200310] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2676 [D loss: 1.010143, acc.: 49.90%] [G loss: 0.199983] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2677 [D loss: 1.030972, acc.: 49.90%] [G loss: 0.195035] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2678 [D loss: 1.018074, acc.: 49.90%] [G loss: 0.203890] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2679 [D loss: 1.027657, acc.: 49.90%] [G loss: 0.192962] [Loss difference: -0.011, iterations with loss: 1]\n",
      "2680 [D loss: 1.024039, acc.: 49.71%] [G loss: 0.194146] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2681 [D loss: 1.030662, acc.: 49.90%] [G loss: 0.195674] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2682 [D loss: 1.031818, acc.: 49.71%] [G loss: 0.202097] [Loss difference: 0.006, iterations with loss: 2]\n",
      "2683 [D loss: 1.028909, acc.: 49.90%] [G loss: 0.201796] [Loss difference: -0.000, iterations with loss: 3]\n",
      "2684 [D loss: 1.018610, acc.: 49.90%] [G loss: 0.196526] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2685 [D loss: 1.016622, acc.: 49.80%] [G loss: 0.201507] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2686 [D loss: 1.026250, acc.: 49.90%] [G loss: 0.201814] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2687 [D loss: 1.020125, acc.: 50.00%] [G loss: 0.203355] [Loss difference: 0.002, iterations with loss: 2]\n",
      "2688 [D loss: 1.022107, acc.: 49.90%] [G loss: 0.206524] [Loss difference: 0.003, iterations with loss: 3]\n",
      "2689 [D loss: 1.039036, acc.: 49.80%] [G loss: 0.200058] [Loss difference: -0.006, iterations with loss: 4]\n",
      "2690 [D loss: 1.020172, acc.: 49.90%] [G loss: 0.196625] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2691 [D loss: 1.033252, acc.: 50.00%] [G loss: 0.198691] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2692 [D loss: 1.032522, acc.: 49.71%] [G loss: 0.198905] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2693 [D loss: 1.009611, acc.: 49.90%] [G loss: 0.194951] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2694 [D loss: 1.019307, acc.: 50.00%] [G loss: 0.198919] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2695 [D loss: 1.019020, acc.: 50.00%] [G loss: 0.196575] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2696 [D loss: 1.010470, acc.: 49.90%] [G loss: 0.204595] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2697 [D loss: 1.025597, acc.: 49.90%] [G loss: 0.200159] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2698 [D loss: 1.003386, acc.: 49.90%] [G loss: 0.207462] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2699 [D loss: 1.019649, acc.: 49.80%] [G loss: 0.204842] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2700 [D loss: 1.008139, acc.: 49.80%] [G loss: 0.206962] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2701 [D loss: 1.005453, acc.: 49.90%] [G loss: 0.196869] [Loss difference: -0.010, iterations with loss: 1]\n",
      "2702 [D loss: 1.018318, acc.: 50.00%] [G loss: 0.204599] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2703 [D loss: 1.006332, acc.: 50.00%] [G loss: 0.203384] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2704 [D loss: 1.032344, acc.: 49.71%] [G loss: 0.208412] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2705 [D loss: 1.009696, acc.: 49.80%] [G loss: 0.201716] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2706 [D loss: 1.033248, acc.: 49.71%] [G loss: 0.193465] [Loss difference: -0.008, iterations with loss: 0]\n",
      "2707 [D loss: 1.023892, acc.: 49.90%] [G loss: 0.199463] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2708 [D loss: 1.044465, acc.: 49.90%] [G loss: 0.199300] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2709 [D loss: 1.008432, acc.: 49.90%] [G loss: 0.205496] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2710 [D loss: 1.029080, acc.: 49.71%] [G loss: 0.209075] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2711 [D loss: 1.026398, acc.: 49.80%] [G loss: 0.198008] [Loss difference: -0.011, iterations with loss: 2]\n",
      "2712 [D loss: 1.018555, acc.: 49.61%] [G loss: 0.198071] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2713 [D loss: 1.006802, acc.: 49.90%] [G loss: 0.205872] [Loss difference: 0.008, iterations with loss: 1]\n",
      "2714 [D loss: 1.017769, acc.: 49.90%] [G loss: 0.198277] [Loss difference: -0.008, iterations with loss: 2]\n",
      "2715 [D loss: 1.019028, acc.: 50.00%] [G loss: 0.202139] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2716 [D loss: 1.012135, acc.: 50.00%] [G loss: 0.204370] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2717 [D loss: 1.010087, acc.: 49.90%] [G loss: 0.203978] [Loss difference: -0.000, iterations with loss: 2]\n",
      "2718 [D loss: 1.014911, acc.: 49.80%] [G loss: 0.194050] [Loss difference: -0.010, iterations with loss: 0]\n",
      "2719 [D loss: 1.028355, acc.: 49.61%] [G loss: 0.200870] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2720 [D loss: 1.017867, acc.: 49.80%] [G loss: 0.201476] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2721 [D loss: 1.010425, acc.: 50.00%] [G loss: 0.199541] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2722 [D loss: 1.040455, acc.: 49.71%] [G loss: 0.199400] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2723 [D loss: 1.024739, acc.: 50.00%] [G loss: 0.204025] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2724 [D loss: 1.030221, acc.: 49.71%] [G loss: 0.205352] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2725 [D loss: 1.009029, acc.: 49.90%] [G loss: 0.203460] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2726 [D loss: 1.008711, acc.: 49.80%] [G loss: 0.203631] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2727 [D loss: 1.020493, acc.: 49.90%] [G loss: 0.206868] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2728 [D loss: 0.995577, acc.: 49.90%] [G loss: 0.207653] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2729 [D loss: 1.014948, acc.: 49.80%] [G loss: 0.206106] [Loss difference: -0.002, iterations with loss: 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2730 [D loss: 1.027774, acc.: 49.71%] [G loss: 0.202431] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2731 [D loss: 1.007152, acc.: 49.80%] [G loss: 0.208005] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2732 [D loss: 1.006058, acc.: 50.00%] [G loss: 0.207002] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2733 [D loss: 1.019890, acc.: 49.90%] [G loss: 0.211134] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2734 [D loss: 1.007012, acc.: 49.90%] [G loss: 0.206588] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2735 [D loss: 1.029708, acc.: 49.51%] [G loss: 0.204245] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2736 [D loss: 1.017356, acc.: 49.71%] [G loss: 0.209962] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2737 [D loss: 1.020789, acc.: 49.90%] [G loss: 0.202947] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2738 [D loss: 1.031233, acc.: 49.80%] [G loss: 0.198853] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2739 [D loss: 1.015288, acc.: 49.90%] [G loss: 0.200421] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2740 [D loss: 1.026565, acc.: 49.80%] [G loss: 0.202370] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2741 [D loss: 1.007140, acc.: 49.90%] [G loss: 0.208442] [Loss difference: 0.006, iterations with loss: 2]\n",
      "2742 [D loss: 1.021012, acc.: 49.61%] [G loss: 0.202142] [Loss difference: -0.006, iterations with loss: 3]\n",
      "2743 [D loss: 1.000967, acc.: 50.00%] [G loss: 0.203570] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2744 [D loss: 1.008722, acc.: 49.90%] [G loss: 0.201225] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2745 [D loss: 1.017731, acc.: 49.71%] [G loss: 0.206633] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2746 [D loss: 1.011894, acc.: 49.80%] [G loss: 0.209182] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2747 [D loss: 1.017922, acc.: 49.90%] [G loss: 0.203953] [Loss difference: -0.005, iterations with loss: 2]\n",
      "2748 [D loss: 1.015703, acc.: 49.71%] [G loss: 0.209379] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2749 [D loss: 1.019814, acc.: 49.71%] [G loss: 0.204450] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2750 [D loss: 1.021272, acc.: 49.71%] [G loss: 0.204327] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2751 [D loss: 1.015829, acc.: 49.61%] [G loss: 0.201514] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2752 [D loss: 1.023729, acc.: 49.80%] [G loss: 0.203429] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2753 [D loss: 1.004120, acc.: 49.90%] [G loss: 0.204619] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2754 [D loss: 1.028875, acc.: 49.71%] [G loss: 0.202517] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2755 [D loss: 1.003279, acc.: 50.00%] [G loss: 0.204367] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2756 [D loss: 1.006889, acc.: 50.00%] [G loss: 0.203037] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2757 [D loss: 1.008380, acc.: 49.80%] [G loss: 0.209251] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2758 [D loss: 1.009023, acc.: 49.71%] [G loss: 0.207249] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2759 [D loss: 1.010593, acc.: 49.90%] [G loss: 0.199597] [Loss difference: -0.008, iterations with loss: 0]\n",
      "2760 [D loss: 1.005471, acc.: 49.90%] [G loss: 0.202987] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2761 [D loss: 1.002617, acc.: 49.90%] [G loss: 0.212048] [Loss difference: 0.009, iterations with loss: 1]\n",
      "2762 [D loss: 0.999014, acc.: 50.00%] [G loss: 0.212649] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2763 [D loss: 0.994906, acc.: 49.80%] [G loss: 0.204766] [Loss difference: -0.008, iterations with loss: 3]\n",
      "2764 [D loss: 1.017381, acc.: 49.71%] [G loss: 0.211082] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2765 [D loss: 0.998893, acc.: 49.80%] [G loss: 0.210780] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2766 [D loss: 1.008172, acc.: 49.90%] [G loss: 0.205827] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2767 [D loss: 0.993291, acc.: 49.71%] [G loss: 0.204527] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2768 [D loss: 1.004161, acc.: 49.80%] [G loss: 0.210974] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2769 [D loss: 1.000823, acc.: 49.90%] [G loss: 0.214840] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2770 [D loss: 0.994078, acc.: 49.80%] [G loss: 0.210613] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2771 [D loss: 1.015273, acc.: 49.80%] [G loss: 0.202651] [Loss difference: -0.008, iterations with loss: 0]\n",
      "2772 [D loss: 1.004192, acc.: 49.80%] [G loss: 0.207396] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2773 [D loss: 1.008989, acc.: 49.80%] [G loss: 0.211507] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2774 [D loss: 1.006148, acc.: 49.90%] [G loss: 0.203515] [Loss difference: -0.008, iterations with loss: 2]\n",
      "2775 [D loss: 1.006808, acc.: 49.61%] [G loss: 0.210899] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2776 [D loss: 0.999342, acc.: 50.00%] [G loss: 0.218638] [Loss difference: 0.008, iterations with loss: 1]\n",
      "2777 [D loss: 0.991527, acc.: 49.90%] [G loss: 0.207134] [Loss difference: -0.012, iterations with loss: 2]\n",
      "2778 [D loss: 1.000408, acc.: 49.80%] [G loss: 0.204915] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2779 [D loss: 0.992784, acc.: 49.80%] [G loss: 0.207065] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2780 [D loss: 1.010687, acc.: 49.80%] [G loss: 0.205803] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2781 [D loss: 1.011107, acc.: 49.71%] [G loss: 0.214130] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2782 [D loss: 0.996862, acc.: 49.80%] [G loss: 0.211156] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2783 [D loss: 1.014050, acc.: 49.90%] [G loss: 0.214499] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2784 [D loss: 1.018148, acc.: 49.80%] [G loss: 0.209508] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2785 [D loss: 1.003137, acc.: 49.90%] [G loss: 0.199812] [Loss difference: -0.010, iterations with loss: 0]\n",
      "2786 [D loss: 1.015055, acc.: 49.80%] [G loss: 0.212114] [Loss difference: 0.012, iterations with loss: 0]\n",
      "2787 [D loss: 0.994877, acc.: 49.80%] [G loss: 0.202448] [Loss difference: -0.010, iterations with loss: 1]\n",
      "2788 [D loss: 1.001582, acc.: 49.71%] [G loss: 0.211672] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2789 [D loss: 0.995759, acc.: 49.90%] [G loss: 0.213519] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2790 [D loss: 0.996256, acc.: 49.61%] [G loss: 0.218384] [Loss difference: 0.005, iterations with loss: 2]\n",
      "2791 [D loss: 0.989572, acc.: 49.90%] [G loss: 0.211599] [Loss difference: -0.007, iterations with loss: 3]\n",
      "2792 [D loss: 0.985145, acc.: 50.00%] [G loss: 0.214270] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2793 [D loss: 1.010200, acc.: 49.80%] [G loss: 0.220238] [Loss difference: 0.006, iterations with loss: 1]\n",
      "2794 [D loss: 1.025092, acc.: 49.80%] [G loss: 0.211007] [Loss difference: -0.009, iterations with loss: 2]\n",
      "2795 [D loss: 0.997887, acc.: 50.00%] [G loss: 0.207189] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2796 [D loss: 1.009802, acc.: 49.71%] [G loss: 0.202366] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2797 [D loss: 1.009501, acc.: 49.80%] [G loss: 0.208618] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2798 [D loss: 1.011459, acc.: 49.90%] [G loss: 0.210572] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2799 [D loss: 1.004903, acc.: 49.90%] [G loss: 0.207984] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2800 [D loss: 0.993265, acc.: 49.71%] [G loss: 0.213129] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2801 [D loss: 1.000615, acc.: 49.90%] [G loss: 0.212157] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2802 [D loss: 0.992050, acc.: 50.00%] [G loss: 0.210984] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2803 [D loss: 0.999881, acc.: 49.90%] [G loss: 0.211313] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2804 [D loss: 0.997029, acc.: 49.61%] [G loss: 0.209811] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2805 [D loss: 1.020002, acc.: 49.51%] [G loss: 0.209149] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2806 [D loss: 1.000899, acc.: 49.90%] [G loss: 0.211168] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2807 [D loss: 1.006118, acc.: 49.90%] [G loss: 0.210299] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2808 [D loss: 0.980056, acc.: 50.00%] [G loss: 0.210647] [Loss difference: 0.000, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809 [D loss: 1.001867, acc.: 49.80%] [G loss: 0.211729] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2810 [D loss: 1.001583, acc.: 49.90%] [G loss: 0.216937] [Loss difference: 0.005, iterations with loss: 2]\n",
      "2811 [D loss: 0.991410, acc.: 50.00%] [G loss: 0.217169] [Loss difference: 0.000, iterations with loss: 3]\n",
      "2812 [D loss: 1.009920, acc.: 49.71%] [G loss: 0.212938] [Loss difference: -0.004, iterations with loss: 4]\n",
      "2813 [D loss: 1.012710, acc.: 49.51%] [G loss: 0.212088] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2814 [D loss: 1.010486, acc.: 49.80%] [G loss: 0.214295] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2815 [D loss: 1.001062, acc.: 49.80%] [G loss: 0.214079] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2816 [D loss: 1.007254, acc.: 49.61%] [G loss: 0.212678] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2817 [D loss: 1.020862, acc.: 50.00%] [G loss: 0.220647] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2818 [D loss: 1.009190, acc.: 49.90%] [G loss: 0.214507] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2819 [D loss: 0.996894, acc.: 49.90%] [G loss: 0.214524] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2820 [D loss: 1.001208, acc.: 49.90%] [G loss: 0.215965] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2821 [D loss: 0.998632, acc.: 49.80%] [G loss: 0.216160] [Loss difference: 0.000, iterations with loss: 2]\n",
      "2822 [D loss: 1.007445, acc.: 49.80%] [G loss: 0.216969] [Loss difference: 0.001, iterations with loss: 3]\n",
      "2823 [D loss: 1.001407, acc.: 49.90%] [G loss: 0.213616] [Loss difference: -0.003, iterations with loss: 4]\n",
      "2824 [D loss: 1.002226, acc.: 49.90%] [G loss: 0.215492] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2825 [D loss: 0.999137, acc.: 49.71%] [G loss: 0.210093] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2826 [D loss: 1.007956, acc.: 49.80%] [G loss: 0.217939] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2827 [D loss: 1.006659, acc.: 49.90%] [G loss: 0.211088] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2828 [D loss: 1.002831, acc.: 49.90%] [G loss: 0.208416] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2829 [D loss: 0.999215, acc.: 50.00%] [G loss: 0.215645] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2830 [D loss: 1.009057, acc.: 49.71%] [G loss: 0.216752] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2831 [D loss: 1.015023, acc.: 49.61%] [G loss: 0.216638] [Loss difference: -0.000, iterations with loss: 2]\n",
      "2832 [D loss: 0.992171, acc.: 49.80%] [G loss: 0.208268] [Loss difference: -0.008, iterations with loss: 0]\n",
      "2833 [D loss: 1.008982, acc.: 49.71%] [G loss: 0.215578] [Loss difference: 0.007, iterations with loss: 0]\n",
      "2834 [D loss: 1.005835, acc.: 49.80%] [G loss: 0.215652] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2835 [D loss: 0.985305, acc.: 49.90%] [G loss: 0.213113] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2836 [D loss: 1.006941, acc.: 49.61%] [G loss: 0.216597] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2837 [D loss: 0.996266, acc.: 49.71%] [G loss: 0.214087] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2838 [D loss: 0.997606, acc.: 49.80%] [G loss: 0.209963] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2839 [D loss: 0.984343, acc.: 49.90%] [G loss: 0.214660] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2840 [D loss: 1.004373, acc.: 49.90%] [G loss: 0.212380] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2841 [D loss: 1.001181, acc.: 49.90%] [G loss: 0.213671] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2842 [D loss: 0.989486, acc.: 49.61%] [G loss: 0.220538] [Loss difference: 0.007, iterations with loss: 1]\n",
      "2843 [D loss: 0.991336, acc.: 49.51%] [G loss: 0.218013] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2844 [D loss: 0.998420, acc.: 49.61%] [G loss: 0.219157] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2845 [D loss: 0.991670, acc.: 49.90%] [G loss: 0.217176] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2846 [D loss: 1.008260, acc.: 49.80%] [G loss: 0.213572] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2847 [D loss: 0.984313, acc.: 49.90%] [G loss: 0.213556] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2848 [D loss: 1.001245, acc.: 49.90%] [G loss: 0.214821] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2849 [D loss: 1.019105, acc.: 49.61%] [G loss: 0.209676] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2850 [D loss: 0.998889, acc.: 49.90%] [G loss: 0.210711] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2851 [D loss: 0.994456, acc.: 49.71%] [G loss: 0.213545] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2852 [D loss: 1.002235, acc.: 49.80%] [G loss: 0.218298] [Loss difference: 0.005, iterations with loss: 2]\n",
      "2853 [D loss: 0.999291, acc.: 50.00%] [G loss: 0.215368] [Loss difference: -0.003, iterations with loss: 3]\n",
      "2854 [D loss: 0.999745, acc.: 49.71%] [G loss: 0.221070] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2855 [D loss: 1.002878, acc.: 49.71%] [G loss: 0.221594] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2856 [D loss: 0.991535, acc.: 49.90%] [G loss: 0.218536] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2857 [D loss: 0.985738, acc.: 50.00%] [G loss: 0.216036] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2858 [D loss: 0.989707, acc.: 49.90%] [G loss: 0.220605] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2859 [D loss: 0.996904, acc.: 49.90%] [G loss: 0.213330] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2860 [D loss: 1.001746, acc.: 49.71%] [G loss: 0.216275] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2861 [D loss: 0.990471, acc.: 49.90%] [G loss: 0.216727] [Loss difference: 0.000, iterations with loss: 1]\n",
      "2862 [D loss: 0.987814, acc.: 49.90%] [G loss: 0.214505] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2863 [D loss: 1.006449, acc.: 49.80%] [G loss: 0.217932] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2864 [D loss: 1.000584, acc.: 49.90%] [G loss: 0.223602] [Loss difference: 0.006, iterations with loss: 1]\n",
      "2865 [D loss: 0.982371, acc.: 49.90%] [G loss: 0.213071] [Loss difference: -0.011, iterations with loss: 2]\n",
      "2866 [D loss: 1.002175, acc.: 49.90%] [G loss: 0.216459] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2867 [D loss: 1.000369, acc.: 49.90%] [G loss: 0.217061] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2868 [D loss: 0.993008, acc.: 50.00%] [G loss: 0.215879] [Loss difference: -0.001, iterations with loss: 2]\n",
      "2869 [D loss: 1.003927, acc.: 50.00%] [G loss: 0.210751] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2870 [D loss: 0.994333, acc.: 50.00%] [G loss: 0.213952] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2871 [D loss: 1.014911, acc.: 49.71%] [G loss: 0.220874] [Loss difference: 0.007, iterations with loss: 1]\n",
      "2872 [D loss: 0.986090, acc.: 49.80%] [G loss: 0.222031] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2873 [D loss: 0.991433, acc.: 49.90%] [G loss: 0.220680] [Loss difference: -0.001, iterations with loss: 3]\n",
      "2874 [D loss: 0.989628, acc.: 49.71%] [G loss: 0.222777] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2875 [D loss: 0.977239, acc.: 50.00%] [G loss: 0.221975] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2876 [D loss: 0.978591, acc.: 50.00%] [G loss: 0.218531] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2877 [D loss: 0.985680, acc.: 49.90%] [G loss: 0.218672] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2878 [D loss: 0.992536, acc.: 49.80%] [G loss: 0.218286] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2879 [D loss: 0.990957, acc.: 49.90%] [G loss: 0.217430] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2880 [D loss: 1.000981, acc.: 49.90%] [G loss: 0.216836] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2881 [D loss: 0.991204, acc.: 50.00%] [G loss: 0.222148] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2882 [D loss: 0.992030, acc.: 49.61%] [G loss: 0.228725] [Loss difference: 0.007, iterations with loss: 1]\n",
      "2883 [D loss: 0.993140, acc.: 49.90%] [G loss: 0.219586] [Loss difference: -0.009, iterations with loss: 2]\n",
      "2884 [D loss: 0.997489, acc.: 49.80%] [G loss: 0.219188] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2885 [D loss: 1.000295, acc.: 49.80%] [G loss: 0.214203] [Loss difference: -0.005, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2886 [D loss: 0.999600, acc.: 49.90%] [G loss: 0.216991] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2887 [D loss: 0.988239, acc.: 49.90%] [G loss: 0.221812] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2888 [D loss: 0.998706, acc.: 49.90%] [G loss: 0.223034] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2889 [D loss: 0.994046, acc.: 49.80%] [G loss: 0.222649] [Loss difference: -0.000, iterations with loss: 3]\n",
      "2890 [D loss: 0.991004, acc.: 49.61%] [G loss: 0.217466] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2891 [D loss: 0.998089, acc.: 49.71%] [G loss: 0.218256] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2892 [D loss: 0.988620, acc.: 49.71%] [G loss: 0.221366] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2893 [D loss: 1.006613, acc.: 49.80%] [G loss: 0.219543] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2894 [D loss: 0.993403, acc.: 49.80%] [G loss: 0.227184] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2895 [D loss: 0.991977, acc.: 49.80%] [G loss: 0.220515] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2896 [D loss: 0.999420, acc.: 49.51%] [G loss: 0.216049] [Loss difference: -0.004, iterations with loss: 0]\n",
      "2897 [D loss: 0.998124, acc.: 49.90%] [G loss: 0.221008] [Loss difference: 0.005, iterations with loss: 0]\n",
      "2898 [D loss: 0.987883, acc.: 49.90%] [G loss: 0.216994] [Loss difference: -0.004, iterations with loss: 1]\n",
      "2899 [D loss: 0.987123, acc.: 49.90%] [G loss: 0.218637] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2900 [D loss: 0.989895, acc.: 50.00%] [G loss: 0.219354] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2901 [D loss: 0.984869, acc.: 49.80%] [G loss: 0.226695] [Loss difference: 0.007, iterations with loss: 2]\n",
      "2902 [D loss: 0.990683, acc.: 49.71%] [G loss: 0.220805] [Loss difference: -0.006, iterations with loss: 3]\n",
      "2903 [D loss: 0.989256, acc.: 49.90%] [G loss: 0.221517] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2904 [D loss: 0.996483, acc.: 49.41%] [G loss: 0.220838] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2905 [D loss: 0.979135, acc.: 50.00%] [G loss: 0.215648] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2906 [D loss: 0.985384, acc.: 49.90%] [G loss: 0.215018] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2907 [D loss: 0.993419, acc.: 49.90%] [G loss: 0.223116] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2908 [D loss: 0.959728, acc.: 50.00%] [G loss: 0.223038] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2909 [D loss: 0.977542, acc.: 49.80%] [G loss: 0.223246] [Loss difference: 0.000, iterations with loss: 0]\n",
      "2910 [D loss: 0.982845, acc.: 49.80%] [G loss: 0.225905] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2911 [D loss: 0.982107, acc.: 49.80%] [G loss: 0.223945] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2912 [D loss: 0.986175, acc.: 49.51%] [G loss: 0.222341] [Loss difference: -0.002, iterations with loss: 0]\n",
      "2913 [D loss: 0.977456, acc.: 49.80%] [G loss: 0.225365] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2914 [D loss: 0.980656, acc.: 49.90%] [G loss: 0.222658] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2915 [D loss: 0.998340, acc.: 49.90%] [G loss: 0.223410] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2916 [D loss: 0.981434, acc.: 49.90%] [G loss: 0.227596] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2917 [D loss: 0.991381, acc.: 49.90%] [G loss: 0.224066] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2918 [D loss: 0.987701, acc.: 49.71%] [G loss: 0.225667] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2919 [D loss: 0.994303, acc.: 49.71%] [G loss: 0.227181] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2920 [D loss: 0.972069, acc.: 49.90%] [G loss: 0.219900] [Loss difference: -0.007, iterations with loss: 2]\n",
      "2921 [D loss: 0.982302, acc.: 50.00%] [G loss: 0.225430] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2922 [D loss: 0.991848, acc.: 49.90%] [G loss: 0.216864] [Loss difference: -0.009, iterations with loss: 1]\n",
      "2923 [D loss: 1.000988, acc.: 49.90%] [G loss: 0.226153] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2924 [D loss: 0.991828, acc.: 49.80%] [G loss: 0.219322] [Loss difference: -0.007, iterations with loss: 1]\n",
      "2925 [D loss: 0.998623, acc.: 49.80%] [G loss: 0.221842] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2926 [D loss: 1.003387, acc.: 49.71%] [G loss: 0.226741] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2927 [D loss: 0.982306, acc.: 49.80%] [G loss: 0.222720] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2928 [D loss: 0.976013, acc.: 49.71%] [G loss: 0.226605] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2929 [D loss: 0.971490, acc.: 49.80%] [G loss: 0.218489] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2930 [D loss: 0.979943, acc.: 49.80%] [G loss: 0.226008] [Loss difference: 0.008, iterations with loss: 0]\n",
      "2931 [D loss: 0.985005, acc.: 49.80%] [G loss: 0.220942] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2932 [D loss: 0.985101, acc.: 49.80%] [G loss: 0.222626] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2933 [D loss: 0.984217, acc.: 49.80%] [G loss: 0.220196] [Loss difference: -0.002, iterations with loss: 1]\n",
      "2934 [D loss: 0.994107, acc.: 49.51%] [G loss: 0.221150] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2935 [D loss: 0.978245, acc.: 50.00%] [G loss: 0.222966] [Loss difference: 0.002, iterations with loss: 1]\n",
      "2936 [D loss: 0.991677, acc.: 49.71%] [G loss: 0.226237] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2937 [D loss: 0.967829, acc.: 50.00%] [G loss: 0.224521] [Loss difference: -0.002, iterations with loss: 3]\n",
      "2938 [D loss: 0.979549, acc.: 49.90%] [G loss: 0.228830] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2939 [D loss: 0.999642, acc.: 49.51%] [G loss: 0.228645] [Loss difference: -0.000, iterations with loss: 1]\n",
      "2940 [D loss: 0.988731, acc.: 50.00%] [G loss: 0.229536] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2941 [D loss: 0.991021, acc.: 49.80%] [G loss: 0.228864] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2942 [D loss: 0.986882, acc.: 49.90%] [G loss: 0.221536] [Loss difference: -0.007, iterations with loss: 0]\n",
      "2943 [D loss: 0.981342, acc.: 49.90%] [G loss: 0.223950] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2944 [D loss: 0.988074, acc.: 49.90%] [G loss: 0.228224] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2945 [D loss: 0.981800, acc.: 49.80%] [G loss: 0.231051] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2946 [D loss: 0.998558, acc.: 49.80%] [G loss: 0.227266] [Loss difference: -0.004, iterations with loss: 3]\n",
      "2947 [D loss: 0.980604, acc.: 50.00%] [G loss: 0.228475] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2948 [D loss: 0.978438, acc.: 50.00%] [G loss: 0.223625] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2949 [D loss: 0.990957, acc.: 49.90%] [G loss: 0.224848] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2950 [D loss: 0.985330, acc.: 49.80%] [G loss: 0.229718] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2951 [D loss: 0.970261, acc.: 49.90%] [G loss: 0.230265] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2952 [D loss: 0.968669, acc.: 49.80%] [G loss: 0.223135] [Loss difference: -0.007, iterations with loss: 3]\n",
      "2953 [D loss: 0.976388, acc.: 50.00%] [G loss: 0.231964] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2954 [D loss: 0.985733, acc.: 49.80%] [G loss: 0.225766] [Loss difference: -0.006, iterations with loss: 1]\n",
      "2955 [D loss: 0.987617, acc.: 50.00%] [G loss: 0.222311] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2956 [D loss: 0.981911, acc.: 49.61%] [G loss: 0.221601] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2957 [D loss: 0.987922, acc.: 49.71%] [G loss: 0.222297] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2958 [D loss: 0.979681, acc.: 50.00%] [G loss: 0.223600] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2959 [D loss: 0.967810, acc.: 50.00%] [G loss: 0.228710] [Loss difference: 0.005, iterations with loss: 2]\n",
      "2960 [D loss: 0.984789, acc.: 49.80%] [G loss: 0.226156] [Loss difference: -0.003, iterations with loss: 3]\n",
      "2961 [D loss: 0.968465, acc.: 49.90%] [G loss: 0.227395] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2962 [D loss: 0.969583, acc.: 49.90%] [G loss: 0.228493] [Loss difference: 0.001, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963 [D loss: 0.971854, acc.: 50.00%] [G loss: 0.226303] [Loss difference: -0.002, iterations with loss: 2]\n",
      "2964 [D loss: 0.979157, acc.: 49.80%] [G loss: 0.219024] [Loss difference: -0.007, iterations with loss: 0]\n",
      "2965 [D loss: 1.000494, acc.: 49.71%] [G loss: 0.220404] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2966 [D loss: 0.986464, acc.: 50.00%] [G loss: 0.221232] [Loss difference: 0.001, iterations with loss: 1]\n",
      "2967 [D loss: 0.981218, acc.: 49.90%] [G loss: 0.224551] [Loss difference: 0.003, iterations with loss: 2]\n",
      "2968 [D loss: 0.975580, acc.: 49.90%] [G loss: 0.229116] [Loss difference: 0.005, iterations with loss: 3]\n",
      "2969 [D loss: 0.986229, acc.: 49.71%] [G loss: 0.224883] [Loss difference: -0.004, iterations with loss: 4]\n",
      "2970 [D loss: 0.967190, acc.: 50.00%] [G loss: 0.233659] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2971 [D loss: 0.953272, acc.: 50.00%] [G loss: 0.232845] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2972 [D loss: 0.966496, acc.: 49.80%] [G loss: 0.227736] [Loss difference: -0.005, iterations with loss: 0]\n",
      "2973 [D loss: 0.984373, acc.: 49.61%] [G loss: 0.230339] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2974 [D loss: 0.990436, acc.: 49.71%] [G loss: 0.229450] [Loss difference: -0.001, iterations with loss: 1]\n",
      "2975 [D loss: 0.963778, acc.: 49.90%] [G loss: 0.231732] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2976 [D loss: 0.974439, acc.: 49.61%] [G loss: 0.226245] [Loss difference: -0.005, iterations with loss: 1]\n",
      "2977 [D loss: 0.964186, acc.: 50.00%] [G loss: 0.226911] [Loss difference: 0.001, iterations with loss: 0]\n",
      "2978 [D loss: 0.966943, acc.: 49.71%] [G loss: 0.223590] [Loss difference: -0.003, iterations with loss: 1]\n",
      "2979 [D loss: 0.985243, acc.: 49.90%] [G loss: 0.232134] [Loss difference: 0.009, iterations with loss: 0]\n",
      "2980 [D loss: 0.972150, acc.: 49.80%] [G loss: 0.222551] [Loss difference: -0.010, iterations with loss: 1]\n",
      "2981 [D loss: 0.976746, acc.: 49.80%] [G loss: 0.226624] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2982 [D loss: 0.983424, acc.: 49.90%] [G loss: 0.229964] [Loss difference: 0.003, iterations with loss: 1]\n",
      "2983 [D loss: 0.964104, acc.: 50.00%] [G loss: 0.225940] [Loss difference: -0.004, iterations with loss: 2]\n",
      "2984 [D loss: 0.973727, acc.: 49.71%] [G loss: 0.223102] [Loss difference: -0.003, iterations with loss: 0]\n",
      "2985 [D loss: 0.971874, acc.: 49.51%] [G loss: 0.226843] [Loss difference: 0.004, iterations with loss: 0]\n",
      "2986 [D loss: 0.981019, acc.: 50.00%] [G loss: 0.232135] [Loss difference: 0.005, iterations with loss: 1]\n",
      "2987 [D loss: 0.956191, acc.: 49.80%] [G loss: 0.233252] [Loss difference: 0.001, iterations with loss: 2]\n",
      "2988 [D loss: 0.960192, acc.: 50.00%] [G loss: 0.233674] [Loss difference: 0.000, iterations with loss: 3]\n",
      "2989 [D loss: 0.957488, acc.: 49.90%] [G loss: 0.232406] [Loss difference: -0.001, iterations with loss: 4]\n",
      "2990 [D loss: 0.984022, acc.: 49.71%] [G loss: 0.232372] [Loss difference: -0.000, iterations with loss: 0]\n",
      "2991 [D loss: 0.953975, acc.: 49.90%] [G loss: 0.235607] [Loss difference: 0.003, iterations with loss: 0]\n",
      "2992 [D loss: 0.976886, acc.: 49.71%] [G loss: 0.227160] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2993 [D loss: 0.974705, acc.: 49.90%] [G loss: 0.226038] [Loss difference: -0.001, iterations with loss: 0]\n",
      "2994 [D loss: 0.968433, acc.: 49.80%] [G loss: 0.231610] [Loss difference: 0.006, iterations with loss: 0]\n",
      "2995 [D loss: 0.962047, acc.: 49.90%] [G loss: 0.223426] [Loss difference: -0.008, iterations with loss: 1]\n",
      "2996 [D loss: 0.969414, acc.: 50.00%] [G loss: 0.225549] [Loss difference: 0.002, iterations with loss: 0]\n",
      "2997 [D loss: 0.993586, acc.: 49.80%] [G loss: 0.229878] [Loss difference: 0.004, iterations with loss: 1]\n",
      "2998 [D loss: 0.964744, acc.: 49.90%] [G loss: 0.226740] [Loss difference: -0.003, iterations with loss: 2]\n",
      "2999 [D loss: 0.967004, acc.: 49.90%] [G loss: 0.229364] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3000 [D loss: 0.966626, acc.: 49.90%] [G loss: 0.231581] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3001 [D loss: 0.977969, acc.: 49.80%] [G loss: 0.230165] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3002 [D loss: 0.974707, acc.: 49.61%] [G loss: 0.230678] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3003 [D loss: 0.970171, acc.: 49.90%] [G loss: 0.233575] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3004 [D loss: 0.970236, acc.: 49.80%] [G loss: 0.230570] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3005 [D loss: 0.976669, acc.: 49.80%] [G loss: 0.231980] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3006 [D loss: 0.980266, acc.: 49.51%] [G loss: 0.227833] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3007 [D loss: 0.977863, acc.: 49.90%] [G loss: 0.231078] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3008 [D loss: 0.978766, acc.: 49.71%] [G loss: 0.232970] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3009 [D loss: 0.969674, acc.: 49.90%] [G loss: 0.232249] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3010 [D loss: 0.980372, acc.: 49.90%] [G loss: 0.227699] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3011 [D loss: 0.979322, acc.: 49.71%] [G loss: 0.228877] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3012 [D loss: 0.979106, acc.: 49.71%] [G loss: 0.230230] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3013 [D loss: 0.969142, acc.: 49.80%] [G loss: 0.237344] [Loss difference: 0.007, iterations with loss: 2]\n",
      "3014 [D loss: 0.973152, acc.: 49.71%] [G loss: 0.235055] [Loss difference: -0.002, iterations with loss: 3]\n",
      "3015 [D loss: 0.969620, acc.: 49.80%] [G loss: 0.238461] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3016 [D loss: 0.964058, acc.: 49.90%] [G loss: 0.233019] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3017 [D loss: 0.993460, acc.: 49.80%] [G loss: 0.231939] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3018 [D loss: 0.977902, acc.: 49.80%] [G loss: 0.229484] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3019 [D loss: 0.977380, acc.: 49.80%] [G loss: 0.227405] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3020 [D loss: 0.973024, acc.: 50.00%] [G loss: 0.231641] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3021 [D loss: 0.970982, acc.: 49.80%] [G loss: 0.231177] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3022 [D loss: 0.976019, acc.: 50.00%] [G loss: 0.235941] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3023 [D loss: 0.966530, acc.: 50.00%] [G loss: 0.233854] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3024 [D loss: 0.951145, acc.: 50.00%] [G loss: 0.234833] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3025 [D loss: 0.963915, acc.: 50.00%] [G loss: 0.232219] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3026 [D loss: 0.976608, acc.: 49.90%] [G loss: 0.231960] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3027 [D loss: 0.976016, acc.: 49.51%] [G loss: 0.238540] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3028 [D loss: 0.968758, acc.: 49.80%] [G loss: 0.237241] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3029 [D loss: 0.969405, acc.: 49.61%] [G loss: 0.231450] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3030 [D loss: 0.966221, acc.: 49.90%] [G loss: 0.231930] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3031 [D loss: 0.967250, acc.: 50.00%] [G loss: 0.233877] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3032 [D loss: 0.965870, acc.: 49.90%] [G loss: 0.237268] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3033 [D loss: 0.972753, acc.: 49.61%] [G loss: 0.229780] [Loss difference: -0.007, iterations with loss: 3]\n",
      "3034 [D loss: 0.961481, acc.: 49.90%] [G loss: 0.232387] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3035 [D loss: 0.968266, acc.: 49.80%] [G loss: 0.233249] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3036 [D loss: 0.968708, acc.: 49.90%] [G loss: 0.237014] [Loss difference: 0.004, iterations with loss: 2]\n",
      "3037 [D loss: 0.963551, acc.: 49.90%] [G loss: 0.233526] [Loss difference: -0.003, iterations with loss: 3]\n",
      "3038 [D loss: 0.962938, acc.: 50.00%] [G loss: 0.235409] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3039 [D loss: 0.962161, acc.: 49.80%] [G loss: 0.238266] [Loss difference: 0.003, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3040 [D loss: 0.956908, acc.: 50.00%] [G loss: 0.240109] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3041 [D loss: 0.966331, acc.: 49.90%] [G loss: 0.241856] [Loss difference: 0.002, iterations with loss: 3]\n",
      "3042 [D loss: 0.965586, acc.: 49.80%] [G loss: 0.240005] [Loss difference: -0.002, iterations with loss: 4]\n",
      "3043 [D loss: 0.967543, acc.: 49.80%] [G loss: 0.240772] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3044 [D loss: 0.964594, acc.: 49.80%] [G loss: 0.233541] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3045 [D loss: 0.971698, acc.: 50.00%] [G loss: 0.233481] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3046 [D loss: 0.966182, acc.: 49.80%] [G loss: 0.235764] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3047 [D loss: 0.986214, acc.: 49.61%] [G loss: 0.235379] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3048 [D loss: 0.967558, acc.: 49.80%] [G loss: 0.229840] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3049 [D loss: 0.967216, acc.: 49.90%] [G loss: 0.236735] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3050 [D loss: 0.954365, acc.: 50.00%] [G loss: 0.239928] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3051 [D loss: 0.966665, acc.: 49.90%] [G loss: 0.241298] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3052 [D loss: 0.965411, acc.: 49.61%] [G loss: 0.233999] [Loss difference: -0.007, iterations with loss: 3]\n",
      "3053 [D loss: 0.968611, acc.: 49.80%] [G loss: 0.231294] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3054 [D loss: 0.977509, acc.: 49.80%] [G loss: 0.238335] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3055 [D loss: 0.976716, acc.: 49.61%] [G loss: 0.238280] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3056 [D loss: 0.975915, acc.: 49.71%] [G loss: 0.235190] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3057 [D loss: 0.969020, acc.: 49.90%] [G loss: 0.239233] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3058 [D loss: 0.957430, acc.: 49.80%] [G loss: 0.234198] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3059 [D loss: 0.960479, acc.: 50.00%] [G loss: 0.233908] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3060 [D loss: 0.965756, acc.: 49.90%] [G loss: 0.238798] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3061 [D loss: 0.960908, acc.: 50.00%] [G loss: 0.237892] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3062 [D loss: 0.957951, acc.: 50.00%] [G loss: 0.242356] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3063 [D loss: 0.962458, acc.: 49.80%] [G loss: 0.239345] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3064 [D loss: 0.952021, acc.: 49.90%] [G loss: 0.237223] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3065 [D loss: 0.961134, acc.: 49.71%] [G loss: 0.235335] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3066 [D loss: 0.959327, acc.: 49.80%] [G loss: 0.233205] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3067 [D loss: 0.960196, acc.: 49.90%] [G loss: 0.235127] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3068 [D loss: 0.960111, acc.: 49.90%] [G loss: 0.240230] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3069 [D loss: 0.968808, acc.: 49.71%] [G loss: 0.246057] [Loss difference: 0.006, iterations with loss: 2]\n",
      "3070 [D loss: 0.971483, acc.: 49.80%] [G loss: 0.235560] [Loss difference: -0.010, iterations with loss: 3]\n",
      "3071 [D loss: 0.959979, acc.: 50.00%] [G loss: 0.234797] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3072 [D loss: 0.978173, acc.: 50.00%] [G loss: 0.236675] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3073 [D loss: 0.971418, acc.: 50.00%] [G loss: 0.241285] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3074 [D loss: 0.952930, acc.: 49.90%] [G loss: 0.237932] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3075 [D loss: 0.953794, acc.: 50.00%] [G loss: 0.238122] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3076 [D loss: 0.965403, acc.: 49.71%] [G loss: 0.242363] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3077 [D loss: 0.966913, acc.: 49.90%] [G loss: 0.243478] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3078 [D loss: 0.950645, acc.: 49.90%] [G loss: 0.240947] [Loss difference: -0.003, iterations with loss: 3]\n",
      "3079 [D loss: 0.949733, acc.: 50.00%] [G loss: 0.236782] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3080 [D loss: 0.972856, acc.: 49.90%] [G loss: 0.236656] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3081 [D loss: 0.956514, acc.: 50.00%] [G loss: 0.241219] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3082 [D loss: 0.984286, acc.: 49.90%] [G loss: 0.239507] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3083 [D loss: 0.962404, acc.: 49.71%] [G loss: 0.236695] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3084 [D loss: 0.958476, acc.: 49.71%] [G loss: 0.240281] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3085 [D loss: 0.964398, acc.: 49.90%] [G loss: 0.240544] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3086 [D loss: 0.948236, acc.: 50.00%] [G loss: 0.246402] [Loss difference: 0.006, iterations with loss: 2]\n",
      "3087 [D loss: 0.955482, acc.: 49.90%] [G loss: 0.245051] [Loss difference: -0.001, iterations with loss: 3]\n",
      "3088 [D loss: 0.957224, acc.: 49.90%] [G loss: 0.239759] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3089 [D loss: 0.960449, acc.: 49.80%] [G loss: 0.232173] [Loss difference: -0.008, iterations with loss: 0]\n",
      "3090 [D loss: 0.968773, acc.: 50.00%] [G loss: 0.235792] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3091 [D loss: 0.971753, acc.: 49.80%] [G loss: 0.238703] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3092 [D loss: 0.969173, acc.: 49.80%] [G loss: 0.244485] [Loss difference: 0.006, iterations with loss: 2]\n",
      "3093 [D loss: 0.964008, acc.: 49.90%] [G loss: 0.239254] [Loss difference: -0.005, iterations with loss: 3]\n",
      "3094 [D loss: 0.945821, acc.: 49.90%] [G loss: 0.239813] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3095 [D loss: 0.975402, acc.: 49.90%] [G loss: 0.243720] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3096 [D loss: 0.942531, acc.: 50.00%] [G loss: 0.239392] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3097 [D loss: 0.952812, acc.: 49.80%] [G loss: 0.244643] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3098 [D loss: 0.957379, acc.: 50.00%] [G loss: 0.231520] [Loss difference: -0.013, iterations with loss: 1]\n",
      "3099 [D loss: 0.959633, acc.: 50.00%] [G loss: 0.236045] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3100 [D loss: 0.957812, acc.: 49.90%] [G loss: 0.235574] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3101 [D loss: 0.973785, acc.: 49.80%] [G loss: 0.242469] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3102 [D loss: 0.948879, acc.: 50.00%] [G loss: 0.248152] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3103 [D loss: 0.957129, acc.: 49.80%] [G loss: 0.248649] [Loss difference: 0.000, iterations with loss: 2]\n",
      "3104 [D loss: 0.974193, acc.: 49.41%] [G loss: 0.238198] [Loss difference: -0.010, iterations with loss: 3]\n",
      "3105 [D loss: 0.952093, acc.: 49.90%] [G loss: 0.242942] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3106 [D loss: 0.941981, acc.: 49.61%] [G loss: 0.242839] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3107 [D loss: 0.954458, acc.: 49.90%] [G loss: 0.247831] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3108 [D loss: 0.959259, acc.: 49.90%] [G loss: 0.243762] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3109 [D loss: 0.946324, acc.: 49.90%] [G loss: 0.241344] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3110 [D loss: 0.958601, acc.: 49.90%] [G loss: 0.237879] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3111 [D loss: 0.961378, acc.: 49.71%] [G loss: 0.241936] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3112 [D loss: 0.956077, acc.: 49.71%] [G loss: 0.240434] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3113 [D loss: 0.948858, acc.: 50.00%] [G loss: 0.244467] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3114 [D loss: 0.953187, acc.: 49.71%] [G loss: 0.241412] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3115 [D loss: 0.964905, acc.: 49.80%] [G loss: 0.243537] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3116 [D loss: 0.947939, acc.: 50.00%] [G loss: 0.242916] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3117 [D loss: 0.948415, acc.: 50.00%] [G loss: 0.248070] [Loss difference: 0.005, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3118 [D loss: 0.948178, acc.: 50.00%] [G loss: 0.247206] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3119 [D loss: 0.936670, acc.: 50.00%] [G loss: 0.248511] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3120 [D loss: 0.955934, acc.: 49.71%] [G loss: 0.247058] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3121 [D loss: 0.957749, acc.: 50.00%] [G loss: 0.246636] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3122 [D loss: 0.938374, acc.: 49.80%] [G loss: 0.242539] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3123 [D loss: 0.952086, acc.: 49.80%] [G loss: 0.238043] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3124 [D loss: 0.971690, acc.: 49.80%] [G loss: 0.238981] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3125 [D loss: 0.962421, acc.: 49.80%] [G loss: 0.243859] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3126 [D loss: 0.978430, acc.: 49.90%] [G loss: 0.240290] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3127 [D loss: 0.949942, acc.: 50.00%] [G loss: 0.250428] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3128 [D loss: 0.949841, acc.: 49.80%] [G loss: 0.245040] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3129 [D loss: 0.939097, acc.: 49.80%] [G loss: 0.251987] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3130 [D loss: 0.973402, acc.: 49.71%] [G loss: 0.239946] [Loss difference: -0.012, iterations with loss: 1]\n",
      "3131 [D loss: 0.961750, acc.: 50.00%] [G loss: 0.239682] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3132 [D loss: 0.956941, acc.: 49.90%] [G loss: 0.238796] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3133 [D loss: 0.977248, acc.: 49.80%] [G loss: 0.240113] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3134 [D loss: 0.972067, acc.: 49.71%] [G loss: 0.249267] [Loss difference: 0.009, iterations with loss: 1]\n",
      "3135 [D loss: 0.954926, acc.: 49.90%] [G loss: 0.246932] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3136 [D loss: 0.959363, acc.: 49.80%] [G loss: 0.248810] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3137 [D loss: 0.942623, acc.: 49.90%] [G loss: 0.246554] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3138 [D loss: 0.965050, acc.: 49.80%] [G loss: 0.244896] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3139 [D loss: 0.970414, acc.: 49.71%] [G loss: 0.245905] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3140 [D loss: 0.949747, acc.: 49.90%] [G loss: 0.244189] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3141 [D loss: 0.945574, acc.: 50.00%] [G loss: 0.247960] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3142 [D loss: 0.954864, acc.: 49.90%] [G loss: 0.241412] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3143 [D loss: 0.963474, acc.: 49.80%] [G loss: 0.248031] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3144 [D loss: 0.968008, acc.: 49.80%] [G loss: 0.245070] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3145 [D loss: 0.943178, acc.: 49.61%] [G loss: 0.245923] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3146 [D loss: 0.962389, acc.: 49.71%] [G loss: 0.242499] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3147 [D loss: 0.959027, acc.: 49.90%] [G loss: 0.244216] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3148 [D loss: 0.957765, acc.: 49.80%] [G loss: 0.249439] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3149 [D loss: 0.964619, acc.: 49.51%] [G loss: 0.250995] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3150 [D loss: 0.955812, acc.: 49.71%] [G loss: 0.253174] [Loss difference: 0.002, iterations with loss: 3]\n",
      "3151 [D loss: 0.946647, acc.: 49.90%] [G loss: 0.248207] [Loss difference: -0.005, iterations with loss: 4]\n",
      "3152 [D loss: 0.940157, acc.: 50.00%] [G loss: 0.247090] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3153 [D loss: 0.958549, acc.: 49.71%] [G loss: 0.247789] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3154 [D loss: 0.962207, acc.: 49.80%] [G loss: 0.243425] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3155 [D loss: 0.933546, acc.: 50.00%] [G loss: 0.245083] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3156 [D loss: 0.953646, acc.: 49.80%] [G loss: 0.245740] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3157 [D loss: 0.954646, acc.: 49.71%] [G loss: 0.248889] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3158 [D loss: 0.944442, acc.: 50.00%] [G loss: 0.247331] [Loss difference: -0.002, iterations with loss: 3]\n",
      "3159 [D loss: 0.969592, acc.: 49.71%] [G loss: 0.248867] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3160 [D loss: 0.959202, acc.: 49.71%] [G loss: 0.251211] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3161 [D loss: 0.960502, acc.: 49.80%] [G loss: 0.244254] [Loss difference: -0.007, iterations with loss: 2]\n",
      "3162 [D loss: 0.959998, acc.: 49.90%] [G loss: 0.249444] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3163 [D loss: 0.963406, acc.: 49.71%] [G loss: 0.248406] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3164 [D loss: 0.964833, acc.: 50.00%] [G loss: 0.250578] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3165 [D loss: 0.952004, acc.: 49.90%] [G loss: 0.245755] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3166 [D loss: 0.968973, acc.: 49.80%] [G loss: 0.247932] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3167 [D loss: 0.963561, acc.: 49.61%] [G loss: 0.252400] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3168 [D loss: 0.953501, acc.: 50.00%] [G loss: 0.251073] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3169 [D loss: 0.947751, acc.: 49.90%] [G loss: 0.247612] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3170 [D loss: 0.924825, acc.: 49.90%] [G loss: 0.251368] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3171 [D loss: 0.955784, acc.: 49.71%] [G loss: 0.251212] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3172 [D loss: 0.947393, acc.: 49.71%] [G loss: 0.250446] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3173 [D loss: 0.957758, acc.: 49.51%] [G loss: 0.251912] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3174 [D loss: 0.959262, acc.: 50.00%] [G loss: 0.244938] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3175 [D loss: 0.954179, acc.: 49.80%] [G loss: 0.241789] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3176 [D loss: 0.967506, acc.: 49.80%] [G loss: 0.249340] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3177 [D loss: 0.953529, acc.: 49.71%] [G loss: 0.250900] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3178 [D loss: 0.951220, acc.: 49.90%] [G loss: 0.247012] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3179 [D loss: 0.954249, acc.: 50.00%] [G loss: 0.248366] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3180 [D loss: 0.947124, acc.: 49.80%] [G loss: 0.248446] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3181 [D loss: 0.962072, acc.: 49.71%] [G loss: 0.248284] [Loss difference: -0.000, iterations with loss: 2]\n",
      "3182 [D loss: 0.950076, acc.: 49.90%] [G loss: 0.253169] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3183 [D loss: 0.935510, acc.: 50.00%] [G loss: 0.250291] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3184 [D loss: 0.972555, acc.: 49.61%] [G loss: 0.250415] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3185 [D loss: 0.952663, acc.: 49.90%] [G loss: 0.250386] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3186 [D loss: 0.950677, acc.: 50.00%] [G loss: 0.255239] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3187 [D loss: 0.957101, acc.: 49.71%] [G loss: 0.245806] [Loss difference: -0.009, iterations with loss: 1]\n",
      "3188 [D loss: 0.951714, acc.: 49.90%] [G loss: 0.252049] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3189 [D loss: 0.949684, acc.: 49.80%] [G loss: 0.254198] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3190 [D loss: 0.950749, acc.: 49.80%] [G loss: 0.250035] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3191 [D loss: 0.945287, acc.: 49.90%] [G loss: 0.255721] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3192 [D loss: 0.949067, acc.: 50.00%] [G loss: 0.255177] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3193 [D loss: 0.956804, acc.: 49.90%] [G loss: 0.254963] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3194 [D loss: 0.959714, acc.: 50.00%] [G loss: 0.256363] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3195 [D loss: 0.947455, acc.: 49.61%] [G loss: 0.251762] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3196 [D loss: 0.953668, acc.: 49.80%] [G loss: 0.250080] [Loss difference: -0.002, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3197 [D loss: 0.957891, acc.: 49.90%] [G loss: 0.247929] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3198 [D loss: 0.945926, acc.: 49.90%] [G loss: 0.254664] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3199 [D loss: 0.948945, acc.: 49.51%] [G loss: 0.249146] [Loss difference: -0.006, iterations with loss: 1]\n",
      "3200 [D loss: 0.943892, acc.: 50.00%] [G loss: 0.249191] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3201 [D loss: 0.942227, acc.: 49.90%] [G loss: 0.248760] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3202 [D loss: 0.950536, acc.: 49.90%] [G loss: 0.255288] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3203 [D loss: 0.954395, acc.: 49.71%] [G loss: 0.249894] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3204 [D loss: 0.952373, acc.: 49.61%] [G loss: 0.250092] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3205 [D loss: 0.958263, acc.: 49.71%] [G loss: 0.247188] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3206 [D loss: 0.946474, acc.: 49.90%] [G loss: 0.252731] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3207 [D loss: 0.932848, acc.: 50.00%] [G loss: 0.255407] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3208 [D loss: 0.925916, acc.: 49.90%] [G loss: 0.260141] [Loss difference: 0.005, iterations with loss: 2]\n",
      "3209 [D loss: 0.942962, acc.: 49.71%] [G loss: 0.256610] [Loss difference: -0.004, iterations with loss: 3]\n",
      "3210 [D loss: 0.952350, acc.: 49.80%] [G loss: 0.258337] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3211 [D loss: 0.938954, acc.: 49.61%] [G loss: 0.257194] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3212 [D loss: 0.941789, acc.: 49.80%] [G loss: 0.256025] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3213 [D loss: 0.956492, acc.: 49.71%] [G loss: 0.251847] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3214 [D loss: 0.946331, acc.: 49.61%] [G loss: 0.252829] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3215 [D loss: 0.961672, acc.: 49.80%] [G loss: 0.253910] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3216 [D loss: 0.945266, acc.: 49.80%] [G loss: 0.258023] [Loss difference: 0.004, iterations with loss: 2]\n",
      "3217 [D loss: 0.938877, acc.: 50.00%] [G loss: 0.255365] [Loss difference: -0.003, iterations with loss: 3]\n",
      "3218 [D loss: 0.946544, acc.: 49.71%] [G loss: 0.266543] [Loss difference: 0.011, iterations with loss: 0]\n",
      "3219 [D loss: 0.947455, acc.: 49.90%] [G loss: 0.253541] [Loss difference: -0.013, iterations with loss: 1]\n",
      "3220 [D loss: 0.927162, acc.: 49.90%] [G loss: 0.255455] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3221 [D loss: 0.960851, acc.: 49.80%] [G loss: 0.253546] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3222 [D loss: 0.956844, acc.: 49.71%] [G loss: 0.254511] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3223 [D loss: 0.959071, acc.: 49.80%] [G loss: 0.259146] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3224 [D loss: 0.949290, acc.: 49.71%] [G loss: 0.252723] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3225 [D loss: 0.947185, acc.: 49.80%] [G loss: 0.254229] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3226 [D loss: 0.927565, acc.: 50.00%] [G loss: 0.256973] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3227 [D loss: 0.941452, acc.: 49.41%] [G loss: 0.255201] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3228 [D loss: 0.932450, acc.: 49.90%] [G loss: 0.255517] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3229 [D loss: 0.947314, acc.: 50.00%] [G loss: 0.253803] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3230 [D loss: 0.940294, acc.: 50.00%] [G loss: 0.260167] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3231 [D loss: 0.940866, acc.: 50.00%] [G loss: 0.267505] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3232 [D loss: 0.952523, acc.: 49.61%] [G loss: 0.256706] [Loss difference: -0.011, iterations with loss: 2]\n",
      "3233 [D loss: 0.943475, acc.: 49.80%] [G loss: 0.256644] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3234 [D loss: 0.954841, acc.: 49.90%] [G loss: 0.251276] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3235 [D loss: 0.952535, acc.: 49.71%] [G loss: 0.245412] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3236 [D loss: 0.951347, acc.: 49.90%] [G loss: 0.247576] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3237 [D loss: 0.953320, acc.: 49.71%] [G loss: 0.259503] [Loss difference: 0.012, iterations with loss: 1]\n",
      "3238 [D loss: 0.937884, acc.: 49.80%] [G loss: 0.260270] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3239 [D loss: 0.936358, acc.: 49.90%] [G loss: 0.259340] [Loss difference: -0.001, iterations with loss: 3]\n",
      "3240 [D loss: 0.943967, acc.: 49.71%] [G loss: 0.259229] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3241 [D loss: 0.947713, acc.: 50.00%] [G loss: 0.260555] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3242 [D loss: 0.938230, acc.: 49.51%] [G loss: 0.261979] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3243 [D loss: 0.940323, acc.: 49.80%] [G loss: 0.262358] [Loss difference: 0.000, iterations with loss: 2]\n",
      "3244 [D loss: 0.950075, acc.: 49.61%] [G loss: 0.256176] [Loss difference: -0.006, iterations with loss: 3]\n",
      "3245 [D loss: 0.943011, acc.: 49.71%] [G loss: 0.261626] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3246 [D loss: 0.933667, acc.: 49.80%] [G loss: 0.259101] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3247 [D loss: 0.935823, acc.: 49.71%] [G loss: 0.258090] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3248 [D loss: 0.952220, acc.: 50.00%] [G loss: 0.260230] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3249 [D loss: 0.932189, acc.: 49.80%] [G loss: 0.262510] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3250 [D loss: 0.942284, acc.: 49.90%] [G loss: 0.257609] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3251 [D loss: 0.950100, acc.: 49.80%] [G loss: 0.256537] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3252 [D loss: 0.938361, acc.: 49.90%] [G loss: 0.259161] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3253 [D loss: 0.932161, acc.: 49.80%] [G loss: 0.260164] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3254 [D loss: 0.957171, acc.: 49.51%] [G loss: 0.260571] [Loss difference: 0.000, iterations with loss: 2]\n",
      "3255 [D loss: 0.937860, acc.: 49.61%] [G loss: 0.256818] [Loss difference: -0.004, iterations with loss: 3]\n",
      "3256 [D loss: 0.941294, acc.: 49.80%] [G loss: 0.257852] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3257 [D loss: 0.944362, acc.: 49.71%] [G loss: 0.261568] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3258 [D loss: 0.949026, acc.: 49.61%] [G loss: 0.258108] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3259 [D loss: 0.941435, acc.: 49.90%] [G loss: 0.262640] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3260 [D loss: 0.949235, acc.: 49.61%] [G loss: 0.260247] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3261 [D loss: 0.932351, acc.: 49.90%] [G loss: 0.257901] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3262 [D loss: 0.945828, acc.: 49.80%] [G loss: 0.259104] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3263 [D loss: 0.944940, acc.: 49.90%] [G loss: 0.260929] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3264 [D loss: 0.938905, acc.: 49.80%] [G loss: 0.261777] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3265 [D loss: 0.931932, acc.: 49.90%] [G loss: 0.257808] [Loss difference: -0.004, iterations with loss: 3]\n",
      "3266 [D loss: 0.930756, acc.: 49.90%] [G loss: 0.258197] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3267 [D loss: 0.955296, acc.: 49.71%] [G loss: 0.257266] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3268 [D loss: 0.934186, acc.: 50.00%] [G loss: 0.260090] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3269 [D loss: 0.950931, acc.: 49.90%] [G loss: 0.259184] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3270 [D loss: 0.943988, acc.: 49.80%] [G loss: 0.255697] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3271 [D loss: 0.939222, acc.: 49.80%] [G loss: 0.262741] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3272 [D loss: 0.940322, acc.: 49.80%] [G loss: 0.270001] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3273 [D loss: 0.931037, acc.: 49.80%] [G loss: 0.265420] [Loss difference: -0.005, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3274 [D loss: 0.919581, acc.: 49.90%] [G loss: 0.262798] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3275 [D loss: 0.923217, acc.: 49.90%] [G loss: 0.269733] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3276 [D loss: 0.927783, acc.: 49.71%] [G loss: 0.260015] [Loss difference: -0.010, iterations with loss: 1]\n",
      "3277 [D loss: 0.934543, acc.: 50.00%] [G loss: 0.253509] [Loss difference: -0.007, iterations with loss: 0]\n",
      "3278 [D loss: 0.927311, acc.: 49.90%] [G loss: 0.263867] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3279 [D loss: 0.942234, acc.: 49.90%] [G loss: 0.256628] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3280 [D loss: 0.932561, acc.: 50.00%] [G loss: 0.262894] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3281 [D loss: 0.940863, acc.: 49.80%] [G loss: 0.260843] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3282 [D loss: 0.944814, acc.: 49.90%] [G loss: 0.263845] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3283 [D loss: 0.915640, acc.: 49.90%] [G loss: 0.267816] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3284 [D loss: 0.919991, acc.: 50.00%] [G loss: 0.270512] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3285 [D loss: 0.912335, acc.: 49.80%] [G loss: 0.262576] [Loss difference: -0.008, iterations with loss: 3]\n",
      "3286 [D loss: 0.910803, acc.: 49.90%] [G loss: 0.261966] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3287 [D loss: 0.925544, acc.: 49.80%] [G loss: 0.265336] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3288 [D loss: 0.915742, acc.: 49.80%] [G loss: 0.261368] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3289 [D loss: 0.921045, acc.: 49.90%] [G loss: 0.265159] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3290 [D loss: 0.925136, acc.: 49.90%] [G loss: 0.254704] [Loss difference: -0.010, iterations with loss: 1]\n",
      "3291 [D loss: 0.916537, acc.: 49.90%] [G loss: 0.256800] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3292 [D loss: 0.918738, acc.: 49.90%] [G loss: 0.260006] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3293 [D loss: 0.920387, acc.: 50.00%] [G loss: 0.254978] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3294 [D loss: 0.914328, acc.: 49.80%] [G loss: 0.258959] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3295 [D loss: 0.912990, acc.: 49.71%] [G loss: 0.258041] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3296 [D loss: 0.908973, acc.: 49.90%] [G loss: 0.256131] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3297 [D loss: 0.919340, acc.: 49.80%] [G loss: 0.257692] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3298 [D loss: 0.922530, acc.: 49.80%] [G loss: 0.264496] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3299 [D loss: 0.907750, acc.: 49.80%] [G loss: 0.259051] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3300 [D loss: 0.907790, acc.: 49.90%] [G loss: 0.267423] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3301 [D loss: 0.909066, acc.: 49.80%] [G loss: 0.268182] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3302 [D loss: 0.907324, acc.: 49.71%] [G loss: 0.266204] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3303 [D loss: 0.913181, acc.: 49.80%] [G loss: 0.270058] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3304 [D loss: 0.918831, acc.: 49.80%] [G loss: 0.261932] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3305 [D loss: 0.923593, acc.: 49.80%] [G loss: 0.263878] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3306 [D loss: 0.926845, acc.: 49.80%] [G loss: 0.256045] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3307 [D loss: 0.924497, acc.: 49.71%] [G loss: 0.261075] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3308 [D loss: 0.919126, acc.: 49.71%] [G loss: 0.263598] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3309 [D loss: 0.917125, acc.: 49.80%] [G loss: 0.257833] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3310 [D loss: 0.926404, acc.: 50.00%] [G loss: 0.263500] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3311 [D loss: 0.920847, acc.: 49.80%] [G loss: 0.258779] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3312 [D loss: 0.927244, acc.: 49.61%] [G loss: 0.262344] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3313 [D loss: 0.932706, acc.: 49.71%] [G loss: 0.263719] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3314 [D loss: 0.925814, acc.: 49.80%] [G loss: 0.262915] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3315 [D loss: 0.916321, acc.: 50.00%] [G loss: 0.265188] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3316 [D loss: 0.910948, acc.: 49.90%] [G loss: 0.266388] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3317 [D loss: 0.909737, acc.: 49.80%] [G loss: 0.262109] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3318 [D loss: 0.912350, acc.: 49.61%] [G loss: 0.262741] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3319 [D loss: 0.912288, acc.: 49.51%] [G loss: 0.260838] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3320 [D loss: 0.925504, acc.: 49.90%] [G loss: 0.263143] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3321 [D loss: 0.918321, acc.: 49.71%] [G loss: 0.262506] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3322 [D loss: 0.909959, acc.: 49.90%] [G loss: 0.264732] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3323 [D loss: 0.912819, acc.: 49.80%] [G loss: 0.262876] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3324 [D loss: 0.906911, acc.: 49.90%] [G loss: 0.267939] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3325 [D loss: 0.901245, acc.: 50.00%] [G loss: 0.264205] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3326 [D loss: 0.914674, acc.: 49.90%] [G loss: 0.272371] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3327 [D loss: 0.910881, acc.: 49.80%] [G loss: 0.260481] [Loss difference: -0.012, iterations with loss: 1]\n",
      "3328 [D loss: 0.909026, acc.: 49.61%] [G loss: 0.265852] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3329 [D loss: 0.913975, acc.: 49.90%] [G loss: 0.269641] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3330 [D loss: 0.910257, acc.: 49.61%] [G loss: 0.263654] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3331 [D loss: 0.899292, acc.: 49.90%] [G loss: 0.262483] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3332 [D loss: 0.912655, acc.: 49.71%] [G loss: 0.269344] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3333 [D loss: 0.915127, acc.: 49.80%] [G loss: 0.266743] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3334 [D loss: 0.904878, acc.: 50.00%] [G loss: 0.261485] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3335 [D loss: 0.906621, acc.: 49.71%] [G loss: 0.263316] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3336 [D loss: 0.904174, acc.: 50.00%] [G loss: 0.268934] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3337 [D loss: 0.904174, acc.: 50.00%] [G loss: 0.269617] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3338 [D loss: 0.903273, acc.: 49.71%] [G loss: 0.269931] [Loss difference: 0.000, iterations with loss: 3]\n",
      "3339 [D loss: 0.898409, acc.: 50.00%] [G loss: 0.271417] [Loss difference: 0.001, iterations with loss: 4]\n",
      "3340 [D loss: 0.897237, acc.: 50.00%] [G loss: 0.271259] [Loss difference: -0.000, iterations with loss: 5]\n",
      "3341 [D loss: 0.912137, acc.: 49.61%] [G loss: 0.267101] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3342 [D loss: 0.906983, acc.: 49.90%] [G loss: 0.264543] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3343 [D loss: 0.920277, acc.: 49.71%] [G loss: 0.266756] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3344 [D loss: 0.907974, acc.: 49.80%] [G loss: 0.261305] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3345 [D loss: 0.921770, acc.: 49.80%] [G loss: 0.261056] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3346 [D loss: 0.930886, acc.: 49.71%] [G loss: 0.271655] [Loss difference: 0.011, iterations with loss: 0]\n",
      "3347 [D loss: 0.917088, acc.: 49.90%] [G loss: 0.274009] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3348 [D loss: 0.909146, acc.: 49.71%] [G loss: 0.270320] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3349 [D loss: 0.898866, acc.: 50.00%] [G loss: 0.268955] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3350 [D loss: 0.898178, acc.: 50.00%] [G loss: 0.271534] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3351 [D loss: 0.900912, acc.: 49.71%] [G loss: 0.269050] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3352 [D loss: 0.912999, acc.: 49.71%] [G loss: 0.265589] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3353 [D loss: 0.923970, acc.: 49.61%] [G loss: 0.269207] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3354 [D loss: 0.913677, acc.: 49.61%] [G loss: 0.266497] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3355 [D loss: 0.910894, acc.: 49.71%] [G loss: 0.268606] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3356 [D loss: 0.923171, acc.: 49.90%] [G loss: 0.268315] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3357 [D loss: 0.919014, acc.: 49.80%] [G loss: 0.263669] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3358 [D loss: 0.915433, acc.: 49.61%] [G loss: 0.264257] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3359 [D loss: 0.915365, acc.: 49.80%] [G loss: 0.267188] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3360 [D loss: 0.916880, acc.: 49.80%] [G loss: 0.266867] [Loss difference: -0.000, iterations with loss: 2]\n",
      "3361 [D loss: 0.927982, acc.: 49.61%] [G loss: 0.265489] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3362 [D loss: 0.925209, acc.: 49.80%] [G loss: 0.268786] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3363 [D loss: 0.910473, acc.: 49.71%] [G loss: 0.264940] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3364 [D loss: 0.902320, acc.: 50.00%] [G loss: 0.270191] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3365 [D loss: 0.899484, acc.: 49.90%] [G loss: 0.277167] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3366 [D loss: 0.913151, acc.: 49.51%] [G loss: 0.265371] [Loss difference: -0.012, iterations with loss: 2]\n",
      "3367 [D loss: 0.929162, acc.: 49.80%] [G loss: 0.267770] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3368 [D loss: 0.916138, acc.: 49.71%] [G loss: 0.267911] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3369 [D loss: 0.916775, acc.: 49.61%] [G loss: 0.267174] [Loss difference: -0.001, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370 [D loss: 0.908933, acc.: 49.80%] [G loss: 0.269163] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3371 [D loss: 0.905088, acc.: 49.80%] [G loss: 0.273533] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3372 [D loss: 0.908368, acc.: 49.71%] [G loss: 0.280174] [Loss difference: 0.007, iterations with loss: 2]\n",
      "3373 [D loss: 0.917070, acc.: 49.51%] [G loss: 0.275708] [Loss difference: -0.004, iterations with loss: 3]\n",
      "3374 [D loss: 0.906182, acc.: 49.80%] [G loss: 0.275384] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3375 [D loss: 0.900420, acc.: 49.90%] [G loss: 0.279149] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3376 [D loss: 0.914261, acc.: 49.80%] [G loss: 0.271610] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3377 [D loss: 0.911428, acc.: 49.80%] [G loss: 0.268841] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3378 [D loss: 0.907074, acc.: 49.80%] [G loss: 0.265603] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3379 [D loss: 0.905330, acc.: 49.71%] [G loss: 0.272413] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3380 [D loss: 0.907237, acc.: 49.61%] [G loss: 0.266511] [Loss difference: -0.006, iterations with loss: 1]\n",
      "3381 [D loss: 0.898681, acc.: 49.80%] [G loss: 0.268716] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3382 [D loss: 0.899235, acc.: 49.71%] [G loss: 0.277036] [Loss difference: 0.008, iterations with loss: 1]\n",
      "3383 [D loss: 0.904715, acc.: 49.80%] [G loss: 0.273936] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3384 [D loss: 0.900716, acc.: 49.90%] [G loss: 0.274507] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3385 [D loss: 0.904440, acc.: 50.00%] [G loss: 0.273711] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3386 [D loss: 0.903926, acc.: 49.90%] [G loss: 0.271633] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3387 [D loss: 0.903075, acc.: 49.71%] [G loss: 0.276860] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3388 [D loss: 0.892805, acc.: 49.90%] [G loss: 0.276072] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3389 [D loss: 0.902854, acc.: 49.90%] [G loss: 0.273838] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3390 [D loss: 0.907348, acc.: 49.90%] [G loss: 0.265960] [Loss difference: -0.008, iterations with loss: 0]\n",
      "3391 [D loss: 0.914238, acc.: 49.90%] [G loss: 0.270668] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3392 [D loss: 0.910584, acc.: 50.00%] [G loss: 0.280684] [Loss difference: 0.010, iterations with loss: 1]\n",
      "3393 [D loss: 0.891845, acc.: 49.80%] [G loss: 0.276269] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3394 [D loss: 0.902511, acc.: 49.71%] [G loss: 0.275616] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3395 [D loss: 0.906581, acc.: 49.80%] [G loss: 0.268977] [Loss difference: -0.007, iterations with loss: 0]\n",
      "3396 [D loss: 0.914987, acc.: 49.90%] [G loss: 0.272276] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3397 [D loss: 0.900660, acc.: 49.80%] [G loss: 0.274079] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3398 [D loss: 0.912098, acc.: 49.71%] [G loss: 0.276679] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3399 [D loss: 0.897677, acc.: 49.80%] [G loss: 0.272024] [Loss difference: -0.005, iterations with loss: 3]\n",
      "3400 [D loss: 0.911532, acc.: 49.80%] [G loss: 0.276511] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3401 [D loss: 0.915629, acc.: 49.71%] [G loss: 0.273275] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3402 [D loss: 0.906559, acc.: 49.80%] [G loss: 0.277385] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3403 [D loss: 0.899096, acc.: 49.90%] [G loss: 0.276628] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3404 [D loss: 0.902821, acc.: 49.80%] [G loss: 0.276426] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3405 [D loss: 0.906285, acc.: 49.80%] [G loss: 0.281158] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3406 [D loss: 0.899827, acc.: 49.71%] [G loss: 0.278199] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3407 [D loss: 0.903185, acc.: 49.90%] [G loss: 0.275770] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3408 [D loss: 0.917989, acc.: 49.80%] [G loss: 0.276250] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3409 [D loss: 0.915229, acc.: 49.51%] [G loss: 0.271418] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3410 [D loss: 0.893062, acc.: 50.00%] [G loss: 0.271937] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3411 [D loss: 0.909300, acc.: 50.00%] [G loss: 0.275942] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3412 [D loss: 0.912540, acc.: 49.71%] [G loss: 0.280165] [Loss difference: 0.004, iterations with loss: 2]\n",
      "3413 [D loss: 0.892554, acc.: 49.71%] [G loss: 0.277899] [Loss difference: -0.002, iterations with loss: 3]\n",
      "3414 [D loss: 0.892987, acc.: 50.00%] [G loss: 0.275721] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3415 [D loss: 0.885668, acc.: 49.71%] [G loss: 0.274665] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3416 [D loss: 0.901248, acc.: 49.80%] [G loss: 0.276220] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3417 [D loss: 0.892006, acc.: 49.80%] [G loss: 0.275322] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3418 [D loss: 0.895637, acc.: 49.90%] [G loss: 0.275305] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3419 [D loss: 0.897064, acc.: 49.71%] [G loss: 0.274109] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3420 [D loss: 0.894109, acc.: 49.90%] [G loss: 0.274747] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3421 [D loss: 0.898724, acc.: 49.90%] [G loss: 0.277817] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3422 [D loss: 0.890036, acc.: 49.90%] [G loss: 0.274047] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3423 [D loss: 0.900457, acc.: 49.80%] [G loss: 0.275171] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3424 [D loss: 0.887656, acc.: 49.80%] [G loss: 0.281143] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3425 [D loss: 0.889347, acc.: 49.90%] [G loss: 0.275741] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3426 [D loss: 0.895088, acc.: 50.00%] [G loss: 0.276821] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3427 [D loss: 0.885964, acc.: 49.80%] [G loss: 0.278892] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3428 [D loss: 0.892922, acc.: 49.90%] [G loss: 0.273186] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3429 [D loss: 0.895966, acc.: 49.80%] [G loss: 0.274385] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3430 [D loss: 0.910758, acc.: 49.90%] [G loss: 0.276942] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3431 [D loss: 0.907063, acc.: 49.80%] [G loss: 0.276692] [Loss difference: -0.000, iterations with loss: 2]\n",
      "3432 [D loss: 0.894678, acc.: 49.90%] [G loss: 0.275443] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3433 [D loss: 0.903148, acc.: 49.80%] [G loss: 0.276053] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3434 [D loss: 0.906878, acc.: 49.90%] [G loss: 0.280918] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3435 [D loss: 0.892675, acc.: 49.90%] [G loss: 0.277679] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3436 [D loss: 0.897046, acc.: 49.80%] [G loss: 0.285488] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3437 [D loss: 0.915570, acc.: 49.61%] [G loss: 0.277295] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3438 [D loss: 0.905922, acc.: 49.90%] [G loss: 0.276872] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3439 [D loss: 0.900249, acc.: 49.90%] [G loss: 0.278937] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3440 [D loss: 0.902547, acc.: 49.71%] [G loss: 0.281898] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3441 [D loss: 0.889272, acc.: 49.71%] [G loss: 0.282038] [Loss difference: 0.000, iterations with loss: 2]\n",
      "3442 [D loss: 0.894962, acc.: 49.80%] [G loss: 0.276328] [Loss difference: -0.006, iterations with loss: 3]\n",
      "3443 [D loss: 0.887156, acc.: 49.90%] [G loss: 0.277830] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3444 [D loss: 0.894831, acc.: 49.80%] [G loss: 0.275720] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3445 [D loss: 0.904828, acc.: 49.80%] [G loss: 0.278423] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3446 [D loss: 0.905779, acc.: 49.80%] [G loss: 0.282274] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3447 [D loss: 0.888563, acc.: 49.80%] [G loss: 0.278460] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3448 [D loss: 0.881162, acc.: 49.80%] [G loss: 0.282486] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3449 [D loss: 0.888966, acc.: 49.80%] [G loss: 0.283376] [Loss difference: 0.001, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3450 [D loss: 0.893583, acc.: 49.90%] [G loss: 0.281414] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3451 [D loss: 0.890534, acc.: 50.00%] [G loss: 0.281315] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3452 [D loss: 0.900527, acc.: 49.51%] [G loss: 0.279359] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3453 [D loss: 0.895762, acc.: 50.00%] [G loss: 0.275276] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3454 [D loss: 0.904237, acc.: 49.80%] [G loss: 0.280425] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3455 [D loss: 0.897578, acc.: 49.80%] [G loss: 0.278548] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3456 [D loss: 0.898158, acc.: 49.71%] [G loss: 0.287426] [Loss difference: 0.009, iterations with loss: 0]\n",
      "3457 [D loss: 0.894240, acc.: 49.80%] [G loss: 0.277419] [Loss difference: -0.010, iterations with loss: 1]\n",
      "3458 [D loss: 0.901012, acc.: 49.80%] [G loss: 0.285713] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3459 [D loss: 0.905532, acc.: 49.71%] [G loss: 0.284663] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3460 [D loss: 0.903004, acc.: 49.71%] [G loss: 0.280898] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3461 [D loss: 0.896442, acc.: 49.90%] [G loss: 0.279508] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3462 [D loss: 0.899968, acc.: 49.61%] [G loss: 0.276949] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3463 [D loss: 0.906927, acc.: 50.00%] [G loss: 0.283424] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3464 [D loss: 0.887850, acc.: 49.90%] [G loss: 0.281639] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3465 [D loss: 0.903715, acc.: 50.00%] [G loss: 0.279974] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3466 [D loss: 0.894214, acc.: 49.80%] [G loss: 0.280768] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3467 [D loss: 0.900714, acc.: 49.71%] [G loss: 0.285898] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3468 [D loss: 0.905125, acc.: 49.90%] [G loss: 0.280776] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3469 [D loss: 0.894060, acc.: 49.90%] [G loss: 0.282726] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3470 [D loss: 0.885217, acc.: 49.90%] [G loss: 0.281485] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3471 [D loss: 0.884092, acc.: 49.90%] [G loss: 0.278523] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3472 [D loss: 0.902627, acc.: 49.71%] [G loss: 0.285344] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3473 [D loss: 0.889361, acc.: 49.90%] [G loss: 0.278692] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3474 [D loss: 0.902321, acc.: 49.90%] [G loss: 0.281561] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3475 [D loss: 0.901618, acc.: 49.80%] [G loss: 0.280346] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3476 [D loss: 0.894546, acc.: 49.80%] [G loss: 0.283364] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3477 [D loss: 0.875202, acc.: 50.00%] [G loss: 0.281311] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3478 [D loss: 0.885669, acc.: 49.61%] [G loss: 0.280472] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3479 [D loss: 0.896627, acc.: 50.00%] [G loss: 0.283085] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3480 [D loss: 0.890009, acc.: 50.00%] [G loss: 0.280213] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3481 [D loss: 0.898531, acc.: 49.71%] [G loss: 0.291221] [Loss difference: 0.011, iterations with loss: 0]\n",
      "3482 [D loss: 0.898935, acc.: 49.61%] [G loss: 0.280594] [Loss difference: -0.011, iterations with loss: 1]\n",
      "3483 [D loss: 0.880334, acc.: 49.80%] [G loss: 0.288824] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3484 [D loss: 0.883043, acc.: 49.71%] [G loss: 0.284127] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3485 [D loss: 0.883724, acc.: 49.90%] [G loss: 0.281908] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3486 [D loss: 0.887052, acc.: 49.80%] [G loss: 0.287559] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3487 [D loss: 0.884919, acc.: 50.00%] [G loss: 0.278139] [Loss difference: -0.009, iterations with loss: 1]\n",
      "3488 [D loss: 0.892056, acc.: 49.90%] [G loss: 0.286965] [Loss difference: 0.009, iterations with loss: 0]\n",
      "3489 [D loss: 0.898073, acc.: 49.71%] [G loss: 0.287084] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3490 [D loss: 0.901673, acc.: 49.80%] [G loss: 0.289777] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3491 [D loss: 0.890841, acc.: 49.80%] [G loss: 0.286640] [Loss difference: -0.003, iterations with loss: 3]\n",
      "3492 [D loss: 0.885160, acc.: 49.90%] [G loss: 0.282977] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3493 [D loss: 0.889778, acc.: 49.80%] [G loss: 0.281936] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3494 [D loss: 0.897102, acc.: 49.80%] [G loss: 0.285005] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3495 [D loss: 0.872200, acc.: 49.90%] [G loss: 0.293198] [Loss difference: 0.008, iterations with loss: 1]\n",
      "3496 [D loss: 0.885276, acc.: 49.90%] [G loss: 0.281650] [Loss difference: -0.012, iterations with loss: 2]\n",
      "3497 [D loss: 0.887035, acc.: 49.71%] [G loss: 0.284075] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3498 [D loss: 0.871172, acc.: 49.90%] [G loss: 0.289726] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3499 [D loss: 0.883611, acc.: 49.80%] [G loss: 0.282781] [Loss difference: -0.007, iterations with loss: 2]\n",
      "3500 [D loss: 0.883757, acc.: 49.80%] [G loss: 0.289402] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3501 [D loss: 0.895488, acc.: 49.61%] [G loss: 0.288634] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3502 [D loss: 0.883069, acc.: 49.61%] [G loss: 0.285912] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3503 [D loss: 0.894422, acc.: 49.90%] [G loss: 0.285429] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3504 [D loss: 0.880538, acc.: 49.90%] [G loss: 0.283900] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3505 [D loss: 0.893061, acc.: 49.71%] [G loss: 0.278858] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3506 [D loss: 0.881316, acc.: 50.00%] [G loss: 0.282905] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3507 [D loss: 0.893388, acc.: 49.41%] [G loss: 0.286229] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3508 [D loss: 0.900188, acc.: 49.61%] [G loss: 0.287145] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3509 [D loss: 0.898660, acc.: 49.80%] [G loss: 0.281508] [Loss difference: -0.006, iterations with loss: 3]\n",
      "3510 [D loss: 0.903650, acc.: 49.71%] [G loss: 0.286977] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3511 [D loss: 0.885647, acc.: 49.90%] [G loss: 0.289769] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3512 [D loss: 0.884519, acc.: 49.80%] [G loss: 0.289135] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3513 [D loss: 0.888802, acc.: 49.90%] [G loss: 0.288140] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3514 [D loss: 0.872749, acc.: 50.00%] [G loss: 0.292351] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3515 [D loss: 0.865590, acc.: 49.90%] [G loss: 0.284719] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3516 [D loss: 0.880589, acc.: 49.80%] [G loss: 0.284718] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3517 [D loss: 0.900274, acc.: 49.51%] [G loss: 0.285360] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3518 [D loss: 0.898117, acc.: 49.80%] [G loss: 0.286416] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3519 [D loss: 0.892358, acc.: 49.80%] [G loss: 0.283258] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3520 [D loss: 0.888779, acc.: 49.71%] [G loss: 0.287820] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3521 [D loss: 0.880022, acc.: 49.51%] [G loss: 0.286566] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3522 [D loss: 0.888234, acc.: 49.71%] [G loss: 0.287486] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3523 [D loss: 0.881884, acc.: 49.90%] [G loss: 0.291827] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3524 [D loss: 0.897584, acc.: 49.90%] [G loss: 0.290640] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3525 [D loss: 0.886056, acc.: 50.00%] [G loss: 0.293470] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3526 [D loss: 0.887594, acc.: 49.71%] [G loss: 0.294022] [Loss difference: 0.001, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527 [D loss: 0.893051, acc.: 50.00%] [G loss: 0.289245] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3528 [D loss: 0.878812, acc.: 49.80%] [G loss: 0.290046] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3529 [D loss: 0.869305, acc.: 50.00%] [G loss: 0.293801] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3530 [D loss: 0.874999, acc.: 49.90%] [G loss: 0.289683] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3531 [D loss: 0.879546, acc.: 49.90%] [G loss: 0.290173] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3532 [D loss: 0.878780, acc.: 49.61%] [G loss: 0.286678] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3533 [D loss: 0.892600, acc.: 49.90%] [G loss: 0.289345] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3534 [D loss: 0.892650, acc.: 49.90%] [G loss: 0.295539] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3535 [D loss: 0.892962, acc.: 49.51%] [G loss: 0.292601] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3536 [D loss: 0.873044, acc.: 49.90%] [G loss: 0.291150] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3537 [D loss: 0.885942, acc.: 49.80%] [G loss: 0.289056] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3538 [D loss: 0.878083, acc.: 49.71%] [G loss: 0.290648] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3539 [D loss: 0.874725, acc.: 49.90%] [G loss: 0.289746] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3540 [D loss: 0.880271, acc.: 49.71%] [G loss: 0.285685] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3541 [D loss: 0.871111, acc.: 49.90%] [G loss: 0.297866] [Loss difference: 0.012, iterations with loss: 0]\n",
      "3542 [D loss: 0.891467, acc.: 49.71%] [G loss: 0.288681] [Loss difference: -0.009, iterations with loss: 1]\n",
      "3543 [D loss: 0.870882, acc.: 49.90%] [G loss: 0.292474] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3544 [D loss: 0.879356, acc.: 49.71%] [G loss: 0.296510] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3545 [D loss: 0.873146, acc.: 49.80%] [G loss: 0.288071] [Loss difference: -0.008, iterations with loss: 2]\n",
      "3546 [D loss: 0.890625, acc.: 49.71%] [G loss: 0.290832] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3547 [D loss: 0.892795, acc.: 49.71%] [G loss: 0.289652] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3548 [D loss: 0.885922, acc.: 49.90%] [G loss: 0.289485] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3549 [D loss: 0.890411, acc.: 49.90%] [G loss: 0.288898] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3550 [D loss: 0.878225, acc.: 50.00%] [G loss: 0.287638] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3551 [D loss: 0.891382, acc.: 49.80%] [G loss: 0.293078] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3552 [D loss: 0.896141, acc.: 49.90%] [G loss: 0.294123] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3553 [D loss: 0.877883, acc.: 49.80%] [G loss: 0.297232] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3554 [D loss: 0.877312, acc.: 49.80%] [G loss: 0.300466] [Loss difference: 0.003, iterations with loss: 3]\n",
      "3555 [D loss: 0.877483, acc.: 49.80%] [G loss: 0.300465] [Loss difference: -0.000, iterations with loss: 4]\n",
      "3556 [D loss: 0.881075, acc.: 50.00%] [G loss: 0.295258] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3557 [D loss: 0.890277, acc.: 50.00%] [G loss: 0.287551] [Loss difference: -0.008, iterations with loss: 0]\n",
      "3558 [D loss: 0.895076, acc.: 49.71%] [G loss: 0.292417] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3559 [D loss: 0.901833, acc.: 49.80%] [G loss: 0.293437] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3560 [D loss: 0.889680, acc.: 49.90%] [G loss: 0.291069] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3561 [D loss: 0.875472, acc.: 49.90%] [G loss: 0.290687] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3562 [D loss: 0.876620, acc.: 49.90%] [G loss: 0.294685] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3563 [D loss: 0.862817, acc.: 50.00%] [G loss: 0.290428] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3564 [D loss: 0.885424, acc.: 49.71%] [G loss: 0.291394] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3565 [D loss: 0.886113, acc.: 49.80%] [G loss: 0.288987] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3566 [D loss: 0.894245, acc.: 49.90%] [G loss: 0.290735] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3567 [D loss: 0.881368, acc.: 49.71%] [G loss: 0.302732] [Loss difference: 0.012, iterations with loss: 1]\n",
      "3568 [D loss: 0.863294, acc.: 49.90%] [G loss: 0.293352] [Loss difference: -0.009, iterations with loss: 2]\n",
      "3569 [D loss: 0.886942, acc.: 49.71%] [G loss: 0.294526] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3570 [D loss: 0.880589, acc.: 49.90%] [G loss: 0.292687] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3571 [D loss: 0.878716, acc.: 49.80%] [G loss: 0.299064] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3572 [D loss: 0.870887, acc.: 49.80%] [G loss: 0.295939] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3573 [D loss: 0.874940, acc.: 49.80%] [G loss: 0.300236] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3574 [D loss: 0.854537, acc.: 50.00%] [G loss: 0.299341] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3575 [D loss: 0.883939, acc.: 49.51%] [G loss: 0.290795] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3576 [D loss: 0.888613, acc.: 49.80%] [G loss: 0.298503] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3577 [D loss: 0.867989, acc.: 49.90%] [G loss: 0.296792] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3578 [D loss: 0.866911, acc.: 49.80%] [G loss: 0.301060] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3579 [D loss: 0.869401, acc.: 49.80%] [G loss: 0.296766] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3580 [D loss: 0.870137, acc.: 49.90%] [G loss: 0.288949] [Loss difference: -0.008, iterations with loss: 0]\n",
      "3581 [D loss: 0.892022, acc.: 49.90%] [G loss: 0.286102] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3582 [D loss: 0.896695, acc.: 49.90%] [G loss: 0.296565] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3583 [D loss: 0.887534, acc.: 49.90%] [G loss: 0.302639] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3584 [D loss: 0.865911, acc.: 49.71%] [G loss: 0.297037] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3585 [D loss: 0.876947, acc.: 49.80%] [G loss: 0.302532] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3586 [D loss: 0.867594, acc.: 50.00%] [G loss: 0.301173] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3587 [D loss: 0.889109, acc.: 49.80%] [G loss: 0.293037] [Loss difference: -0.008, iterations with loss: 0]\n",
      "3588 [D loss: 0.884765, acc.: 50.00%] [G loss: 0.303496] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3589 [D loss: 0.895594, acc.: 49.41%] [G loss: 0.293060] [Loss difference: -0.010, iterations with loss: 1]\n",
      "3590 [D loss: 0.875849, acc.: 49.51%] [G loss: 0.293255] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3591 [D loss: 0.876135, acc.: 49.80%] [G loss: 0.301173] [Loss difference: 0.008, iterations with loss: 1]\n",
      "3592 [D loss: 0.869218, acc.: 49.71%] [G loss: 0.301482] [Loss difference: 0.000, iterations with loss: 2]\n",
      "3593 [D loss: 0.876135, acc.: 49.41%] [G loss: 0.292000] [Loss difference: -0.009, iterations with loss: 3]\n",
      "3594 [D loss: 0.872726, acc.: 49.80%] [G loss: 0.294248] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3595 [D loss: 0.876029, acc.: 49.80%] [G loss: 0.297142] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3596 [D loss: 0.854906, acc.: 49.90%] [G loss: 0.296967] [Loss difference: -0.000, iterations with loss: 2]\n",
      "3597 [D loss: 0.880653, acc.: 49.80%] [G loss: 0.300894] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3598 [D loss: 0.882954, acc.: 49.61%] [G loss: 0.298536] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3599 [D loss: 0.895151, acc.: 49.71%] [G loss: 0.294754] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3600 [D loss: 0.879075, acc.: 50.00%] [G loss: 0.296405] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3601 [D loss: 0.877369, acc.: 49.80%] [G loss: 0.297496] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3602 [D loss: 0.882324, acc.: 49.80%] [G loss: 0.299835] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3603 [D loss: 0.869079, acc.: 49.61%] [G loss: 0.295975] [Loss difference: -0.004, iterations with loss: 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3604 [D loss: 0.881627, acc.: 49.71%] [G loss: 0.299614] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3605 [D loss: 0.863851, acc.: 49.90%] [G loss: 0.303838] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3606 [D loss: 0.882907, acc.: 49.41%] [G loss: 0.301521] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3607 [D loss: 0.872511, acc.: 49.80%] [G loss: 0.296929] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3608 [D loss: 0.877951, acc.: 49.90%] [G loss: 0.300627] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3609 [D loss: 0.886487, acc.: 49.61%] [G loss: 0.300427] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3610 [D loss: 0.882674, acc.: 49.80%] [G loss: 0.299400] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3611 [D loss: 0.887198, acc.: 49.80%] [G loss: 0.300267] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3612 [D loss: 0.874162, acc.: 50.00%] [G loss: 0.300354] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3613 [D loss: 0.869424, acc.: 49.71%] [G loss: 0.293080] [Loss difference: -0.007, iterations with loss: 2]\n",
      "3614 [D loss: 0.857185, acc.: 50.00%] [G loss: 0.298610] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3615 [D loss: 0.874237, acc.: 49.80%] [G loss: 0.304387] [Loss difference: 0.006, iterations with loss: 1]\n",
      "3616 [D loss: 0.876774, acc.: 49.71%] [G loss: 0.306068] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3617 [D loss: 0.856736, acc.: 49.90%] [G loss: 0.306506] [Loss difference: 0.000, iterations with loss: 3]\n",
      "3618 [D loss: 0.866790, acc.: 50.00%] [G loss: 0.305092] [Loss difference: -0.001, iterations with loss: 4]\n",
      "3619 [D loss: 0.875525, acc.: 49.71%] [G loss: 0.304139] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3620 [D loss: 0.882720, acc.: 49.90%] [G loss: 0.301883] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3621 [D loss: 0.879441, acc.: 49.90%] [G loss: 0.302076] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3622 [D loss: 0.878781, acc.: 49.80%] [G loss: 0.303580] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3623 [D loss: 0.877859, acc.: 49.90%] [G loss: 0.300615] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3624 [D loss: 0.872888, acc.: 49.41%] [G loss: 0.303375] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3625 [D loss: 0.871905, acc.: 50.00%] [G loss: 0.306879] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3626 [D loss: 0.858228, acc.: 49.80%] [G loss: 0.300817] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3627 [D loss: 0.856485, acc.: 49.80%] [G loss: 0.296499] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3628 [D loss: 0.869064, acc.: 49.71%] [G loss: 0.297707] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3629 [D loss: 0.866708, acc.: 49.90%] [G loss: 0.306125] [Loss difference: 0.008, iterations with loss: 1]\n",
      "3630 [D loss: 0.866994, acc.: 49.80%] [G loss: 0.298483] [Loss difference: -0.008, iterations with loss: 2]\n",
      "3631 [D loss: 0.876010, acc.: 49.90%] [G loss: 0.298151] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3632 [D loss: 0.867052, acc.: 49.71%] [G loss: 0.307928] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3633 [D loss: 0.859745, acc.: 49.90%] [G loss: 0.307600] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3634 [D loss: 0.861397, acc.: 50.00%] [G loss: 0.303965] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3635 [D loss: 0.863298, acc.: 49.80%] [G loss: 0.298478] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3636 [D loss: 0.859885, acc.: 49.71%] [G loss: 0.299950] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3637 [D loss: 0.869232, acc.: 49.71%] [G loss: 0.303685] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3638 [D loss: 0.883408, acc.: 49.51%] [G loss: 0.306052] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3639 [D loss: 0.861915, acc.: 49.80%] [G loss: 0.306355] [Loss difference: 0.000, iterations with loss: 3]\n",
      "3640 [D loss: 0.870063, acc.: 49.80%] [G loss: 0.298233] [Loss difference: -0.008, iterations with loss: 4]\n",
      "3641 [D loss: 0.859924, acc.: 49.90%] [G loss: 0.304245] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3642 [D loss: 0.865341, acc.: 49.90%] [G loss: 0.300210] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3643 [D loss: 0.887086, acc.: 49.80%] [G loss: 0.301079] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3644 [D loss: 0.862891, acc.: 50.00%] [G loss: 0.305148] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3645 [D loss: 0.854093, acc.: 49.90%] [G loss: 0.301613] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3646 [D loss: 0.849366, acc.: 49.90%] [G loss: 0.304723] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3647 [D loss: 0.870903, acc.: 49.80%] [G loss: 0.303031] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3648 [D loss: 0.859993, acc.: 49.80%] [G loss: 0.305059] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3649 [D loss: 0.872298, acc.: 50.00%] [G loss: 0.303157] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3650 [D loss: 0.864509, acc.: 49.90%] [G loss: 0.300969] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3651 [D loss: 0.874134, acc.: 49.80%] [G loss: 0.301769] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3652 [D loss: 0.867499, acc.: 49.71%] [G loss: 0.305186] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3653 [D loss: 0.859080, acc.: 49.90%] [G loss: 0.300649] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3654 [D loss: 0.844212, acc.: 49.90%] [G loss: 0.300261] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3655 [D loss: 0.868401, acc.: 49.71%] [G loss: 0.303799] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3656 [D loss: 0.866323, acc.: 49.90%] [G loss: 0.310711] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3657 [D loss: 0.851888, acc.: 49.90%] [G loss: 0.310255] [Loss difference: -0.000, iterations with loss: 2]\n",
      "3658 [D loss: 0.847248, acc.: 49.90%] [G loss: 0.309672] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3659 [D loss: 0.861745, acc.: 49.90%] [G loss: 0.300440] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3660 [D loss: 0.882076, acc.: 49.80%] [G loss: 0.300876] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3661 [D loss: 0.868941, acc.: 49.71%] [G loss: 0.308122] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3662 [D loss: 0.864452, acc.: 49.90%] [G loss: 0.304969] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3663 [D loss: 0.860406, acc.: 49.80%] [G loss: 0.300882] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3664 [D loss: 0.860466, acc.: 50.00%] [G loss: 0.296986] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3665 [D loss: 0.875666, acc.: 49.80%] [G loss: 0.306568] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3666 [D loss: 0.865895, acc.: 49.61%] [G loss: 0.314781] [Loss difference: 0.008, iterations with loss: 1]\n",
      "3667 [D loss: 0.847675, acc.: 49.80%] [G loss: 0.309284] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3668 [D loss: 0.830712, acc.: 50.00%] [G loss: 0.307626] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3669 [D loss: 0.859326, acc.: 49.71%] [G loss: 0.307550] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3670 [D loss: 0.868738, acc.: 49.71%] [G loss: 0.300109] [Loss difference: -0.007, iterations with loss: 0]\n",
      "3671 [D loss: 0.865100, acc.: 49.80%] [G loss: 0.303379] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3672 [D loss: 0.870645, acc.: 49.71%] [G loss: 0.305307] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3673 [D loss: 0.864532, acc.: 49.90%] [G loss: 0.304363] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3674 [D loss: 0.867983, acc.: 49.61%] [G loss: 0.310564] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3675 [D loss: 0.862754, acc.: 49.80%] [G loss: 0.309747] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3676 [D loss: 0.847391, acc.: 49.71%] [G loss: 0.303939] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3677 [D loss: 0.860584, acc.: 49.61%] [G loss: 0.302095] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3678 [D loss: 0.849633, acc.: 49.90%] [G loss: 0.305923] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3679 [D loss: 0.862793, acc.: 49.80%] [G loss: 0.305841] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3680 [D loss: 0.867733, acc.: 49.80%] [G loss: 0.306740] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3681 [D loss: 0.851924, acc.: 50.00%] [G loss: 0.311570] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3682 [D loss: 0.851513, acc.: 50.00%] [G loss: 0.314804] [Loss difference: 0.003, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3683 [D loss: 0.839300, acc.: 49.90%] [G loss: 0.307949] [Loss difference: -0.007, iterations with loss: 3]\n",
      "3684 [D loss: 0.862057, acc.: 49.80%] [G loss: 0.310309] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3685 [D loss: 0.853269, acc.: 49.71%] [G loss: 0.310697] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3686 [D loss: 0.853771, acc.: 49.71%] [G loss: 0.315040] [Loss difference: 0.004, iterations with loss: 2]\n",
      "3687 [D loss: 0.860180, acc.: 49.90%] [G loss: 0.311424] [Loss difference: -0.004, iterations with loss: 3]\n",
      "3688 [D loss: 0.875953, acc.: 49.71%] [G loss: 0.302624] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3689 [D loss: 0.866360, acc.: 49.61%] [G loss: 0.315160] [Loss difference: 0.013, iterations with loss: 0]\n",
      "3690 [D loss: 0.879182, acc.: 49.61%] [G loss: 0.311936] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3691 [D loss: 0.874563, acc.: 49.80%] [G loss: 0.306176] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3692 [D loss: 0.864233, acc.: 49.80%] [G loss: 0.312937] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3693 [D loss: 0.855274, acc.: 49.71%] [G loss: 0.315748] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3694 [D loss: 0.847780, acc.: 49.80%] [G loss: 0.308506] [Loss difference: -0.007, iterations with loss: 2]\n",
      "3695 [D loss: 0.862655, acc.: 49.71%] [G loss: 0.305557] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3696 [D loss: 0.866557, acc.: 49.71%] [G loss: 0.310257] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3697 [D loss: 0.870109, acc.: 49.61%] [G loss: 0.309922] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3698 [D loss: 0.843431, acc.: 50.00%] [G loss: 0.307465] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3699 [D loss: 0.863184, acc.: 49.71%] [G loss: 0.311028] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3700 [D loss: 0.857392, acc.: 49.80%] [G loss: 0.303971] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3701 [D loss: 0.862005, acc.: 49.80%] [G loss: 0.318153] [Loss difference: 0.014, iterations with loss: 0]\n",
      "3702 [D loss: 0.862422, acc.: 49.80%] [G loss: 0.306479] [Loss difference: -0.012, iterations with loss: 1]\n",
      "3703 [D loss: 0.853071, acc.: 49.90%] [G loss: 0.312778] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3704 [D loss: 0.866604, acc.: 49.71%] [G loss: 0.312996] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3705 [D loss: 0.861622, acc.: 50.00%] [G loss: 0.311779] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3706 [D loss: 0.860406, acc.: 49.90%] [G loss: 0.308674] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3707 [D loss: 0.861808, acc.: 49.71%] [G loss: 0.311901] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3708 [D loss: 0.863123, acc.: 49.90%] [G loss: 0.310258] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3709 [D loss: 0.846424, acc.: 50.00%] [G loss: 0.310205] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3710 [D loss: 0.856172, acc.: 49.90%] [G loss: 0.307974] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3711 [D loss: 0.849261, acc.: 49.71%] [G loss: 0.310163] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3712 [D loss: 0.861721, acc.: 49.71%] [G loss: 0.311053] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3713 [D loss: 0.855606, acc.: 49.71%] [G loss: 0.312366] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3714 [D loss: 0.856328, acc.: 49.90%] [G loss: 0.314885] [Loss difference: 0.003, iterations with loss: 3]\n",
      "3715 [D loss: 0.829388, acc.: 50.00%] [G loss: 0.314091] [Loss difference: -0.001, iterations with loss: 4]\n",
      "3716 [D loss: 0.854509, acc.: 49.80%] [G loss: 0.318245] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3717 [D loss: 0.847727, acc.: 49.90%] [G loss: 0.312889] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3718 [D loss: 0.851456, acc.: 49.80%] [G loss: 0.314442] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3719 [D loss: 0.831294, acc.: 49.90%] [G loss: 0.309820] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3720 [D loss: 0.854841, acc.: 49.71%] [G loss: 0.313466] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3721 [D loss: 0.841258, acc.: 50.00%] [G loss: 0.310717] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3722 [D loss: 0.882915, acc.: 49.61%] [G loss: 0.314461] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3723 [D loss: 0.851949, acc.: 49.90%] [G loss: 0.319368] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3724 [D loss: 0.855928, acc.: 49.80%] [G loss: 0.307279] [Loss difference: -0.012, iterations with loss: 2]\n",
      "3725 [D loss: 0.865425, acc.: 49.90%] [G loss: 0.313925] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3726 [D loss: 0.848517, acc.: 49.90%] [G loss: 0.309464] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3727 [D loss: 0.849228, acc.: 50.00%] [G loss: 0.318338] [Loss difference: 0.009, iterations with loss: 0]\n",
      "3728 [D loss: 0.849944, acc.: 49.90%] [G loss: 0.318678] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3729 [D loss: 0.852460, acc.: 50.00%] [G loss: 0.317953] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3730 [D loss: 0.845530, acc.: 49.61%] [G loss: 0.320629] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3731 [D loss: 0.840499, acc.: 49.90%] [G loss: 0.316794] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3732 [D loss: 0.850780, acc.: 50.00%] [G loss: 0.310453] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3733 [D loss: 0.864824, acc.: 49.61%] [G loss: 0.311375] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3734 [D loss: 0.851115, acc.: 49.51%] [G loss: 0.311847] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3735 [D loss: 0.858640, acc.: 49.41%] [G loss: 0.312469] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3736 [D loss: 0.854872, acc.: 49.71%] [G loss: 0.317030] [Loss difference: 0.005, iterations with loss: 3]\n",
      "3737 [D loss: 0.837343, acc.: 50.00%] [G loss: 0.317241] [Loss difference: 0.000, iterations with loss: 4]\n",
      "3738 [D loss: 0.853038, acc.: 49.32%] [G loss: 0.314741] [Loss difference: -0.003, iterations with loss: 5]\n",
      "3739 [D loss: 0.840192, acc.: 50.00%] [G loss: 0.320781] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3740 [D loss: 0.837015, acc.: 49.90%] [G loss: 0.317737] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3741 [D loss: 0.847030, acc.: 49.80%] [G loss: 0.312234] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3742 [D loss: 0.849216, acc.: 49.61%] [G loss: 0.314018] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3743 [D loss: 0.854308, acc.: 49.80%] [G loss: 0.312019] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3744 [D loss: 0.848892, acc.: 49.71%] [G loss: 0.313878] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3745 [D loss: 0.859413, acc.: 49.61%] [G loss: 0.311358] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3746 [D loss: 0.852516, acc.: 49.80%] [G loss: 0.315675] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3747 [D loss: 0.854373, acc.: 49.71%] [G loss: 0.318501] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3748 [D loss: 0.849938, acc.: 49.80%] [G loss: 0.316025] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3749 [D loss: 0.848670, acc.: 50.00%] [G loss: 0.322979] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3750 [D loss: 0.834545, acc.: 49.71%] [G loss: 0.323898] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3751 [D loss: 0.844283, acc.: 49.71%] [G loss: 0.319622] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3752 [D loss: 0.845576, acc.: 49.71%] [G loss: 0.316154] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3753 [D loss: 0.840024, acc.: 49.80%] [G loss: 0.317363] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3754 [D loss: 0.853749, acc.: 49.80%] [G loss: 0.313118] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3755 [D loss: 0.852257, acc.: 50.00%] [G loss: 0.318865] [Loss difference: 0.006, iterations with loss: 0]\n",
      "3756 [D loss: 0.844594, acc.: 49.80%] [G loss: 0.320411] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3757 [D loss: 0.855002, acc.: 49.71%] [G loss: 0.314779] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3758 [D loss: 0.860009, acc.: 49.80%] [G loss: 0.322358] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3759 [D loss: 0.835631, acc.: 49.90%] [G loss: 0.318606] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3760 [D loss: 0.841576, acc.: 49.80%] [G loss: 0.319478] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3761 [D loss: 0.859788, acc.: 49.71%] [G loss: 0.318907] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3762 [D loss: 0.860661, acc.: 49.71%] [G loss: 0.321843] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3763 [D loss: 0.844591, acc.: 49.90%] [G loss: 0.325356] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3764 [D loss: 0.848859, acc.: 49.90%] [G loss: 0.318147] [Loss difference: -0.007, iterations with loss: 2]\n",
      "3765 [D loss: 0.837855, acc.: 49.90%] [G loss: 0.317830] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3766 [D loss: 0.842611, acc.: 49.71%] [G loss: 0.316670] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3767 [D loss: 0.841028, acc.: 49.90%] [G loss: 0.310358] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3768 [D loss: 0.830196, acc.: 49.80%] [G loss: 0.314555] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3769 [D loss: 0.859295, acc.: 49.80%] [G loss: 0.311286] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3770 [D loss: 0.846178, acc.: 49.90%] [G loss: 0.312007] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3771 [D loss: 0.828859, acc.: 49.90%] [G loss: 0.316813] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3772 [D loss: 0.854586, acc.: 49.32%] [G loss: 0.322644] [Loss difference: 0.006, iterations with loss: 2]\n",
      "3773 [D loss: 0.834260, acc.: 49.71%] [G loss: 0.326625] [Loss difference: 0.004, iterations with loss: 3]\n",
      "3774 [D loss: 0.833441, acc.: 49.80%] [G loss: 0.312533] [Loss difference: -0.014, iterations with loss: 4]\n",
      "3775 [D loss: 0.837027, acc.: 49.90%] [G loss: 0.317309] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3776 [D loss: 0.837578, acc.: 49.80%] [G loss: 0.322738] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3777 [D loss: 0.836207, acc.: 49.90%] [G loss: 0.318628] [Loss difference: -0.004, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3778 [D loss: 0.822262, acc.: 50.00%] [G loss: 0.321672] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3779 [D loss: 0.840632, acc.: 49.90%] [G loss: 0.330341] [Loss difference: 0.009, iterations with loss: 1]\n",
      "3780 [D loss: 0.848450, acc.: 49.51%] [G loss: 0.321816] [Loss difference: -0.009, iterations with loss: 2]\n",
      "3781 [D loss: 0.832491, acc.: 49.51%] [G loss: 0.318084] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3782 [D loss: 0.839917, acc.: 50.00%] [G loss: 0.319685] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3783 [D loss: 0.835358, acc.: 49.90%] [G loss: 0.323850] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3784 [D loss: 0.839222, acc.: 49.90%] [G loss: 0.318366] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3785 [D loss: 0.838391, acc.: 50.00%] [G loss: 0.320816] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3786 [D loss: 0.842772, acc.: 50.00%] [G loss: 0.324164] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3787 [D loss: 0.837760, acc.: 49.61%] [G loss: 0.323090] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3788 [D loss: 0.845940, acc.: 49.71%] [G loss: 0.324206] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3789 [D loss: 0.839646, acc.: 49.90%] [G loss: 0.328677] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3790 [D loss: 0.839117, acc.: 49.90%] [G loss: 0.324607] [Loss difference: -0.004, iterations with loss: 2]\n",
      "3791 [D loss: 0.842358, acc.: 49.80%] [G loss: 0.320607] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3792 [D loss: 0.837991, acc.: 49.71%] [G loss: 0.318270] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3793 [D loss: 0.841914, acc.: 49.90%] [G loss: 0.317767] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3794 [D loss: 0.841424, acc.: 50.00%] [G loss: 0.311994] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3795 [D loss: 0.843240, acc.: 49.80%] [G loss: 0.322080] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3796 [D loss: 0.849075, acc.: 49.90%] [G loss: 0.327104] [Loss difference: 0.005, iterations with loss: 1]\n",
      "3797 [D loss: 0.836214, acc.: 49.90%] [G loss: 0.330822] [Loss difference: 0.004, iterations with loss: 2]\n",
      "3798 [D loss: 0.836548, acc.: 49.71%] [G loss: 0.319415] [Loss difference: -0.011, iterations with loss: 3]\n",
      "3799 [D loss: 0.842525, acc.: 49.61%] [G loss: 0.323326] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3800 [D loss: 0.851111, acc.: 49.71%] [G loss: 0.317398] [Loss difference: -0.006, iterations with loss: 1]\n",
      "3801 [D loss: 0.858588, acc.: 49.80%] [G loss: 0.317306] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3802 [D loss: 0.843600, acc.: 50.00%] [G loss: 0.324286] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3803 [D loss: 0.829769, acc.: 49.90%] [G loss: 0.328451] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3804 [D loss: 0.833016, acc.: 50.00%] [G loss: 0.323001] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3805 [D loss: 0.841670, acc.: 49.80%] [G loss: 0.319566] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3806 [D loss: 0.848182, acc.: 49.80%] [G loss: 0.318075] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3807 [D loss: 0.845304, acc.: 50.00%] [G loss: 0.331296] [Loss difference: 0.013, iterations with loss: 0]\n",
      "3808 [D loss: 0.833527, acc.: 49.90%] [G loss: 0.328091] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3809 [D loss: 0.816165, acc.: 50.00%] [G loss: 0.326874] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3810 [D loss: 0.826743, acc.: 49.90%] [G loss: 0.329265] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3811 [D loss: 0.829704, acc.: 49.71%] [G loss: 0.323956] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3812 [D loss: 0.831295, acc.: 49.80%] [G loss: 0.323165] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3813 [D loss: 0.851468, acc.: 49.80%] [G loss: 0.314319] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3814 [D loss: 0.840855, acc.: 49.80%] [G loss: 0.326463] [Loss difference: 0.012, iterations with loss: 0]\n",
      "3815 [D loss: 0.836111, acc.: 49.80%] [G loss: 0.328255] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3816 [D loss: 0.832729, acc.: 49.90%] [G loss: 0.327120] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3817 [D loss: 0.839238, acc.: 49.71%] [G loss: 0.322931] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3818 [D loss: 0.843947, acc.: 49.80%] [G loss: 0.323812] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3819 [D loss: 0.845217, acc.: 49.80%] [G loss: 0.327557] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3820 [D loss: 0.837879, acc.: 49.90%] [G loss: 0.328730] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3821 [D loss: 0.836996, acc.: 49.41%] [G loss: 0.316133] [Loss difference: -0.013, iterations with loss: 3]\n",
      "3822 [D loss: 0.839240, acc.: 49.80%] [G loss: 0.317484] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3823 [D loss: 0.828886, acc.: 49.90%] [G loss: 0.324113] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3824 [D loss: 0.834433, acc.: 50.00%] [G loss: 0.336857] [Loss difference: 0.013, iterations with loss: 2]\n",
      "3825 [D loss: 0.829219, acc.: 49.80%] [G loss: 0.329092] [Loss difference: -0.008, iterations with loss: 3]\n",
      "3826 [D loss: 0.824430, acc.: 49.90%] [G loss: 0.330340] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3827 [D loss: 0.817937, acc.: 49.71%] [G loss: 0.320642] [Loss difference: -0.010, iterations with loss: 1]\n",
      "3828 [D loss: 0.833546, acc.: 49.61%] [G loss: 0.324560] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3829 [D loss: 0.846685, acc.: 50.00%] [G loss: 0.324834] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3830 [D loss: 0.854155, acc.: 49.71%] [G loss: 0.324185] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3831 [D loss: 0.830613, acc.: 49.90%] [G loss: 0.322246] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3832 [D loss: 0.834447, acc.: 50.00%] [G loss: 0.326170] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3833 [D loss: 0.835992, acc.: 49.90%] [G loss: 0.329330] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3834 [D loss: 0.825218, acc.: 49.80%] [G loss: 0.328026] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3835 [D loss: 0.823467, acc.: 49.90%] [G loss: 0.331981] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3836 [D loss: 0.830121, acc.: 49.71%] [G loss: 0.326603] [Loss difference: -0.005, iterations with loss: 1]\n",
      "3837 [D loss: 0.837928, acc.: 49.71%] [G loss: 0.327410] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3838 [D loss: 0.839563, acc.: 49.51%] [G loss: 0.326170] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3839 [D loss: 0.827843, acc.: 49.90%] [G loss: 0.324723] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3840 [D loss: 0.835228, acc.: 49.90%] [G loss: 0.324732] [Loss difference: 0.000, iterations with loss: 0]\n",
      "3841 [D loss: 0.839837, acc.: 49.90%] [G loss: 0.333620] [Loss difference: 0.009, iterations with loss: 1]\n",
      "3842 [D loss: 0.825473, acc.: 49.71%] [G loss: 0.327362] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3843 [D loss: 0.832200, acc.: 49.71%] [G loss: 0.332367] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3844 [D loss: 0.821039, acc.: 49.90%] [G loss: 0.325898] [Loss difference: -0.006, iterations with loss: 1]\n",
      "3845 [D loss: 0.846774, acc.: 49.61%] [G loss: 0.329553] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3846 [D loss: 0.832332, acc.: 50.00%] [G loss: 0.330090] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3847 [D loss: 0.825116, acc.: 49.61%] [G loss: 0.329333] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3848 [D loss: 0.827533, acc.: 49.80%] [G loss: 0.327500] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3849 [D loss: 0.824503, acc.: 50.00%] [G loss: 0.325027] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3850 [D loss: 0.817550, acc.: 49.80%] [G loss: 0.329378] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3851 [D loss: 0.831741, acc.: 50.00%] [G loss: 0.326623] [Loss difference: -0.003, iterations with loss: 1]\n",
      "3852 [D loss: 0.837211, acc.: 49.90%] [G loss: 0.329553] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3853 [D loss: 0.844955, acc.: 49.90%] [G loss: 0.331924] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3854 [D loss: 0.848128, acc.: 49.90%] [G loss: 0.325620] [Loss difference: -0.006, iterations with loss: 2]\n",
      "3855 [D loss: 0.834562, acc.: 49.51%] [G loss: 0.330755] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3856 [D loss: 0.838297, acc.: 49.71%] [G loss: 0.334498] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3857 [D loss: 0.834155, acc.: 49.90%] [G loss: 0.340444] [Loss difference: 0.006, iterations with loss: 2]\n",
      "3858 [D loss: 0.821321, acc.: 49.80%] [G loss: 0.343777] [Loss difference: 0.003, iterations with loss: 3]\n",
      "3859 [D loss: 0.814380, acc.: 49.90%] [G loss: 0.335079] [Loss difference: -0.009, iterations with loss: 4]\n",
      "3860 [D loss: 0.816421, acc.: 49.80%] [G loss: 0.334324] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3861 [D loss: 0.826996, acc.: 50.00%] [G loss: 0.327609] [Loss difference: -0.007, iterations with loss: 0]\n",
      "3862 [D loss: 0.846542, acc.: 49.71%] [G loss: 0.330002] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3863 [D loss: 0.834532, acc.: 49.90%] [G loss: 0.330533] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3864 [D loss: 0.835272, acc.: 49.61%] [G loss: 0.331107] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3865 [D loss: 0.817370, acc.: 50.00%] [G loss: 0.338749] [Loss difference: 0.008, iterations with loss: 3]\n",
      "3866 [D loss: 0.834531, acc.: 49.90%] [G loss: 0.344394] [Loss difference: 0.006, iterations with loss: 4]\n",
      "3867 [D loss: 0.825709, acc.: 49.80%] [G loss: 0.332284] [Loss difference: -0.012, iterations with loss: 5]\n",
      "3868 [D loss: 0.821561, acc.: 49.80%] [G loss: 0.329361] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3869 [D loss: 0.831951, acc.: 49.51%] [G loss: 0.331589] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3870 [D loss: 0.854401, acc.: 49.61%] [G loss: 0.330714] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3871 [D loss: 0.834527, acc.: 49.61%] [G loss: 0.335662] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3872 [D loss: 0.826809, acc.: 50.00%] [G loss: 0.335739] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3873 [D loss: 0.822792, acc.: 49.90%] [G loss: 0.329431] [Loss difference: -0.006, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3874 [D loss: 0.817375, acc.: 49.90%] [G loss: 0.329940] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3875 [D loss: 0.816472, acc.: 50.00%] [G loss: 0.332498] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3876 [D loss: 0.816734, acc.: 49.90%] [G loss: 0.331591] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3877 [D loss: 0.823064, acc.: 49.61%] [G loss: 0.324905] [Loss difference: -0.007, iterations with loss: 0]\n",
      "3878 [D loss: 0.812643, acc.: 49.80%] [G loss: 0.331669] [Loss difference: 0.007, iterations with loss: 0]\n",
      "3879 [D loss: 0.849586, acc.: 49.80%] [G loss: 0.340672] [Loss difference: 0.009, iterations with loss: 1]\n",
      "3880 [D loss: 0.821092, acc.: 49.80%] [G loss: 0.343528] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3881 [D loss: 0.827604, acc.: 49.61%] [G loss: 0.340255] [Loss difference: -0.003, iterations with loss: 3]\n",
      "3882 [D loss: 0.831407, acc.: 49.80%] [G loss: 0.333993] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3883 [D loss: 0.818199, acc.: 49.90%] [G loss: 0.339213] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3884 [D loss: 0.830862, acc.: 49.61%] [G loss: 0.331658] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3885 [D loss: 0.841207, acc.: 49.80%] [G loss: 0.334204] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3886 [D loss: 0.828948, acc.: 49.61%] [G loss: 0.342016] [Loss difference: 0.008, iterations with loss: 1]\n",
      "3887 [D loss: 0.830539, acc.: 49.71%] [G loss: 0.348403] [Loss difference: 0.006, iterations with loss: 2]\n",
      "3888 [D loss: 0.806819, acc.: 49.61%] [G loss: 0.345945] [Loss difference: -0.002, iterations with loss: 3]\n",
      "3889 [D loss: 0.821687, acc.: 49.90%] [G loss: 0.348083] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3890 [D loss: 0.819463, acc.: 49.71%] [G loss: 0.344447] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3891 [D loss: 0.825048, acc.: 50.00%] [G loss: 0.341422] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3892 [D loss: 0.819955, acc.: 49.71%] [G loss: 0.343287] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3893 [D loss: 0.832256, acc.: 49.80%] [G loss: 0.336794] [Loss difference: -0.006, iterations with loss: 1]\n",
      "3894 [D loss: 0.806817, acc.: 49.80%] [G loss: 0.328128] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3895 [D loss: 0.819454, acc.: 49.80%] [G loss: 0.325089] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3896 [D loss: 0.834126, acc.: 49.71%] [G loss: 0.326527] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3897 [D loss: 0.839976, acc.: 49.80%] [G loss: 0.337087] [Loss difference: 0.011, iterations with loss: 1]\n",
      "3898 [D loss: 0.822620, acc.: 49.80%] [G loss: 0.335834] [Loss difference: -0.001, iterations with loss: 2]\n",
      "3899 [D loss: 0.819925, acc.: 49.51%] [G loss: 0.334699] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3900 [D loss: 0.818992, acc.: 49.90%] [G loss: 0.337630] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3901 [D loss: 0.802279, acc.: 49.90%] [G loss: 0.340073] [Loss difference: 0.002, iterations with loss: 1]\n",
      "3902 [D loss: 0.815268, acc.: 49.80%] [G loss: 0.337915] [Loss difference: -0.002, iterations with loss: 2]\n",
      "3903 [D loss: 0.811114, acc.: 49.80%] [G loss: 0.335263] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3904 [D loss: 0.809689, acc.: 50.10%] [G loss: 0.327515] [Loss difference: -0.008, iterations with loss: 0]\n",
      "3905 [D loss: 0.810476, acc.: 49.80%] [G loss: 0.335715] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3906 [D loss: 0.823752, acc.: 50.10%] [G loss: 0.338838] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3907 [D loss: 0.806642, acc.: 49.90%] [G loss: 0.341634] [Loss difference: 0.003, iterations with loss: 2]\n",
      "3908 [D loss: 0.805448, acc.: 50.00%] [G loss: 0.335715] [Loss difference: -0.006, iterations with loss: 3]\n",
      "3909 [D loss: 0.816948, acc.: 50.00%] [G loss: 0.339901] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3910 [D loss: 0.811491, acc.: 50.00%] [G loss: 0.339173] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3911 [D loss: 0.822137, acc.: 49.71%] [G loss: 0.351276] [Loss difference: 0.012, iterations with loss: 0]\n",
      "3912 [D loss: 0.813898, acc.: 49.80%] [G loss: 0.343936] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3913 [D loss: 0.804693, acc.: 49.51%] [G loss: 0.340524] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3914 [D loss: 0.812953, acc.: 49.80%] [G loss: 0.345023] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3915 [D loss: 0.833950, acc.: 49.61%] [G loss: 0.328918] [Loss difference: -0.016, iterations with loss: 1]\n",
      "3916 [D loss: 0.823836, acc.: 50.00%] [G loss: 0.338622] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3917 [D loss: 0.817979, acc.: 49.71%] [G loss: 0.339757] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3918 [D loss: 0.819986, acc.: 49.71%] [G loss: 0.348258] [Loss difference: 0.009, iterations with loss: 2]\n",
      "3919 [D loss: 0.805899, acc.: 49.80%] [G loss: 0.345124] [Loss difference: -0.003, iterations with loss: 3]\n",
      "3920 [D loss: 0.801654, acc.: 50.00%] [G loss: 0.340617] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3921 [D loss: 0.825198, acc.: 49.90%] [G loss: 0.341360] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3922 [D loss: 0.825530, acc.: 50.10%] [G loss: 0.342419] [Loss difference: 0.001, iterations with loss: 1]\n",
      "3923 [D loss: 0.822159, acc.: 49.90%] [G loss: 0.344060] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3924 [D loss: 0.815748, acc.: 49.80%] [G loss: 0.346024] [Loss difference: 0.002, iterations with loss: 3]\n",
      "3925 [D loss: 0.817774, acc.: 49.80%] [G loss: 0.338621] [Loss difference: -0.007, iterations with loss: 4]\n",
      "3926 [D loss: 0.819517, acc.: 49.90%] [G loss: 0.333480] [Loss difference: -0.005, iterations with loss: 0]\n",
      "3927 [D loss: 0.813069, acc.: 50.20%] [G loss: 0.342849] [Loss difference: 0.009, iterations with loss: 0]\n",
      "3928 [D loss: 0.803971, acc.: 50.00%] [G loss: 0.335223] [Loss difference: -0.008, iterations with loss: 1]\n",
      "3929 [D loss: 0.819299, acc.: 49.90%] [G loss: 0.346241] [Loss difference: 0.011, iterations with loss: 0]\n",
      "3930 [D loss: 0.817977, acc.: 49.80%] [G loss: 0.345071] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3931 [D loss: 0.795593, acc.: 49.90%] [G loss: 0.342115] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3932 [D loss: 0.828980, acc.: 49.80%] [G loss: 0.354219] [Loss difference: 0.012, iterations with loss: 0]\n",
      "3933 [D loss: 0.822496, acc.: 49.80%] [G loss: 0.347270] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3934 [D loss: 0.820718, acc.: 49.80%] [G loss: 0.347909] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3935 [D loss: 0.814956, acc.: 49.71%] [G loss: 0.347711] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3936 [D loss: 0.811831, acc.: 50.10%] [G loss: 0.346479] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3937 [D loss: 0.813363, acc.: 49.71%] [G loss: 0.350957] [Loss difference: 0.004, iterations with loss: 0]\n",
      "3938 [D loss: 0.798777, acc.: 49.90%] [G loss: 0.347192] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3939 [D loss: 0.801978, acc.: 49.80%] [G loss: 0.347839] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3940 [D loss: 0.808676, acc.: 49.80%] [G loss: 0.340929] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3941 [D loss: 0.803765, acc.: 49.90%] [G loss: 0.348473] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3942 [D loss: 0.803194, acc.: 50.00%] [G loss: 0.355047] [Loss difference: 0.007, iterations with loss: 1]\n",
      "3943 [D loss: 0.809723, acc.: 49.61%] [G loss: 0.349817] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3944 [D loss: 0.807415, acc.: 49.90%] [G loss: 0.340905] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3945 [D loss: 0.815436, acc.: 49.90%] [G loss: 0.342805] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3946 [D loss: 0.811995, acc.: 50.00%] [G loss: 0.346778] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3947 [D loss: 0.802089, acc.: 50.10%] [G loss: 0.341773] [Loss difference: -0.005, iterations with loss: 2]\n",
      "3948 [D loss: 0.814252, acc.: 50.20%] [G loss: 0.343753] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3949 [D loss: 0.808400, acc.: 50.39%] [G loss: 0.346854] [Loss difference: 0.003, iterations with loss: 1]\n",
      "3950 [D loss: 0.818579, acc.: 50.10%] [G loss: 0.361481] [Loss difference: 0.015, iterations with loss: 2]\n",
      "3951 [D loss: 0.805952, acc.: 50.10%] [G loss: 0.361195] [Loss difference: -0.000, iterations with loss: 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952 [D loss: 0.808725, acc.: 50.39%] [G loss: 0.363794] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3953 [D loss: 0.816400, acc.: 49.90%] [G loss: 0.363988] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3954 [D loss: 0.817908, acc.: 49.71%] [G loss: 0.361476] [Loss difference: -0.003, iterations with loss: 2]\n",
      "3955 [D loss: 0.828249, acc.: 50.39%] [G loss: 0.361111] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3956 [D loss: 0.828566, acc.: 50.00%] [G loss: 0.353785] [Loss difference: -0.007, iterations with loss: 0]\n",
      "3957 [D loss: 0.834988, acc.: 49.90%] [G loss: 0.358538] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3958 [D loss: 0.817372, acc.: 50.29%] [G loss: 0.356814] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3959 [D loss: 0.807270, acc.: 50.39%] [G loss: 0.358044] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3960 [D loss: 0.796578, acc.: 50.10%] [G loss: 0.351455] [Loss difference: -0.007, iterations with loss: 1]\n",
      "3961 [D loss: 0.817828, acc.: 50.20%] [G loss: 0.361061] [Loss difference: 0.010, iterations with loss: 0]\n",
      "3962 [D loss: 0.807557, acc.: 50.29%] [G loss: 0.350316] [Loss difference: -0.011, iterations with loss: 1]\n",
      "3963 [D loss: 0.811668, acc.: 50.20%] [G loss: 0.353101] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3964 [D loss: 0.810823, acc.: 49.90%] [G loss: 0.353018] [Loss difference: -0.000, iterations with loss: 1]\n",
      "3965 [D loss: 0.813124, acc.: 49.90%] [G loss: 0.352962] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3966 [D loss: 0.819078, acc.: 49.90%] [G loss: 0.363515] [Loss difference: 0.011, iterations with loss: 0]\n",
      "3967 [D loss: 0.809752, acc.: 49.80%] [G loss: 0.353806] [Loss difference: -0.010, iterations with loss: 1]\n",
      "3968 [D loss: 0.809700, acc.: 50.00%] [G loss: 0.349462] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3969 [D loss: 0.802506, acc.: 50.00%] [G loss: 0.349324] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3970 [D loss: 0.819006, acc.: 50.39%] [G loss: 0.349890] [Loss difference: 0.001, iterations with loss: 0]\n",
      "3971 [D loss: 0.792643, acc.: 50.00%] [G loss: 0.345495] [Loss difference: -0.004, iterations with loss: 1]\n",
      "3972 [D loss: 0.817818, acc.: 50.00%] [G loss: 0.343911] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3973 [D loss: 0.795928, acc.: 50.39%] [G loss: 0.347036] [Loss difference: 0.003, iterations with loss: 0]\n",
      "3974 [D loss: 0.798470, acc.: 50.00%] [G loss: 0.347175] [Loss difference: 0.000, iterations with loss: 1]\n",
      "3975 [D loss: 0.810213, acc.: 50.00%] [G loss: 0.348345] [Loss difference: 0.001, iterations with loss: 2]\n",
      "3976 [D loss: 0.816387, acc.: 50.00%] [G loss: 0.348433] [Loss difference: 0.000, iterations with loss: 3]\n",
      "3977 [D loss: 0.818013, acc.: 50.00%] [G loss: 0.359442] [Loss difference: 0.011, iterations with loss: 4]\n",
      "3978 [D loss: 0.809196, acc.: 50.10%] [G loss: 0.358954] [Loss difference: -0.000, iterations with loss: 5]\n",
      "3979 [D loss: 0.792453, acc.: 50.10%] [G loss: 0.358673] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3980 [D loss: 0.822908, acc.: 50.20%] [G loss: 0.357035] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3981 [D loss: 0.810798, acc.: 50.00%] [G loss: 0.356840] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3982 [D loss: 0.805387, acc.: 50.00%] [G loss: 0.347548] [Loss difference: -0.009, iterations with loss: 0]\n",
      "3983 [D loss: 0.816786, acc.: 50.00%] [G loss: 0.349575] [Loss difference: 0.002, iterations with loss: 0]\n",
      "3984 [D loss: 0.825733, acc.: 50.20%] [G loss: 0.353184] [Loss difference: 0.004, iterations with loss: 1]\n",
      "3985 [D loss: 0.880871, acc.: 50.29%] [G loss: 0.354916] [Loss difference: 0.002, iterations with loss: 2]\n",
      "3986 [D loss: 0.806316, acc.: 50.29%] [G loss: 0.353585] [Loss difference: -0.001, iterations with loss: 3]\n",
      "3987 [D loss: 0.801210, acc.: 49.90%] [G loss: 0.353169] [Loss difference: -0.000, iterations with loss: 0]\n",
      "3988 [D loss: 0.802712, acc.: 50.39%] [G loss: 0.358171] [Loss difference: 0.005, iterations with loss: 0]\n",
      "3989 [D loss: 0.799133, acc.: 50.10%] [G loss: 0.357421] [Loss difference: -0.001, iterations with loss: 1]\n",
      "3990 [D loss: 0.814013, acc.: 50.39%] [G loss: 0.356242] [Loss difference: -0.001, iterations with loss: 0]\n",
      "3991 [D loss: 0.810176, acc.: 49.90%] [G loss: 0.350731] [Loss difference: -0.006, iterations with loss: 0]\n",
      "3992 [D loss: 0.793942, acc.: 50.39%] [G loss: 0.347105] [Loss difference: -0.004, iterations with loss: 0]\n",
      "3993 [D loss: 0.806601, acc.: 50.00%] [G loss: 0.355399] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3994 [D loss: 0.798720, acc.: 50.10%] [G loss: 0.349072] [Loss difference: -0.006, iterations with loss: 1]\n",
      "3995 [D loss: 0.809087, acc.: 50.49%] [G loss: 0.356920] [Loss difference: 0.008, iterations with loss: 0]\n",
      "3996 [D loss: 0.816217, acc.: 50.29%] [G loss: 0.354718] [Loss difference: -0.002, iterations with loss: 1]\n",
      "3997 [D loss: 0.817625, acc.: 50.00%] [G loss: 0.352457] [Loss difference: -0.002, iterations with loss: 0]\n",
      "3998 [D loss: 0.790757, acc.: 50.29%] [G loss: 0.349728] [Loss difference: -0.003, iterations with loss: 0]\n",
      "3999 [D loss: 0.813479, acc.: 50.39%] [G loss: 0.363645] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4000 [D loss: 0.816748, acc.: 50.00%] [G loss: 0.367873] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4001 [D loss: 0.809470, acc.: 50.49%] [G loss: 0.359437] [Loss difference: -0.008, iterations with loss: 2]\n",
      "4002 [D loss: 0.817284, acc.: 50.39%] [G loss: 0.364705] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4003 [D loss: 0.806737, acc.: 50.20%] [G loss: 0.350472] [Loss difference: -0.014, iterations with loss: 1]\n",
      "4004 [D loss: 0.798005, acc.: 50.49%] [G loss: 0.359384] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4005 [D loss: 0.803098, acc.: 50.29%] [G loss: 0.354467] [Loss difference: -0.005, iterations with loss: 1]\n",
      "4006 [D loss: 0.801486, acc.: 50.29%] [G loss: 0.358831] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4007 [D loss: 0.815432, acc.: 50.10%] [G loss: 0.352181] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4008 [D loss: 0.803557, acc.: 50.00%] [G loss: 0.356854] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4009 [D loss: 0.802030, acc.: 50.39%] [G loss: 0.353447] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4010 [D loss: 0.797554, acc.: 50.39%] [G loss: 0.360049] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4011 [D loss: 0.813101, acc.: 49.90%] [G loss: 0.351944] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4012 [D loss: 0.808036, acc.: 50.59%] [G loss: 0.357850] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4013 [D loss: 0.798508, acc.: 50.68%] [G loss: 0.363765] [Loss difference: 0.006, iterations with loss: 1]\n",
      "4014 [D loss: 0.796807, acc.: 50.39%] [G loss: 0.356932] [Loss difference: -0.007, iterations with loss: 2]\n",
      "4015 [D loss: 0.797694, acc.: 50.20%] [G loss: 0.361514] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4016 [D loss: 0.805778, acc.: 50.20%] [G loss: 0.352457] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4017 [D loss: 0.815608, acc.: 50.59%] [G loss: 0.359123] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4018 [D loss: 0.809583, acc.: 50.88%] [G loss: 0.357748] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4019 [D loss: 0.797147, acc.: 50.68%] [G loss: 0.356080] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4020 [D loss: 0.827262, acc.: 50.20%] [G loss: 0.358528] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4021 [D loss: 0.791481, acc.: 50.49%] [G loss: 0.355883] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4022 [D loss: 0.793919, acc.: 50.10%] [G loss: 0.353490] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4023 [D loss: 0.800563, acc.: 50.29%] [G loss: 0.347635] [Loss difference: -0.006, iterations with loss: 0]\n",
      "4024 [D loss: 0.791983, acc.: 50.98%] [G loss: 0.355800] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4025 [D loss: 0.808439, acc.: 50.00%] [G loss: 0.351420] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4026 [D loss: 0.810881, acc.: 50.29%] [G loss: 0.360482] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4027 [D loss: 0.813021, acc.: 50.10%] [G loss: 0.358172] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4028 [D loss: 0.804569, acc.: 50.29%] [G loss: 0.360568] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4029 [D loss: 0.816988, acc.: 50.00%] [G loss: 0.365233] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4030 [D loss: 0.793721, acc.: 50.49%] [G loss: 0.361160] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4031 [D loss: 0.816855, acc.: 50.10%] [G loss: 0.369087] [Loss difference: 0.008, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032 [D loss: 0.806298, acc.: 50.49%] [G loss: 0.366869] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4033 [D loss: 0.785472, acc.: 50.10%] [G loss: 0.367817] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4034 [D loss: 0.791458, acc.: 50.20%] [G loss: 0.362079] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4035 [D loss: 0.799922, acc.: 50.10%] [G loss: 0.364242] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4036 [D loss: 0.784679, acc.: 50.39%] [G loss: 0.361897] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4037 [D loss: 0.784608, acc.: 50.20%] [G loss: 0.370528] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4038 [D loss: 0.794077, acc.: 50.20%] [G loss: 0.353280] [Loss difference: -0.017, iterations with loss: 1]\n",
      "4039 [D loss: 0.786578, acc.: 50.20%] [G loss: 0.360714] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4040 [D loss: 0.796909, acc.: 50.00%] [G loss: 0.351707] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4041 [D loss: 0.795696, acc.: 50.20%] [G loss: 0.348867] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4042 [D loss: 0.801190, acc.: 50.20%] [G loss: 0.356396] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4043 [D loss: 0.787322, acc.: 50.49%] [G loss: 0.349839] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4044 [D loss: 0.792827, acc.: 50.39%] [G loss: 0.357817] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4045 [D loss: 0.780566, acc.: 50.49%] [G loss: 0.356566] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4046 [D loss: 0.784816, acc.: 50.29%] [G loss: 0.356072] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4047 [D loss: 0.784885, acc.: 50.39%] [G loss: 0.364763] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4048 [D loss: 0.783465, acc.: 50.59%] [G loss: 0.359191] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4049 [D loss: 0.802096, acc.: 50.10%] [G loss: 0.362500] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4050 [D loss: 0.788773, acc.: 50.39%] [G loss: 0.356205] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4051 [D loss: 0.789970, acc.: 50.00%] [G loss: 0.365380] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4052 [D loss: 0.781866, acc.: 50.59%] [G loss: 0.359434] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4053 [D loss: 0.784281, acc.: 50.10%] [G loss: 0.368013] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4054 [D loss: 0.782738, acc.: 50.39%] [G loss: 0.367047] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4055 [D loss: 0.771062, acc.: 50.88%] [G loss: 0.361778] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4056 [D loss: 0.809661, acc.: 49.71%] [G loss: 0.349208] [Loss difference: -0.013, iterations with loss: 0]\n",
      "4057 [D loss: 0.813271, acc.: 49.80%] [G loss: 0.356954] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4058 [D loss: 0.786731, acc.: 50.00%] [G loss: 0.356234] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4059 [D loss: 0.796737, acc.: 50.00%] [G loss: 0.363578] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4060 [D loss: 0.775379, acc.: 50.59%] [G loss: 0.362563] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4061 [D loss: 0.795607, acc.: 50.29%] [G loss: 0.367116] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4062 [D loss: 0.779128, acc.: 50.49%] [G loss: 0.363383] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4063 [D loss: 0.789362, acc.: 50.20%] [G loss: 0.365319] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4064 [D loss: 0.785662, acc.: 50.68%] [G loss: 0.360047] [Loss difference: -0.005, iterations with loss: 1]\n",
      "4065 [D loss: 0.784342, acc.: 50.59%] [G loss: 0.363060] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4066 [D loss: 0.785617, acc.: 50.59%] [G loss: 0.362193] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4067 [D loss: 0.779980, acc.: 50.39%] [G loss: 0.362900] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4068 [D loss: 0.802559, acc.: 50.00%] [G loss: 0.371220] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4069 [D loss: 0.786203, acc.: 50.29%] [G loss: 0.359581] [Loss difference: -0.012, iterations with loss: 2]\n",
      "4070 [D loss: 0.775623, acc.: 50.20%] [G loss: 0.361580] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4071 [D loss: 0.786302, acc.: 50.29%] [G loss: 0.364131] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4072 [D loss: 0.784906, acc.: 50.10%] [G loss: 0.360340] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4073 [D loss: 0.778237, acc.: 49.61%] [G loss: 0.363980] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4074 [D loss: 0.778830, acc.: 50.39%] [G loss: 0.354353] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4075 [D loss: 0.778315, acc.: 50.88%] [G loss: 0.358213] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4076 [D loss: 0.774542, acc.: 50.49%] [G loss: 0.366175] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4077 [D loss: 0.785595, acc.: 50.39%] [G loss: 0.359839] [Loss difference: -0.006, iterations with loss: 2]\n",
      "4078 [D loss: 0.787197, acc.: 50.00%] [G loss: 0.355666] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4079 [D loss: 0.788497, acc.: 50.00%] [G loss: 0.364291] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4080 [D loss: 0.785701, acc.: 50.39%] [G loss: 0.362766] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4081 [D loss: 0.778753, acc.: 50.20%] [G loss: 0.360503] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4082 [D loss: 0.778287, acc.: 50.78%] [G loss: 0.365059] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4083 [D loss: 0.783762, acc.: 50.10%] [G loss: 0.370079] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4084 [D loss: 0.770388, acc.: 50.10%] [G loss: 0.369987] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4085 [D loss: 0.765233, acc.: 50.68%] [G loss: 0.366321] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4086 [D loss: 0.784683, acc.: 50.20%] [G loss: 0.369180] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4087 [D loss: 0.793072, acc.: 50.49%] [G loss: 0.370038] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4088 [D loss: 0.775744, acc.: 50.39%] [G loss: 0.370577] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4089 [D loss: 0.787230, acc.: 50.39%] [G loss: 0.362158] [Loss difference: -0.008, iterations with loss: 3]\n",
      "4090 [D loss: 0.783644, acc.: 50.59%] [G loss: 0.363024] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4091 [D loss: 0.786682, acc.: 50.10%] [G loss: 0.364438] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4092 [D loss: 0.765682, acc.: 50.39%] [G loss: 0.370567] [Loss difference: 0.006, iterations with loss: 2]\n",
      "4093 [D loss: 0.770984, acc.: 50.68%] [G loss: 0.372923] [Loss difference: 0.002, iterations with loss: 3]\n",
      "4094 [D loss: 0.772649, acc.: 50.39%] [G loss: 0.371368] [Loss difference: -0.002, iterations with loss: 4]\n",
      "4095 [D loss: 0.791551, acc.: 50.10%] [G loss: 0.367632] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4096 [D loss: 0.778328, acc.: 50.10%] [G loss: 0.368644] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4097 [D loss: 0.769076, acc.: 50.20%] [G loss: 0.369289] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4098 [D loss: 0.796123, acc.: 49.71%] [G loss: 0.370282] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4099 [D loss: 0.776043, acc.: 50.49%] [G loss: 0.373838] [Loss difference: 0.004, iterations with loss: 3]\n",
      "4100 [D loss: 0.793417, acc.: 49.90%] [G loss: 0.367340] [Loss difference: -0.006, iterations with loss: 4]\n",
      "4101 [D loss: 0.779015, acc.: 50.39%] [G loss: 0.370453] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4102 [D loss: 0.778086, acc.: 50.10%] [G loss: 0.363008] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4103 [D loss: 0.788337, acc.: 50.10%] [G loss: 0.367139] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4104 [D loss: 0.768701, acc.: 50.29%] [G loss: 0.366673] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4105 [D loss: 0.776049, acc.: 50.49%] [G loss: 0.367689] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4106 [D loss: 0.771723, acc.: 50.59%] [G loss: 0.364385] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4107 [D loss: 0.774093, acc.: 50.68%] [G loss: 0.367935] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4108 [D loss: 0.778210, acc.: 50.20%] [G loss: 0.368720] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4109 [D loss: 0.784989, acc.: 50.49%] [G loss: 0.362187] [Loss difference: -0.007, iterations with loss: 2]\n",
      "4110 [D loss: 0.778795, acc.: 50.39%] [G loss: 0.361919] [Loss difference: -0.000, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4111 [D loss: 0.777568, acc.: 50.59%] [G loss: 0.369539] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4112 [D loss: 0.781762, acc.: 50.68%] [G loss: 0.367002] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4113 [D loss: 0.768696, acc.: 50.39%] [G loss: 0.371984] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4114 [D loss: 0.788118, acc.: 50.00%] [G loss: 0.366168] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4115 [D loss: 0.786963, acc.: 50.78%] [G loss: 0.370877] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4116 [D loss: 0.773686, acc.: 50.49%] [G loss: 0.379035] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4117 [D loss: 0.775234, acc.: 50.00%] [G loss: 0.377363] [Loss difference: -0.002, iterations with loss: 2]\n",
      "4118 [D loss: 0.779849, acc.: 50.10%] [G loss: 0.375300] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4119 [D loss: 0.775865, acc.: 50.20%] [G loss: 0.367357] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4120 [D loss: 0.770121, acc.: 50.29%] [G loss: 0.374160] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4121 [D loss: 0.794190, acc.: 50.10%] [G loss: 0.365778] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4122 [D loss: 0.783733, acc.: 50.29%] [G loss: 0.376443] [Loss difference: 0.011, iterations with loss: 0]\n",
      "4123 [D loss: 0.789734, acc.: 50.20%] [G loss: 0.369918] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4124 [D loss: 0.781503, acc.: 50.10%] [G loss: 0.367259] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4125 [D loss: 0.775480, acc.: 50.49%] [G loss: 0.366438] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4126 [D loss: 0.763708, acc.: 50.00%] [G loss: 0.364774] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4127 [D loss: 0.784893, acc.: 50.10%] [G loss: 0.366649] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4128 [D loss: 0.779404, acc.: 50.20%] [G loss: 0.374357] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4129 [D loss: 0.781025, acc.: 50.59%] [G loss: 0.369434] [Loss difference: -0.005, iterations with loss: 2]\n",
      "4130 [D loss: 0.773102, acc.: 50.49%] [G loss: 0.371167] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4131 [D loss: 0.784257, acc.: 50.10%] [G loss: 0.368186] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4132 [D loss: 0.779279, acc.: 50.59%] [G loss: 0.374575] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4133 [D loss: 0.786318, acc.: 50.88%] [G loss: 0.376675] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4134 [D loss: 0.796139, acc.: 49.71%] [G loss: 0.376410] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4135 [D loss: 0.769707, acc.: 50.29%] [G loss: 0.374933] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4136 [D loss: 0.777950, acc.: 50.88%] [G loss: 0.379516] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4137 [D loss: 0.777784, acc.: 50.49%] [G loss: 0.377586] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4138 [D loss: 0.773817, acc.: 50.39%] [G loss: 0.372477] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4139 [D loss: 0.775843, acc.: 50.29%] [G loss: 0.372220] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4140 [D loss: 0.763324, acc.: 49.90%] [G loss: 0.371553] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4141 [D loss: 0.763649, acc.: 50.39%] [G loss: 0.369201] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4142 [D loss: 0.762296, acc.: 50.29%] [G loss: 0.378555] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4143 [D loss: 0.775332, acc.: 50.10%] [G loss: 0.379121] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4144 [D loss: 0.779743, acc.: 50.68%] [G loss: 0.372923] [Loss difference: -0.006, iterations with loss: 2]\n",
      "4145 [D loss: 0.766336, acc.: 50.49%] [G loss: 0.371817] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4146 [D loss: 0.764134, acc.: 50.78%] [G loss: 0.378762] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4147 [D loss: 0.772453, acc.: 49.90%] [G loss: 0.376034] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4148 [D loss: 0.778269, acc.: 50.39%] [G loss: 0.377860] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4149 [D loss: 0.779248, acc.: 50.39%] [G loss: 0.376412] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4150 [D loss: 0.769997, acc.: 50.10%] [G loss: 0.375385] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4151 [D loss: 0.763715, acc.: 50.49%] [G loss: 0.377274] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4152 [D loss: 0.769009, acc.: 50.29%] [G loss: 0.369946] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4153 [D loss: 0.763113, acc.: 49.90%] [G loss: 0.377031] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4154 [D loss: 0.756117, acc.: 50.29%] [G loss: 0.368043] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4155 [D loss: 0.775124, acc.: 49.80%] [G loss: 0.378867] [Loss difference: 0.011, iterations with loss: 0]\n",
      "4156 [D loss: 0.772211, acc.: 50.29%] [G loss: 0.369334] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4157 [D loss: 0.761334, acc.: 50.00%] [G loss: 0.366340] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4158 [D loss: 0.775588, acc.: 50.20%] [G loss: 0.366874] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4159 [D loss: 0.782567, acc.: 50.49%] [G loss: 0.367911] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4160 [D loss: 0.771980, acc.: 50.49%] [G loss: 0.370089] [Loss difference: 0.002, iterations with loss: 2]\n",
      "4161 [D loss: 0.775553, acc.: 49.90%] [G loss: 0.380226] [Loss difference: 0.010, iterations with loss: 3]\n",
      "4162 [D loss: 0.774266, acc.: 50.49%] [G loss: 0.385316] [Loss difference: 0.005, iterations with loss: 4]\n",
      "4163 [D loss: 0.767719, acc.: 50.29%] [G loss: 0.372609] [Loss difference: -0.013, iterations with loss: 5]\n",
      "4164 [D loss: 0.787555, acc.: 50.20%] [G loss: 0.373519] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4165 [D loss: 0.793871, acc.: 50.10%] [G loss: 0.375614] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4166 [D loss: 0.768714, acc.: 50.20%] [G loss: 0.381481] [Loss difference: 0.006, iterations with loss: 2]\n",
      "4167 [D loss: 0.774269, acc.: 50.39%] [G loss: 0.376384] [Loss difference: -0.005, iterations with loss: 3]\n",
      "4168 [D loss: 0.772622, acc.: 50.20%] [G loss: 0.388557] [Loss difference: 0.012, iterations with loss: 0]\n",
      "4169 [D loss: 0.771253, acc.: 50.20%] [G loss: 0.373291] [Loss difference: -0.015, iterations with loss: 1]\n",
      "4170 [D loss: 0.780568, acc.: 49.90%] [G loss: 0.377934] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4171 [D loss: 0.772054, acc.: 50.10%] [G loss: 0.371596] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4172 [D loss: 0.761812, acc.: 50.29%] [G loss: 0.378509] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4173 [D loss: 0.766388, acc.: 49.90%] [G loss: 0.383542] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4174 [D loss: 0.759899, acc.: 50.10%] [G loss: 0.376883] [Loss difference: -0.007, iterations with loss: 2]\n",
      "4175 [D loss: 0.764071, acc.: 50.10%] [G loss: 0.372898] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4176 [D loss: 0.748267, acc.: 50.39%] [G loss: 0.374422] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4177 [D loss: 0.767471, acc.: 50.00%] [G loss: 0.377974] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4178 [D loss: 0.763331, acc.: 50.20%] [G loss: 0.378436] [Loss difference: 0.000, iterations with loss: 2]\n",
      "4179 [D loss: 0.765602, acc.: 50.29%] [G loss: 0.380470] [Loss difference: 0.002, iterations with loss: 3]\n",
      "4180 [D loss: 0.769798, acc.: 50.20%] [G loss: 0.379810] [Loss difference: -0.001, iterations with loss: 4]\n",
      "4181 [D loss: 0.750614, acc.: 50.49%] [G loss: 0.386922] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4182 [D loss: 0.768845, acc.: 50.29%] [G loss: 0.386836] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4183 [D loss: 0.762693, acc.: 50.78%] [G loss: 0.381306] [Loss difference: -0.006, iterations with loss: 0]\n",
      "4184 [D loss: 0.765637, acc.: 50.39%] [G loss: 0.381272] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4185 [D loss: 0.766134, acc.: 50.00%] [G loss: 0.375996] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4186 [D loss: 0.768472, acc.: 50.49%] [G loss: 0.381029] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4187 [D loss: 0.772891, acc.: 50.20%] [G loss: 0.378170] [Loss difference: -0.003, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4188 [D loss: 0.785480, acc.: 49.90%] [G loss: 0.385524] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4189 [D loss: 0.758702, acc.: 51.27%] [G loss: 0.398254] [Loss difference: 0.013, iterations with loss: 1]\n",
      "4190 [D loss: 0.768688, acc.: 50.20%] [G loss: 0.390593] [Loss difference: -0.008, iterations with loss: 2]\n",
      "4191 [D loss: 0.753719, acc.: 50.29%] [G loss: 0.387979] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4192 [D loss: 0.762850, acc.: 50.20%] [G loss: 0.385484] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4193 [D loss: 0.762224, acc.: 50.20%] [G loss: 0.384926] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4194 [D loss: 0.763052, acc.: 50.29%] [G loss: 0.381162] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4195 [D loss: 0.756346, acc.: 50.49%] [G loss: 0.381967] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4196 [D loss: 0.761368, acc.: 50.49%] [G loss: 0.376167] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4197 [D loss: 0.769850, acc.: 50.00%] [G loss: 0.379173] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4198 [D loss: 0.768898, acc.: 49.71%] [G loss: 0.381970] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4199 [D loss: 0.769074, acc.: 50.10%] [G loss: 0.391276] [Loss difference: 0.009, iterations with loss: 2]\n",
      "4200 [D loss: 0.757777, acc.: 49.90%] [G loss: 0.388390] [Loss difference: -0.003, iterations with loss: 3]\n",
      "4201 [D loss: 0.752954, acc.: 50.10%] [G loss: 0.398312] [Loss difference: 0.010, iterations with loss: 0]\n",
      "4202 [D loss: 0.778742, acc.: 49.90%] [G loss: 0.384094] [Loss difference: -0.014, iterations with loss: 1]\n",
      "4203 [D loss: 0.756891, acc.: 50.68%] [G loss: 0.383903] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4204 [D loss: 0.777158, acc.: 49.61%] [G loss: 0.391685] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4205 [D loss: 0.775714, acc.: 49.90%] [G loss: 0.389897] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4206 [D loss: 0.758539, acc.: 49.90%] [G loss: 0.379030] [Loss difference: -0.011, iterations with loss: 0]\n",
      "4207 [D loss: 0.772894, acc.: 50.39%] [G loss: 0.392657] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4208 [D loss: 0.767531, acc.: 50.29%] [G loss: 0.384664] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4209 [D loss: 0.751961, acc.: 50.00%] [G loss: 0.391409] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4210 [D loss: 0.755743, acc.: 50.29%] [G loss: 0.376145] [Loss difference: -0.015, iterations with loss: 1]\n",
      "4211 [D loss: 0.763058, acc.: 49.80%] [G loss: 0.373554] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4212 [D loss: 0.767067, acc.: 50.49%] [G loss: 0.386723] [Loss difference: 0.013, iterations with loss: 0]\n",
      "4213 [D loss: 0.746530, acc.: 50.20%] [G loss: 0.377471] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4214 [D loss: 0.773741, acc.: 50.00%] [G loss: 0.379942] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4215 [D loss: 0.758893, acc.: 50.39%] [G loss: 0.389881] [Loss difference: 0.010, iterations with loss: 1]\n",
      "4216 [D loss: 0.755576, acc.: 50.00%] [G loss: 0.392976] [Loss difference: 0.003, iterations with loss: 2]\n",
      "4217 [D loss: 0.746887, acc.: 50.20%] [G loss: 0.376899] [Loss difference: -0.016, iterations with loss: 3]\n",
      "4218 [D loss: 0.752013, acc.: 50.29%] [G loss: 0.388802] [Loss difference: 0.012, iterations with loss: 0]\n",
      "4219 [D loss: 0.757282, acc.: 49.80%] [G loss: 0.381753] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4220 [D loss: 0.765764, acc.: 50.00%] [G loss: 0.388548] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4221 [D loss: 0.762430, acc.: 50.98%] [G loss: 0.388597] [Loss difference: 0.000, iterations with loss: 1]\n",
      "4222 [D loss: 0.751707, acc.: 50.29%] [G loss: 0.387801] [Loss difference: -0.001, iterations with loss: 2]\n",
      "4223 [D loss: 0.764527, acc.: 50.20%] [G loss: 0.394323] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4224 [D loss: 0.759629, acc.: 50.20%] [G loss: 0.391259] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4225 [D loss: 0.763906, acc.: 50.29%] [G loss: 0.391770] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4226 [D loss: 0.767521, acc.: 49.90%] [G loss: 0.390301] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4227 [D loss: 0.753519, acc.: 50.10%] [G loss: 0.388585] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4228 [D loss: 0.761200, acc.: 50.00%] [G loss: 0.385730] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4229 [D loss: 0.750789, acc.: 50.68%] [G loss: 0.384259] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4230 [D loss: 0.772612, acc.: 50.00%] [G loss: 0.383551] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4231 [D loss: 0.748870, acc.: 50.00%] [G loss: 0.391857] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4232 [D loss: 0.757777, acc.: 50.10%] [G loss: 0.377824] [Loss difference: -0.014, iterations with loss: 1]\n",
      "4233 [D loss: 0.760995, acc.: 50.00%] [G loss: 0.384213] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4234 [D loss: 0.757443, acc.: 50.29%] [G loss: 0.389635] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4235 [D loss: 0.753908, acc.: 50.39%] [G loss: 0.389923] [Loss difference: 0.000, iterations with loss: 2]\n",
      "4236 [D loss: 0.764405, acc.: 49.90%] [G loss: 0.379202] [Loss difference: -0.011, iterations with loss: 3]\n",
      "4237 [D loss: 0.755974, acc.: 50.29%] [G loss: 0.396813] [Loss difference: 0.018, iterations with loss: 0]\n",
      "4238 [D loss: 0.764999, acc.: 49.61%] [G loss: 0.387578] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4239 [D loss: 0.759362, acc.: 50.10%] [G loss: 0.382480] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4240 [D loss: 0.755827, acc.: 50.29%] [G loss: 0.386868] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4241 [D loss: 0.753616, acc.: 50.29%] [G loss: 0.394746] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4242 [D loss: 0.749420, acc.: 50.29%] [G loss: 0.384574] [Loss difference: -0.010, iterations with loss: 2]\n",
      "4243 [D loss: 0.749089, acc.: 50.10%] [G loss: 0.383805] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4244 [D loss: 0.743129, acc.: 50.98%] [G loss: 0.384721] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4245 [D loss: 0.761487, acc.: 50.59%] [G loss: 0.384326] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4246 [D loss: 0.749003, acc.: 50.59%] [G loss: 0.390569] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4247 [D loss: 0.758304, acc.: 50.39%] [G loss: 0.388853] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4248 [D loss: 0.750238, acc.: 50.10%] [G loss: 0.394668] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4249 [D loss: 0.740556, acc.: 50.29%] [G loss: 0.401467] [Loss difference: 0.007, iterations with loss: 1]\n",
      "4250 [D loss: 0.748622, acc.: 51.07%] [G loss: 0.392717] [Loss difference: -0.009, iterations with loss: 2]\n",
      "4251 [D loss: 0.753649, acc.: 50.59%] [G loss: 0.398911] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4252 [D loss: 0.767221, acc.: 50.59%] [G loss: 0.395506] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4253 [D loss: 0.765559, acc.: 50.49%] [G loss: 0.393169] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4254 [D loss: 0.757096, acc.: 50.29%] [G loss: 0.391790] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4255 [D loss: 0.757406, acc.: 50.00%] [G loss: 0.402496] [Loss difference: 0.011, iterations with loss: 0]\n",
      "4256 [D loss: 0.757788, acc.: 50.39%] [G loss: 0.401032] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4257 [D loss: 0.772801, acc.: 50.29%] [G loss: 0.401238] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4258 [D loss: 0.758355, acc.: 50.49%] [G loss: 0.397210] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4259 [D loss: 0.766817, acc.: 50.10%] [G loss: 0.397577] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4260 [D loss: 0.755100, acc.: 49.80%] [G loss: 0.390972] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4261 [D loss: 0.742345, acc.: 50.59%] [G loss: 0.395917] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4262 [D loss: 0.753400, acc.: 50.59%] [G loss: 0.395561] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4263 [D loss: 0.749269, acc.: 51.07%] [G loss: 0.397124] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4264 [D loss: 0.754441, acc.: 50.29%] [G loss: 0.401395] [Loss difference: 0.004, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265 [D loss: 0.739575, acc.: 50.59%] [G loss: 0.394624] [Loss difference: -0.007, iterations with loss: 2]\n",
      "4266 [D loss: 0.757360, acc.: 50.29%] [G loss: 0.390896] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4267 [D loss: 0.749830, acc.: 50.39%] [G loss: 0.394562] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4268 [D loss: 0.756644, acc.: 50.49%] [G loss: 0.388360] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4269 [D loss: 0.755330, acc.: 50.20%] [G loss: 0.402027] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4270 [D loss: 0.753507, acc.: 49.90%] [G loss: 0.398590] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4271 [D loss: 0.747289, acc.: 50.68%] [G loss: 0.396688] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4272 [D loss: 0.763768, acc.: 50.10%] [G loss: 0.384774] [Loss difference: -0.012, iterations with loss: 0]\n",
      "4273 [D loss: 0.773142, acc.: 50.49%] [G loss: 0.388486] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4274 [D loss: 0.768811, acc.: 50.10%] [G loss: 0.388299] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4275 [D loss: 0.740584, acc.: 50.20%] [G loss: 0.402590] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4276 [D loss: 0.741834, acc.: 50.49%] [G loss: 0.396274] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4277 [D loss: 0.749206, acc.: 50.68%] [G loss: 0.402876] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4278 [D loss: 0.733693, acc.: 50.88%] [G loss: 0.397456] [Loss difference: -0.005, iterations with loss: 1]\n",
      "4279 [D loss: 0.746909, acc.: 50.68%] [G loss: 0.391189] [Loss difference: -0.006, iterations with loss: 0]\n",
      "4280 [D loss: 0.750438, acc.: 50.88%] [G loss: 0.395463] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4281 [D loss: 0.763915, acc.: 50.20%] [G loss: 0.404073] [Loss difference: 0.009, iterations with loss: 1]\n",
      "4282 [D loss: 0.744916, acc.: 50.49%] [G loss: 0.408941] [Loss difference: 0.005, iterations with loss: 2]\n",
      "4283 [D loss: 0.739458, acc.: 50.29%] [G loss: 0.411067] [Loss difference: 0.002, iterations with loss: 3]\n",
      "4284 [D loss: 0.756685, acc.: 50.29%] [G loss: 0.397639] [Loss difference: -0.013, iterations with loss: 4]\n",
      "4285 [D loss: 0.743330, acc.: 50.49%] [G loss: 0.399668] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4286 [D loss: 0.757398, acc.: 50.20%] [G loss: 0.401233] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4287 [D loss: 0.763260, acc.: 50.00%] [G loss: 0.395488] [Loss difference: -0.006, iterations with loss: 2]\n",
      "4288 [D loss: 0.753005, acc.: 50.29%] [G loss: 0.400971] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4289 [D loss: 0.769505, acc.: 49.80%] [G loss: 0.393434] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4290 [D loss: 0.759455, acc.: 51.07%] [G loss: 0.397572] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4291 [D loss: 0.763504, acc.: 50.10%] [G loss: 0.403158] [Loss difference: 0.006, iterations with loss: 1]\n",
      "4292 [D loss: 0.746886, acc.: 50.88%] [G loss: 0.405141] [Loss difference: 0.002, iterations with loss: 2]\n",
      "4293 [D loss: 0.746721, acc.: 50.49%] [G loss: 0.395589] [Loss difference: -0.010, iterations with loss: 3]\n",
      "4294 [D loss: 0.745135, acc.: 50.49%] [G loss: 0.395795] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4295 [D loss: 0.761309, acc.: 50.49%] [G loss: 0.399950] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4296 [D loss: 0.758238, acc.: 50.78%] [G loss: 0.400907] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4297 [D loss: 0.733558, acc.: 50.78%] [G loss: 0.395948] [Loss difference: -0.005, iterations with loss: 3]\n",
      "4298 [D loss: 0.743285, acc.: 50.29%] [G loss: 0.386355] [Loss difference: -0.010, iterations with loss: 0]\n",
      "4299 [D loss: 0.753025, acc.: 50.29%] [G loss: 0.405165] [Loss difference: 0.019, iterations with loss: 0]\n",
      "4300 [D loss: 0.762351, acc.: 50.39%] [G loss: 0.397054] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4301 [D loss: 0.754761, acc.: 50.20%] [G loss: 0.391988] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4302 [D loss: 0.743921, acc.: 50.49%] [G loss: 0.395645] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4303 [D loss: 0.744400, acc.: 50.39%] [G loss: 0.397817] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4304 [D loss: 0.751645, acc.: 50.88%] [G loss: 0.394427] [Loss difference: -0.003, iterations with loss: 2]\n",
      "4305 [D loss: 0.736043, acc.: 50.88%] [G loss: 0.405365] [Loss difference: 0.011, iterations with loss: 0]\n",
      "4306 [D loss: 0.748288, acc.: 50.68%] [G loss: 0.398302] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4307 [D loss: 0.742655, acc.: 50.59%] [G loss: 0.408554] [Loss difference: 0.010, iterations with loss: 0]\n",
      "4308 [D loss: 0.758973, acc.: 50.49%] [G loss: 0.402609] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4309 [D loss: 0.752961, acc.: 50.20%] [G loss: 0.398536] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4310 [D loss: 0.740047, acc.: 50.39%] [G loss: 0.412906] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4311 [D loss: 0.739154, acc.: 50.88%] [G loss: 0.403798] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4312 [D loss: 0.758297, acc.: 50.20%] [G loss: 0.400302] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4313 [D loss: 0.738008, acc.: 50.59%] [G loss: 0.413041] [Loss difference: 0.013, iterations with loss: 0]\n",
      "4314 [D loss: 0.758250, acc.: 50.49%] [G loss: 0.411052] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4315 [D loss: 0.743539, acc.: 50.59%] [G loss: 0.397208] [Loss difference: -0.014, iterations with loss: 0]\n",
      "4316 [D loss: 0.738531, acc.: 50.68%] [G loss: 0.398815] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4317 [D loss: 0.746423, acc.: 50.29%] [G loss: 0.403820] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4318 [D loss: 0.745566, acc.: 50.78%] [G loss: 0.403503] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4319 [D loss: 0.747320, acc.: 50.29%] [G loss: 0.408686] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4320 [D loss: 0.749080, acc.: 50.39%] [G loss: 0.400372] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4321 [D loss: 0.737962, acc.: 50.59%] [G loss: 0.403221] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4322 [D loss: 0.749646, acc.: 50.20%] [G loss: 0.406692] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4323 [D loss: 0.741194, acc.: 50.49%] [G loss: 0.407399] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4324 [D loss: 0.738901, acc.: 50.59%] [G loss: 0.410746] [Loss difference: 0.003, iterations with loss: 3]\n",
      "4325 [D loss: 0.729037, acc.: 50.59%] [G loss: 0.408057] [Loss difference: -0.003, iterations with loss: 4]\n",
      "4326 [D loss: 0.735807, acc.: 51.07%] [G loss: 0.411878] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4327 [D loss: 0.746733, acc.: 50.59%] [G loss: 0.395136] [Loss difference: -0.017, iterations with loss: 1]\n",
      "4328 [D loss: 0.751841, acc.: 50.20%] [G loss: 0.400058] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4329 [D loss: 0.738811, acc.: 50.88%] [G loss: 0.401118] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4330 [D loss: 0.744889, acc.: 50.29%] [G loss: 0.400717] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4331 [D loss: 0.747105, acc.: 50.68%] [G loss: 0.414885] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4332 [D loss: 0.745072, acc.: 50.78%] [G loss: 0.412891] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4333 [D loss: 0.739857, acc.: 50.10%] [G loss: 0.399387] [Loss difference: -0.014, iterations with loss: 0]\n",
      "4334 [D loss: 0.757907, acc.: 50.39%] [G loss: 0.396410] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4335 [D loss: 0.763281, acc.: 50.59%] [G loss: 0.405429] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4336 [D loss: 0.736816, acc.: 50.59%] [G loss: 0.401338] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4337 [D loss: 0.754608, acc.: 50.29%] [G loss: 0.407138] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4338 [D loss: 0.741111, acc.: 49.80%] [G loss: 0.406853] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4339 [D loss: 0.729755, acc.: 50.59%] [G loss: 0.401362] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4340 [D loss: 0.747628, acc.: 50.59%] [G loss: 0.404444] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4341 [D loss: 0.748856, acc.: 51.37%] [G loss: 0.404017] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4342 [D loss: 0.741822, acc.: 50.59%] [G loss: 0.400879] [Loss difference: -0.003, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4343 [D loss: 0.743337, acc.: 50.00%] [G loss: 0.407883] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4344 [D loss: 0.747251, acc.: 49.90%] [G loss: 0.410177] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4345 [D loss: 0.749603, acc.: 50.49%] [G loss: 0.411241] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4346 [D loss: 0.734266, acc.: 50.68%] [G loss: 0.415315] [Loss difference: 0.004, iterations with loss: 3]\n",
      "4347 [D loss: 0.741894, acc.: 50.88%] [G loss: 0.423766] [Loss difference: 0.008, iterations with loss: 4]\n",
      "4348 [D loss: 0.738191, acc.: 50.78%] [G loss: 0.409152] [Loss difference: -0.015, iterations with loss: 5]\n",
      "4349 [D loss: 0.744514, acc.: 50.78%] [G loss: 0.415801] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4350 [D loss: 0.755576, acc.: 49.80%] [G loss: 0.414736] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4351 [D loss: 0.734337, acc.: 50.39%] [G loss: 0.411794] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4352 [D loss: 0.750390, acc.: 50.68%] [G loss: 0.408968] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4353 [D loss: 0.738187, acc.: 50.29%] [G loss: 0.411007] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4354 [D loss: 0.738823, acc.: 50.49%] [G loss: 0.415578] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4355 [D loss: 0.752124, acc.: 50.39%] [G loss: 0.424064] [Loss difference: 0.008, iterations with loss: 2]\n",
      "4356 [D loss: 0.722333, acc.: 50.68%] [G loss: 0.421170] [Loss difference: -0.003, iterations with loss: 3]\n",
      "4357 [D loss: 0.753459, acc.: 50.39%] [G loss: 0.426664] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4358 [D loss: 0.736213, acc.: 50.29%] [G loss: 0.417617] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4359 [D loss: 0.750177, acc.: 50.00%] [G loss: 0.430932] [Loss difference: 0.013, iterations with loss: 0]\n",
      "4360 [D loss: 0.753012, acc.: 49.51%] [G loss: 0.421343] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4361 [D loss: 0.749183, acc.: 49.80%] [G loss: 0.422751] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4362 [D loss: 0.747198, acc.: 50.49%] [G loss: 0.420939] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4363 [D loss: 0.753477, acc.: 50.10%] [G loss: 0.413853] [Loss difference: -0.007, iterations with loss: 0]\n",
      "4364 [D loss: 0.747929, acc.: 50.00%] [G loss: 0.410717] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4365 [D loss: 0.726963, acc.: 50.39%] [G loss: 0.424140] [Loss difference: 0.013, iterations with loss: 0]\n",
      "4366 [D loss: 0.749883, acc.: 50.10%] [G loss: 0.416921] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4367 [D loss: 0.742412, acc.: 50.20%] [G loss: 0.420459] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4368 [D loss: 0.733313, acc.: 50.10%] [G loss: 0.421642] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4369 [D loss: 0.719223, acc.: 50.68%] [G loss: 0.411189] [Loss difference: -0.010, iterations with loss: 2]\n",
      "4370 [D loss: 0.749799, acc.: 50.29%] [G loss: 0.410330] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4371 [D loss: 0.733777, acc.: 50.10%] [G loss: 0.418704] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4372 [D loss: 0.737307, acc.: 50.59%] [G loss: 0.423167] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4373 [D loss: 0.724977, acc.: 50.29%] [G loss: 0.417626] [Loss difference: -0.006, iterations with loss: 2]\n",
      "4374 [D loss: 0.744992, acc.: 50.88%] [G loss: 0.410900] [Loss difference: -0.007, iterations with loss: 0]\n",
      "4375 [D loss: 0.746433, acc.: 50.00%] [G loss: 0.413954] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4376 [D loss: 0.731549, acc.: 50.39%] [G loss: 0.420508] [Loss difference: 0.007, iterations with loss: 1]\n",
      "4377 [D loss: 0.739814, acc.: 50.68%] [G loss: 0.419137] [Loss difference: -0.001, iterations with loss: 2]\n",
      "4378 [D loss: 0.752242, acc.: 50.59%] [G loss: 0.414740] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4379 [D loss: 0.743621, acc.: 50.88%] [G loss: 0.408445] [Loss difference: -0.006, iterations with loss: 0]\n",
      "4380 [D loss: 0.762342, acc.: 50.10%] [G loss: 0.415537] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4381 [D loss: 0.749951, acc.: 50.39%] [G loss: 0.414863] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4382 [D loss: 0.727081, acc.: 50.68%] [G loss: 0.427337] [Loss difference: 0.012, iterations with loss: 0]\n",
      "4383 [D loss: 0.740838, acc.: 50.00%] [G loss: 0.422501] [Loss difference: -0.005, iterations with loss: 1]\n",
      "4384 [D loss: 0.734206, acc.: 50.39%] [G loss: 0.421549] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4385 [D loss: 0.743714, acc.: 50.20%] [G loss: 0.412310] [Loss difference: -0.009, iterations with loss: 0]\n",
      "4386 [D loss: 0.741641, acc.: 50.20%] [G loss: 0.416643] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4387 [D loss: 0.738530, acc.: 50.39%] [G loss: 0.422488] [Loss difference: 0.006, iterations with loss: 1]\n",
      "4388 [D loss: 0.732122, acc.: 50.00%] [G loss: 0.426997] [Loss difference: 0.005, iterations with loss: 2]\n",
      "4389 [D loss: 0.729378, acc.: 50.49%] [G loss: 0.428311] [Loss difference: 0.001, iterations with loss: 3]\n",
      "4390 [D loss: 0.737291, acc.: 50.00%] [G loss: 0.413443] [Loss difference: -0.015, iterations with loss: 4]\n",
      "4391 [D loss: 0.721475, acc.: 50.88%] [G loss: 0.417707] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4392 [D loss: 0.724289, acc.: 50.59%] [G loss: 0.417618] [Loss difference: -0.000, iterations with loss: 1]\n",
      "4393 [D loss: 0.740171, acc.: 50.29%] [G loss: 0.419980] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4394 [D loss: 0.743527, acc.: 50.29%] [G loss: 0.422715] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4395 [D loss: 0.734355, acc.: 50.10%] [G loss: 0.428559] [Loss difference: 0.006, iterations with loss: 2]\n",
      "4396 [D loss: 0.742811, acc.: 50.10%] [G loss: 0.419737] [Loss difference: -0.009, iterations with loss: 3]\n",
      "4397 [D loss: 0.741900, acc.: 50.39%] [G loss: 0.417190] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4398 [D loss: 0.734391, acc.: 51.27%] [G loss: 0.419603] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4399 [D loss: 0.750372, acc.: 50.29%] [G loss: 0.418759] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4400 [D loss: 0.736150, acc.: 50.49%] [G loss: 0.425351] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4401 [D loss: 0.737579, acc.: 50.39%] [G loss: 0.415792] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4402 [D loss: 0.743499, acc.: 49.80%] [G loss: 0.429151] [Loss difference: 0.013, iterations with loss: 0]\n",
      "4403 [D loss: 0.727828, acc.: 50.29%] [G loss: 0.417582] [Loss difference: -0.012, iterations with loss: 1]\n",
      "4404 [D loss: 0.727947, acc.: 50.29%] [G loss: 0.421383] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4405 [D loss: 0.746889, acc.: 50.29%] [G loss: 0.418089] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4406 [D loss: 0.745186, acc.: 50.49%] [G loss: 0.416560] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4407 [D loss: 0.728251, acc.: 50.68%] [G loss: 0.424682] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4408 [D loss: 0.735509, acc.: 50.39%] [G loss: 0.418833] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4409 [D loss: 0.732851, acc.: 50.49%] [G loss: 0.424974] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4410 [D loss: 0.730437, acc.: 50.39%] [G loss: 0.431740] [Loss difference: 0.007, iterations with loss: 1]\n",
      "4411 [D loss: 0.725402, acc.: 50.49%] [G loss: 0.431087] [Loss difference: -0.001, iterations with loss: 2]\n",
      "4412 [D loss: 0.745338, acc.: 49.80%] [G loss: 0.420265] [Loss difference: -0.011, iterations with loss: 0]\n",
      "4413 [D loss: 0.719993, acc.: 50.88%] [G loss: 0.427978] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4414 [D loss: 0.722279, acc.: 50.98%] [G loss: 0.410626] [Loss difference: -0.017, iterations with loss: 1]\n",
      "4415 [D loss: 0.734804, acc.: 50.39%] [G loss: 0.416659] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4416 [D loss: 0.716978, acc.: 50.88%] [G loss: 0.417148] [Loss difference: 0.000, iterations with loss: 1]\n",
      "4417 [D loss: 0.737861, acc.: 50.39%] [G loss: 0.421709] [Loss difference: 0.005, iterations with loss: 2]\n",
      "4418 [D loss: 0.735309, acc.: 50.00%] [G loss: 0.424033] [Loss difference: 0.002, iterations with loss: 3]\n",
      "4419 [D loss: 0.737264, acc.: 50.29%] [G loss: 0.432611] [Loss difference: 0.009, iterations with loss: 4]\n",
      "4420 [D loss: 0.728216, acc.: 50.59%] [G loss: 0.425587] [Loss difference: -0.007, iterations with loss: 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421 [D loss: 0.728691, acc.: 49.90%] [G loss: 0.427699] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4422 [D loss: 0.742820, acc.: 50.20%] [G loss: 0.427788] [Loss difference: 0.000, iterations with loss: 1]\n",
      "4423 [D loss: 0.729387, acc.: 50.68%] [G loss: 0.426972] [Loss difference: -0.001, iterations with loss: 2]\n",
      "4424 [D loss: 0.717471, acc.: 50.39%] [G loss: 0.427273] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4425 [D loss: 0.738473, acc.: 50.20%] [G loss: 0.423967] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4426 [D loss: 0.743257, acc.: 50.20%] [G loss: 0.437813] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4427 [D loss: 0.728800, acc.: 50.10%] [G loss: 0.428211] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4428 [D loss: 0.720931, acc.: 50.20%] [G loss: 0.433772] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4429 [D loss: 0.725268, acc.: 50.39%] [G loss: 0.432286] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4430 [D loss: 0.713550, acc.: 50.29%] [G loss: 0.432868] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4431 [D loss: 0.726217, acc.: 50.39%] [G loss: 0.423805] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4432 [D loss: 0.742184, acc.: 50.29%] [G loss: 0.420738] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4433 [D loss: 0.743090, acc.: 50.78%] [G loss: 0.420293] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4434 [D loss: 0.736395, acc.: 50.00%] [G loss: 0.415813] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4435 [D loss: 0.743672, acc.: 50.10%] [G loss: 0.418413] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4436 [D loss: 0.743450, acc.: 50.49%] [G loss: 0.419927] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4437 [D loss: 0.726486, acc.: 50.49%] [G loss: 0.435680] [Loss difference: 0.016, iterations with loss: 2]\n",
      "4438 [D loss: 0.712401, acc.: 51.07%] [G loss: 0.431080] [Loss difference: -0.005, iterations with loss: 3]\n",
      "4439 [D loss: 0.723997, acc.: 49.71%] [G loss: 0.427403] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4440 [D loss: 0.728381, acc.: 50.39%] [G loss: 0.422612] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4441 [D loss: 0.717349, acc.: 50.20%] [G loss: 0.423022] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4442 [D loss: 0.723324, acc.: 50.49%] [G loss: 0.419060] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4443 [D loss: 0.733331, acc.: 50.29%] [G loss: 0.421244] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4444 [D loss: 0.727701, acc.: 50.39%] [G loss: 0.422281] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4445 [D loss: 0.716095, acc.: 50.29%] [G loss: 0.431685] [Loss difference: 0.009, iterations with loss: 2]\n",
      "4446 [D loss: 0.718373, acc.: 50.59%] [G loss: 0.437780] [Loss difference: 0.006, iterations with loss: 3]\n",
      "4447 [D loss: 0.721644, acc.: 50.88%] [G loss: 0.426390] [Loss difference: -0.011, iterations with loss: 4]\n",
      "4448 [D loss: 0.718526, acc.: 50.49%] [G loss: 0.422708] [Loss difference: -0.004, iterations with loss: 0]\n",
      "4449 [D loss: 0.714856, acc.: 50.78%] [G loss: 0.431833] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4450 [D loss: 0.719264, acc.: 50.78%] [G loss: 0.433724] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4451 [D loss: 0.715682, acc.: 50.98%] [G loss: 0.435032] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4452 [D loss: 0.724221, acc.: 50.39%] [G loss: 0.430950] [Loss difference: -0.004, iterations with loss: 3]\n",
      "4453 [D loss: 0.727668, acc.: 50.59%] [G loss: 0.445093] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4454 [D loss: 0.721191, acc.: 50.29%] [G loss: 0.434114] [Loss difference: -0.011, iterations with loss: 1]\n",
      "4455 [D loss: 0.730664, acc.: 50.20%] [G loss: 0.430620] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4456 [D loss: 0.741800, acc.: 50.00%] [G loss: 0.420191] [Loss difference: -0.010, iterations with loss: 0]\n",
      "4457 [D loss: 0.723627, acc.: 50.39%] [G loss: 0.425751] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4458 [D loss: 0.725330, acc.: 50.59%] [G loss: 0.421872] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4459 [D loss: 0.735443, acc.: 50.00%] [G loss: 0.424966] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4460 [D loss: 0.720019, acc.: 50.20%] [G loss: 0.432212] [Loss difference: 0.007, iterations with loss: 1]\n",
      "4461 [D loss: 0.733313, acc.: 50.39%] [G loss: 0.432992] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4462 [D loss: 0.727682, acc.: 50.68%] [G loss: 0.434169] [Loss difference: 0.001, iterations with loss: 3]\n",
      "4463 [D loss: 0.719082, acc.: 50.68%] [G loss: 0.437716] [Loss difference: 0.004, iterations with loss: 4]\n",
      "4464 [D loss: 0.711561, acc.: 50.20%] [G loss: 0.424892] [Loss difference: -0.013, iterations with loss: 5]\n",
      "4465 [D loss: 0.729292, acc.: 50.39%] [G loss: 0.430246] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4466 [D loss: 0.735506, acc.: 50.59%] [G loss: 0.435277] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4467 [D loss: 0.744036, acc.: 50.29%] [G loss: 0.432100] [Loss difference: -0.003, iterations with loss: 2]\n",
      "4468 [D loss: 0.723258, acc.: 50.78%] [G loss: 0.435944] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4469 [D loss: 0.714528, acc.: 50.98%] [G loss: 0.429205] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4470 [D loss: 0.733645, acc.: 50.00%] [G loss: 0.435590] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4471 [D loss: 0.716247, acc.: 50.49%] [G loss: 0.439820] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4472 [D loss: 0.727129, acc.: 50.78%] [G loss: 0.439645] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4473 [D loss: 0.727548, acc.: 50.49%] [G loss: 0.436543] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4474 [D loss: 0.737069, acc.: 50.68%] [G loss: 0.428989] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4475 [D loss: 0.734327, acc.: 50.39%] [G loss: 0.432669] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4476 [D loss: 0.718152, acc.: 50.49%] [G loss: 0.445333] [Loss difference: 0.013, iterations with loss: 1]\n",
      "4477 [D loss: 0.728852, acc.: 50.29%] [G loss: 0.430640] [Loss difference: -0.015, iterations with loss: 2]\n",
      "4478 [D loss: 0.717270, acc.: 50.59%] [G loss: 0.437413] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4479 [D loss: 0.740165, acc.: 50.88%] [G loss: 0.451908] [Loss difference: 0.014, iterations with loss: 1]\n",
      "4480 [D loss: 0.748312, acc.: 50.00%] [G loss: 0.465184] [Loss difference: 0.013, iterations with loss: 2]\n",
      "4481 [D loss: 0.734687, acc.: 50.29%] [G loss: 0.460520] [Loss difference: -0.005, iterations with loss: 3]\n",
      "4482 [D loss: 0.727959, acc.: 50.98%] [G loss: 0.466303] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4483 [D loss: 0.735119, acc.: 50.39%] [G loss: 0.451241] [Loss difference: -0.015, iterations with loss: 1]\n",
      "4484 [D loss: 0.739246, acc.: 50.68%] [G loss: 0.445086] [Loss difference: -0.006, iterations with loss: 0]\n",
      "4485 [D loss: 0.736283, acc.: 50.98%] [G loss: 0.440484] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4486 [D loss: 0.741461, acc.: 50.20%] [G loss: 0.433063] [Loss difference: -0.007, iterations with loss: 0]\n",
      "4487 [D loss: 0.743681, acc.: 50.59%] [G loss: 0.432883] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4488 [D loss: 0.753286, acc.: 50.10%] [G loss: 0.438945] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4489 [D loss: 0.742732, acc.: 50.00%] [G loss: 0.439391] [Loss difference: 0.000, iterations with loss: 1]\n",
      "4490 [D loss: 0.720018, acc.: 50.68%] [G loss: 0.435212] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4491 [D loss: 0.713836, acc.: 50.98%] [G loss: 0.447425] [Loss difference: 0.012, iterations with loss: 0]\n",
      "4492 [D loss: 0.719069, acc.: 51.07%] [G loss: 0.439094] [Loss difference: -0.008, iterations with loss: 1]\n",
      "4493 [D loss: 0.737673, acc.: 50.29%] [G loss: 0.431423] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4494 [D loss: 0.713406, acc.: 50.49%] [G loss: 0.432916] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4495 [D loss: 0.720755, acc.: 50.00%] [G loss: 0.436236] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4496 [D loss: 0.719169, acc.: 50.39%] [G loss: 0.435825] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4497 [D loss: 0.718047, acc.: 50.78%] [G loss: 0.442874] [Loss difference: 0.007, iterations with loss: 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4498 [D loss: 0.728607, acc.: 50.39%] [G loss: 0.443277] [Loss difference: 0.000, iterations with loss: 1]\n",
      "4499 [D loss: 0.714404, acc.: 50.88%] [G loss: 0.443272] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4500 [D loss: 0.718959, acc.: 50.49%] [G loss: 0.444679] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4501 [D loss: 0.715781, acc.: 50.49%] [G loss: 0.437391] [Loss difference: -0.007, iterations with loss: 1]\n",
      "4502 [D loss: 0.731092, acc.: 50.10%] [G loss: 0.438086] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4503 [D loss: 0.721137, acc.: 50.29%] [G loss: 0.438751] [Loss difference: 0.001, iterations with loss: 1]\n",
      "4504 [D loss: 0.719325, acc.: 50.39%] [G loss: 0.444650] [Loss difference: 0.006, iterations with loss: 2]\n",
      "4505 [D loss: 0.718845, acc.: 50.20%] [G loss: 0.451948] [Loss difference: 0.007, iterations with loss: 3]\n",
      "4506 [D loss: 0.713138, acc.: 50.29%] [G loss: 0.433131] [Loss difference: -0.019, iterations with loss: 4]\n",
      "4507 [D loss: 0.721843, acc.: 50.68%] [G loss: 0.439035] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4508 [D loss: 0.729168, acc.: 50.39%] [G loss: 0.427371] [Loss difference: -0.012, iterations with loss: 1]\n",
      "4509 [D loss: 0.708583, acc.: 50.29%] [G loss: 0.431483] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4510 [D loss: 0.713957, acc.: 50.10%] [G loss: 0.435245] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4511 [D loss: 0.726961, acc.: 50.68%] [G loss: 0.433830] [Loss difference: -0.001, iterations with loss: 2]\n",
      "4512 [D loss: 0.713971, acc.: 50.68%] [G loss: 0.432791] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4513 [D loss: 0.725768, acc.: 50.49%] [G loss: 0.439005] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4514 [D loss: 0.716712, acc.: 50.98%] [G loss: 0.441170] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4515 [D loss: 0.715317, acc.: 49.80%] [G loss: 0.450950] [Loss difference: 0.010, iterations with loss: 2]\n",
      "4516 [D loss: 0.713616, acc.: 50.68%] [G loss: 0.444879] [Loss difference: -0.006, iterations with loss: 3]\n",
      "4517 [D loss: 0.708782, acc.: 50.68%] [G loss: 0.437105] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4518 [D loss: 0.714761, acc.: 50.68%] [G loss: 0.444970] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4519 [D loss: 0.722420, acc.: 50.10%] [G loss: 0.440379] [Loss difference: -0.005, iterations with loss: 1]\n",
      "4520 [D loss: 0.692341, acc.: 50.59%] [G loss: 0.451360] [Loss difference: 0.011, iterations with loss: 0]\n",
      "4521 [D loss: 0.712040, acc.: 50.00%] [G loss: 0.448662] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4522 [D loss: 0.699704, acc.: 50.29%] [G loss: 0.449241] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4523 [D loss: 0.708288, acc.: 50.39%] [G loss: 0.439917] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4524 [D loss: 0.720378, acc.: 50.10%] [G loss: 0.447298] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4525 [D loss: 0.723253, acc.: 50.59%] [G loss: 0.436828] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4526 [D loss: 0.724785, acc.: 50.39%] [G loss: 0.451623] [Loss difference: 0.015, iterations with loss: 0]\n",
      "4527 [D loss: 0.713837, acc.: 50.10%] [G loss: 0.453588] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4528 [D loss: 0.710762, acc.: 50.88%] [G loss: 0.454990] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4529 [D loss: 0.718202, acc.: 50.10%] [G loss: 0.449033] [Loss difference: -0.006, iterations with loss: 3]\n",
      "4530 [D loss: 0.719012, acc.: 50.78%] [G loss: 0.439531] [Loss difference: -0.010, iterations with loss: 0]\n",
      "4531 [D loss: 0.715932, acc.: 50.78%] [G loss: 0.439953] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4532 [D loss: 0.729585, acc.: 50.20%] [G loss: 0.445437] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4533 [D loss: 0.698835, acc.: 50.78%] [G loss: 0.441396] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4534 [D loss: 0.719019, acc.: 50.10%] [G loss: 0.451485] [Loss difference: 0.010, iterations with loss: 0]\n",
      "4535 [D loss: 0.701654, acc.: 50.59%] [G loss: 0.448010] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4536 [D loss: 0.709998, acc.: 50.49%] [G loss: 0.439947] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4537 [D loss: 0.695321, acc.: 50.29%] [G loss: 0.444505] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4538 [D loss: 0.711838, acc.: 50.59%] [G loss: 0.439092] [Loss difference: -0.005, iterations with loss: 1]\n",
      "4539 [D loss: 0.716345, acc.: 50.10%] [G loss: 0.438355] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4540 [D loss: 0.705005, acc.: 50.68%] [G loss: 0.447805] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4541 [D loss: 0.712178, acc.: 50.59%] [G loss: 0.443878] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4542 [D loss: 0.705462, acc.: 50.68%] [G loss: 0.444117] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4543 [D loss: 0.735131, acc.: 50.39%] [G loss: 0.451764] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4544 [D loss: 0.716166, acc.: 50.49%] [G loss: 0.452151] [Loss difference: 0.000, iterations with loss: 2]\n",
      "4545 [D loss: 0.702305, acc.: 50.49%] [G loss: 0.451167] [Loss difference: -0.001, iterations with loss: 3]\n",
      "4546 [D loss: 0.680040, acc.: 50.88%] [G loss: 0.448052] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4547 [D loss: 0.703403, acc.: 50.88%] [G loss: 0.445899] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4548 [D loss: 0.708844, acc.: 50.49%] [G loss: 0.445300] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4549 [D loss: 0.706526, acc.: 50.29%] [G loss: 0.439273] [Loss difference: -0.006, iterations with loss: 0]\n",
      "4550 [D loss: 0.713732, acc.: 50.49%] [G loss: 0.441398] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4551 [D loss: 0.727099, acc.: 50.78%] [G loss: 0.437035] [Loss difference: -0.004, iterations with loss: 1]\n",
      "4552 [D loss: 0.717004, acc.: 50.59%] [G loss: 0.442803] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4553 [D loss: 0.708813, acc.: 50.59%] [G loss: 0.451653] [Loss difference: 0.009, iterations with loss: 1]\n",
      "4554 [D loss: 0.726871, acc.: 50.59%] [G loss: 0.457751] [Loss difference: 0.006, iterations with loss: 2]\n",
      "4555 [D loss: 0.709430, acc.: 50.59%] [G loss: 0.463672] [Loss difference: 0.006, iterations with loss: 3]\n",
      "4556 [D loss: 0.715462, acc.: 50.20%] [G loss: 0.459755] [Loss difference: -0.004, iterations with loss: 4]\n",
      "4557 [D loss: 0.697980, acc.: 50.98%] [G loss: 0.459434] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4558 [D loss: 0.727072, acc.: 50.59%] [G loss: 0.443250] [Loss difference: -0.016, iterations with loss: 0]\n",
      "4559 [D loss: 0.727617, acc.: 50.59%] [G loss: 0.442015] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4560 [D loss: 0.722835, acc.: 50.39%] [G loss: 0.440529] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4561 [D loss: 0.719152, acc.: 50.59%] [G loss: 0.448720] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4562 [D loss: 0.729145, acc.: 49.80%] [G loss: 0.461661] [Loss difference: 0.013, iterations with loss: 1]\n",
      "4563 [D loss: 0.704943, acc.: 51.07%] [G loss: 0.457551] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4564 [D loss: 0.706477, acc.: 50.29%] [G loss: 0.463335] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4565 [D loss: 0.703286, acc.: 50.00%] [G loss: 0.449505] [Loss difference: -0.014, iterations with loss: 1]\n",
      "4566 [D loss: 0.704858, acc.: 51.07%] [G loss: 0.452391] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4567 [D loss: 0.693263, acc.: 50.68%] [G loss: 0.449846] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4568 [D loss: 0.722476, acc.: 50.39%] [G loss: 0.435697] [Loss difference: -0.014, iterations with loss: 0]\n",
      "4569 [D loss: 0.720458, acc.: 51.07%] [G loss: 0.449819] [Loss difference: 0.014, iterations with loss: 0]\n",
      "4570 [D loss: 0.725256, acc.: 50.49%] [G loss: 0.440827] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4571 [D loss: 0.699824, acc.: 50.98%] [G loss: 0.447923] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4572 [D loss: 0.714990, acc.: 50.78%] [G loss: 0.450085] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4573 [D loss: 0.698912, acc.: 51.37%] [G loss: 0.445830] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4574 [D loss: 0.713266, acc.: 51.46%] [G loss: 0.454995] [Loss difference: 0.009, iterations with loss: 0]\n",
      "4575 [D loss: 0.697374, acc.: 50.68%] [G loss: 0.451382] [Loss difference: -0.004, iterations with loss: 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4576 [D loss: 0.744652, acc.: 51.07%] [G loss: 0.461091] [Loss difference: 0.010, iterations with loss: 0]\n",
      "4577 [D loss: 0.693401, acc.: 50.98%] [G loss: 0.474095] [Loss difference: 0.013, iterations with loss: 1]\n",
      "4578 [D loss: 0.701130, acc.: 50.49%] [G loss: 0.460004] [Loss difference: -0.014, iterations with loss: 2]\n",
      "4579 [D loss: 0.706568, acc.: 50.98%] [G loss: 0.465252] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4580 [D loss: 0.711010, acc.: 50.78%] [G loss: 0.450913] [Loss difference: -0.014, iterations with loss: 1]\n",
      "4581 [D loss: 0.697821, acc.: 50.78%] [G loss: 0.447889] [Loss difference: -0.003, iterations with loss: 0]\n",
      "4582 [D loss: 0.707378, acc.: 50.78%] [G loss: 0.463195] [Loss difference: 0.015, iterations with loss: 0]\n",
      "4583 [D loss: 0.701461, acc.: 50.98%] [G loss: 0.471028] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4584 [D loss: 0.703697, acc.: 50.78%] [G loss: 0.466959] [Loss difference: -0.004, iterations with loss: 2]\n",
      "4585 [D loss: 0.695931, acc.: 50.49%] [G loss: 0.454522] [Loss difference: -0.012, iterations with loss: 0]\n",
      "4586 [D loss: 0.698829, acc.: 51.07%] [G loss: 0.447051] [Loss difference: -0.007, iterations with loss: 0]\n",
      "4587 [D loss: 0.708446, acc.: 50.49%] [G loss: 0.453559] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4588 [D loss: 0.709535, acc.: 50.78%] [G loss: 0.456274] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4589 [D loss: 0.709954, acc.: 50.29%] [G loss: 0.449637] [Loss difference: -0.007, iterations with loss: 2]\n",
      "4590 [D loss: 0.691262, acc.: 51.56%] [G loss: 0.454443] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4591 [D loss: 0.707606, acc.: 50.20%] [G loss: 0.451810] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4592 [D loss: 0.703826, acc.: 50.78%] [G loss: 0.449346] [Loss difference: -0.002, iterations with loss: 0]\n",
      "4593 [D loss: 0.717526, acc.: 49.80%] [G loss: 0.444205] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4594 [D loss: 0.695956, acc.: 50.88%] [G loss: 0.449936] [Loss difference: 0.006, iterations with loss: 0]\n",
      "4595 [D loss: 0.708360, acc.: 50.88%] [G loss: 0.452267] [Loss difference: 0.002, iterations with loss: 1]\n",
      "4596 [D loss: 0.700778, acc.: 50.78%] [G loss: 0.458242] [Loss difference: 0.006, iterations with loss: 2]\n",
      "4597 [D loss: 0.691640, acc.: 50.59%] [G loss: 0.451567] [Loss difference: -0.007, iterations with loss: 3]\n",
      "4598 [D loss: 0.699483, acc.: 50.68%] [G loss: 0.456824] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4599 [D loss: 0.718627, acc.: 50.29%] [G loss: 0.456066] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4600 [D loss: 0.710277, acc.: 50.98%] [G loss: 0.457097] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4601 [D loss: 0.709040, acc.: 50.68%] [G loss: 0.447468] [Loss difference: -0.010, iterations with loss: 1]\n",
      "4602 [D loss: 0.697780, acc.: 50.88%] [G loss: 0.454916] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4603 [D loss: 0.699525, acc.: 50.49%] [G loss: 0.458521] [Loss difference: 0.004, iterations with loss: 1]\n",
      "4604 [D loss: 0.691576, acc.: 50.78%] [G loss: 0.458437] [Loss difference: -0.000, iterations with loss: 2]\n",
      "4605 [D loss: 0.700040, acc.: 50.98%] [G loss: 0.448315] [Loss difference: -0.010, iterations with loss: 0]\n",
      "4606 [D loss: 0.702089, acc.: 50.88%] [G loss: 0.458161] [Loss difference: 0.010, iterations with loss: 0]\n",
      "4607 [D loss: 0.692539, acc.: 51.27%] [G loss: 0.463649] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4608 [D loss: 0.704823, acc.: 50.88%] [G loss: 0.462510] [Loss difference: -0.001, iterations with loss: 2]\n",
      "4609 [D loss: 0.681187, acc.: 50.88%] [G loss: 0.454492] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4610 [D loss: 0.687251, acc.: 50.68%] [G loss: 0.455629] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4611 [D loss: 0.689571, acc.: 50.78%] [G loss: 0.460993] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4612 [D loss: 0.689497, acc.: 50.49%] [G loss: 0.464680] [Loss difference: 0.004, iterations with loss: 2]\n",
      "4613 [D loss: 0.703344, acc.: 51.07%] [G loss: 0.467400] [Loss difference: 0.003, iterations with loss: 3]\n",
      "4614 [D loss: 0.700078, acc.: 50.78%] [G loss: 0.468138] [Loss difference: 0.001, iterations with loss: 4]\n",
      "4615 [D loss: 0.708446, acc.: 50.29%] [G loss: 0.467746] [Loss difference: -0.000, iterations with loss: 5]\n",
      "4616 [D loss: 0.700552, acc.: 50.68%] [G loss: 0.471228] [Loss difference: 0.003, iterations with loss: 0]\n",
      "4617 [D loss: 0.692508, acc.: 50.49%] [G loss: 0.456873] [Loss difference: -0.014, iterations with loss: 1]\n",
      "4618 [D loss: 0.713539, acc.: 50.29%] [G loss: 0.461258] [Loss difference: 0.004, iterations with loss: 0]\n",
      "4619 [D loss: 0.708179, acc.: 50.20%] [G loss: 0.464266] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4620 [D loss: 0.709381, acc.: 50.98%] [G loss: 0.468835] [Loss difference: 0.005, iterations with loss: 2]\n",
      "4621 [D loss: 0.711495, acc.: 50.98%] [G loss: 0.469447] [Loss difference: 0.001, iterations with loss: 3]\n",
      "4622 [D loss: 0.698013, acc.: 50.68%] [G loss: 0.468562] [Loss difference: -0.001, iterations with loss: 4]\n",
      "4623 [D loss: 0.703794, acc.: 51.17%] [G loss: 0.469210] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4624 [D loss: 0.704942, acc.: 51.27%] [G loss: 0.460217] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4625 [D loss: 0.706941, acc.: 51.27%] [G loss: 0.478488] [Loss difference: 0.018, iterations with loss: 0]\n",
      "4626 [D loss: 0.696123, acc.: 50.78%] [G loss: 0.472204] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4627 [D loss: 0.699377, acc.: 50.49%] [G loss: 0.464347] [Loss difference: -0.008, iterations with loss: 0]\n",
      "4628 [D loss: 0.690886, acc.: 50.59%] [G loss: 0.464778] [Loss difference: 0.000, iterations with loss: 0]\n",
      "4629 [D loss: 0.697844, acc.: 50.78%] [G loss: 0.455772] [Loss difference: -0.009, iterations with loss: 1]\n",
      "4630 [D loss: 0.693724, acc.: 50.88%] [G loss: 0.462950] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4631 [D loss: 0.706322, acc.: 50.20%] [G loss: 0.463034] [Loss difference: 0.000, iterations with loss: 1]\n",
      "4632 [D loss: 0.690571, acc.: 51.07%] [G loss: 0.484591] [Loss difference: 0.022, iterations with loss: 2]\n",
      "4633 [D loss: 0.689747, acc.: 51.17%] [G loss: 0.476635] [Loss difference: -0.008, iterations with loss: 3]\n",
      "4634 [D loss: 0.691459, acc.: 50.59%] [G loss: 0.476549] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4635 [D loss: 0.691952, acc.: 50.78%] [G loss: 0.461132] [Loss difference: -0.015, iterations with loss: 0]\n",
      "4636 [D loss: 0.688534, acc.: 50.98%] [G loss: 0.469111] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4637 [D loss: 0.704127, acc.: 50.59%] [G loss: 0.456146] [Loss difference: -0.013, iterations with loss: 1]\n",
      "4638 [D loss: 0.695518, acc.: 50.59%] [G loss: 0.454863] [Loss difference: -0.001, iterations with loss: 0]\n",
      "4639 [D loss: 0.705594, acc.: 50.00%] [G loss: 0.459564] [Loss difference: 0.005, iterations with loss: 0]\n",
      "4640 [D loss: 0.686029, acc.: 50.49%] [G loss: 0.456737] [Loss difference: -0.003, iterations with loss: 1]\n",
      "4641 [D loss: 0.686923, acc.: 51.07%] [G loss: 0.456387] [Loss difference: -0.000, iterations with loss: 0]\n",
      "4642 [D loss: 0.694128, acc.: 50.49%] [G loss: 0.463444] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4643 [D loss: 0.688498, acc.: 50.68%] [G loss: 0.470130] [Loss difference: 0.007, iterations with loss: 1]\n",
      "4644 [D loss: 0.685357, acc.: 50.49%] [G loss: 0.471062] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4645 [D loss: 0.694173, acc.: 50.98%] [G loss: 0.459968] [Loss difference: -0.011, iterations with loss: 3]\n",
      "4646 [D loss: 0.688515, acc.: 50.39%] [G loss: 0.472386] [Loss difference: 0.012, iterations with loss: 0]\n",
      "4647 [D loss: 0.694558, acc.: 50.29%] [G loss: 0.471003] [Loss difference: -0.001, iterations with loss: 1]\n",
      "4648 [D loss: 0.693219, acc.: 51.07%] [G loss: 0.472499] [Loss difference: 0.001, iterations with loss: 0]\n",
      "4649 [D loss: 0.686108, acc.: 51.07%] [G loss: 0.470884] [Loss difference: -0.002, iterations with loss: 1]\n",
      "4650 [D loss: 0.695741, acc.: 50.39%] [G loss: 0.472645] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4651 [D loss: 0.704286, acc.: 50.78%] [G loss: 0.477425] [Loss difference: 0.005, iterations with loss: 1]\n",
      "4652 [D loss: 0.705072, acc.: 50.10%] [G loss: 0.468460] [Loss difference: -0.009, iterations with loss: 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4653 [D loss: 0.829034, acc.: 50.88%] [G loss: 0.497449] [Loss difference: 0.029, iterations with loss: 0]\n",
      "4654 [D loss: 0.692136, acc.: 50.49%] [G loss: 0.486896] [Loss difference: -0.011, iterations with loss: 1]\n",
      "4655 [D loss: 0.707546, acc.: 50.49%] [G loss: 0.472732] [Loss difference: -0.014, iterations with loss: 0]\n",
      "4656 [D loss: 0.768073, acc.: 50.10%] [G loss: 0.474328] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4657 [D loss: 0.702479, acc.: 50.88%] [G loss: 0.477513] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4658 [D loss: 0.749571, acc.: 50.10%] [G loss: 0.482983] [Loss difference: 0.005, iterations with loss: 2]\n",
      "4659 [D loss: 0.700136, acc.: 50.88%] [G loss: 0.495197] [Loss difference: 0.012, iterations with loss: 3]\n",
      "4660 [D loss: 0.689865, acc.: 51.07%] [G loss: 0.470371] [Loss difference: -0.025, iterations with loss: 4]\n",
      "4661 [D loss: 0.766306, acc.: 50.59%] [G loss: 0.477344] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4662 [D loss: 0.697981, acc.: 50.78%] [G loss: 0.471731] [Loss difference: -0.006, iterations with loss: 1]\n",
      "4663 [D loss: 0.760175, acc.: 50.29%] [G loss: 0.473641] [Loss difference: 0.002, iterations with loss: 0]\n",
      "4664 [D loss: 0.680134, acc.: 51.07%] [G loss: 0.476433] [Loss difference: 0.003, iterations with loss: 1]\n",
      "4665 [D loss: 0.747348, acc.: 50.78%] [G loss: 0.493424] [Loss difference: 0.017, iterations with loss: 2]\n",
      "4666 [D loss: 0.714898, acc.: 50.98%] [G loss: 0.484908] [Loss difference: -0.009, iterations with loss: 3]\n",
      "4667 [D loss: 0.689439, acc.: 51.07%] [G loss: 0.479907] [Loss difference: -0.005, iterations with loss: 0]\n",
      "4668 [D loss: 0.713548, acc.: 51.07%] [G loss: 0.487268] [Loss difference: 0.007, iterations with loss: 0]\n",
      "4669 [D loss: 0.690219, acc.: 50.98%] [G loss: 0.468958] [Loss difference: -0.018, iterations with loss: 1]\n",
      "4670 [D loss: 0.731045, acc.: 51.27%] [G loss: 0.477128] [Loss difference: 0.008, iterations with loss: 0]\n",
      "4671 [D loss: 0.698384, acc.: 50.68%] [G loss: 0.485520] [Loss difference: 0.008, iterations with loss: 1]\n",
      "4672 [D loss: 0.723263, acc.: 50.39%] [G loss: 0.486765] [Loss difference: 0.001, iterations with loss: 2]\n",
      "4673 [D loss: 0.710741, acc.: 51.27%] [G loss: 0.486898] [Loss difference: 0.000, iterations with loss: 3]\n",
      "4674 [D loss: 0.697664, acc.: 50.88%] [G loss: 0.494976] [Loss difference: 0.008, iterations with loss: 4]\n",
      "4675 [D loss: 0.700353, acc.: 50.59%] [G loss: 0.495049] [Loss difference: 0.000, iterations with loss: 5]\n",
      "Stoping on iteration:  4675\n",
      "Generated Neptune attacks: \n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0. 108.   0.   0.   0.   0.   0.\n",
      "    6.  20.   0.   0.   0.  12.   1.  19.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0. 106.   0.   0.   0.   0.   0.\n",
      "    6.  20.   0.   0.   0.  12.   1.  19.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(41, input_dim=41, activation='relu'))  # discriminator takes 41 values from our dataset\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # outputs 0 to 1, 1 being read and 0 being fake\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    attack = Input(shape=(41,))\n",
    "    validity = model(attack)\n",
    "\n",
    "    return Model(attack, validity)\n",
    "\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=41))  # arbitrarily selected 100 for our input noise vector?\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(75))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(45))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(41, activation='relu'))  # outputs a generated vector of the same size as our data (41)\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    noise = Input(shape=(41,))\n",
    "    attack = model(noise)\n",
    "    return Model(noise, attack)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    f = open(\"GANresults.txt\", \"w\")\n",
    "    f.write(\"\"\"Results:\n",
    "    -------------------------------\"\"\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    dataframe = pd.read_csv('kdd_neptune_only_5000.csv').sample(4096) # sample 100 data points randomly from the csv\n",
    "    batch_size = 512\n",
    "    epochs = 10000\n",
    "\n",
    "    # apply \"le.fit_transform\" to every column (usually only works on 1 column)\n",
    "    le = LabelEncoder()\n",
    "    dataframe_encoded = dataframe.apply(le.fit_transform)\n",
    "    dataset = dataframe_encoded.values\n",
    "    \n",
    "    print(\"Real neptune attacks:\")\n",
    "    print(dataset[:2])\n",
    "\n",
    "    # Set X as our input data and Y as our label\n",
    "    X_train = dataset[:, 0:41].astype(float)\n",
    "    Y_train = dataset[:, 41]\n",
    "    \n",
    "    np.savetxt(\"NeptuneFeatures.txt\", X_train, fmt=\"%.0f\")\n",
    "\n",
    "    # size of each batch for training and number of epochs\n",
    "    \n",
    "    \n",
    "    # labels for data. 1 for valid attacks, 0 for fake (generated) attacks\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    discriminator = build_discriminator();\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                               optimizer=optimizer,\n",
    "                               metrics=['accuracy'])\n",
    "    generator = build_generator()\n",
    "\n",
    "    z = Input(shape=(41,))\n",
    "    attack = generator(z)\n",
    "\n",
    "    # discriminator.trainable = False\n",
    "\n",
    "    validity = discriminator(attack)\n",
    "\n",
    "    combined = Model(z, validity)\n",
    "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    #stop training if our G loss starts going up (is G loss really the loss of the entire model?)\n",
    "    loss_increase_count = 0;\n",
    "    prev_g_loss = 0;\n",
    "    \n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # selecting batch_size random attacks from our training data\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        attacks = X_train[idx]\n",
    "\n",
    "        # TODO: if there is problems, we might need to normalize our data too\n",
    "        # generating an array of normalized random noise vectors\n",
    "        noise = noise = np.random.normal(0, 1, (batch_size, 41))\n",
    "\n",
    "        # create an array of generatid attack by using the model to predict based on the noise vectors\n",
    "        gen_attacks = generator.predict(noise)\n",
    "\n",
    "        # don't really understand what these loss functions are\n",
    "        d_loss_real = discriminator.train_on_batch(attacks, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_attacks, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 41))\n",
    "\n",
    "        # Train the generator (to have the discriminator label samples as valid)\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "        print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f] [Loss difference: %.3f, iterations with loss: %.0f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss, g_loss - prev_g_loss, loss_increase_count))\n",
    "\n",
    "        \n",
    "            \n",
    "        # this is to break us out and save good results if our model starts increasing loss\n",
    "        \n",
    "        # if our generator loss icreased this iteration, increment the counter by 1\n",
    "        if (g_loss - prev_g_loss) > 0:\n",
    "            loss_increase_count = loss_increase_count + 1\n",
    "        else: \n",
    "            loss_increase_count = 0  # otherwise, reset it to 0, we are still training effectively\n",
    "            \n",
    "        # if we've gone 10 iterations of increasing loss, stop training. Results are only saved every 50 iterations\n",
    "        if loss_increase_count > 5:\n",
    "            print('Stoping on iteration: ', epoch)\n",
    "            break\n",
    "        \n",
    "        # write generated attacks to file every 50 iterations\n",
    "        if epoch % 50 == 0:\n",
    "            f = open(\"GANresults.txt\", \"a\")\n",
    "            rounded_attacks = np.around(gen_attacks, decimals=3)\n",
    "            # np.savetxt(\"GANresults.txt\", rounded_attacks, fmt=\"[%1.3f],\")\n",
    "            np.savetxt(\"GANresults.txt\", gen_attacks, fmt=\"%.0f\")\n",
    "            f.close()\n",
    "        \n",
    "        prev_g_loss = g_loss\n",
    "        \n",
    "    results = np.loadtxt(\"GANresults.txt\")\n",
    "    \n",
    "    print(\"Generated Neptune attacks: \")\n",
    "    print(results[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

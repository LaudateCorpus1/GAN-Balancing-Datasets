{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "import numpy\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Number Generator\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back.' 'guess_passwd.' 'ipsweep.' 'land.' 'neptune.' 'nmap.' 'normal.'\n",
      " 'pod.' 'portsweep.' 'satan.' 'smurf.' 'teardrop.' 'warezclient.']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "# dataframe = pandas.read_csv(\"kddforpandatrain.csv\")#, header=True)\n",
    "dataframe = pandas.read_csv(\"kdd_dataset.csv\")#, header=True)  # read the whole 10% dataset into dataframe\n",
    "\n",
    "#samples a smaller batch for testing\n",
    "\n",
    "# samples 3000 random data points from 500k\n",
    "dataframe = dataframe.sample(n=4000)\n",
    "\n",
    "\n",
    "# LabelEncoder, turns all our categorical data into integers\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply \"le.fit_transform\" to every column (usually only works on 1 column)\n",
    "dataframe_encoded = dataframe.apply(le.fit_transform)\n",
    "attack_labels = le.classes_\n",
    "dataset = dataframe_encoded.values\n",
    "\n",
    "\n",
    "# need to find what the integer value of neptune label is, so we can feed generated neptune data\n",
    "print(attack_labels)  # for debugging, checking we got the right label for neptune\n",
    "indices_of_neptune = numpy.where(attack_labels == 'neptune.')  # find the index of neptune attacks in the label list (should only be one)\n",
    "neptune_index = indices_of_neptune[0]  # get the first element of that (redundant in this case, but safe)\n",
    "\n",
    "print(neptune_index[0])  # for debugging\n",
    "\n",
    "\n",
    "#Set X as our input data and Y as our label\n",
    "X = dataset[0:3000,0:41].astype(float)\n",
    "Y = dataset[0:3000,41]\n",
    "\n",
    "X_test = dataset[3000:,0:41].astype(float)\n",
    "Y_test = dataset[3000:,41]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "# print(dummy_y)\n",
    "print(len(dummy_y[0]))\n",
    "num_of_classes = len(dummy_y[0])  # the length of dummy y is the number of classes we have in our small sample\n",
    "# since we are randomly sampling from a large dataset, we might not get 1 of every class in our sample\n",
    "# we need to set output layer to be equal to the length of our dummy_y vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputs = 41\n",
    "    hidden_layer1 = 18\n",
    "    hidden_layer2 = 6\n",
    "    hidden_layer3 = 0\n",
    "    outputs = num_of_classes  #needs to be this variable in case we forget to sample. Could end up having 10 classes or 12, etc\n",
    "    \n",
    "    model.add(Dense(hidden_layer1, input_dim=inputs, activation='relu'))\n",
    "    if hidden_layer2 != 0:\n",
    "        model.add(Dense(hidden_layer2, activation='relu'))\n",
    "    if hidden_layer3 != 0:\n",
    "        model.add(Dense(hidden_layer3, activation='relu'))\n",
    "    model.add(Dense(outputs, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0 213   0   0   0   0   0   0   0]\n",
      " [  1   1   0   0 187   0   0   0   0   1   1]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 579   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0]]\n",
      "total: 1000\n",
      "accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=300, batch_size=10, verbose=0)\n",
    "\n",
    "# fit the estimator to our train data\n",
    "estimator.fit(X, Y)\n",
    "\n",
    "# predict the values based on a test set\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# create a confusion matrix with the results\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"total: \" + str(cm.sum()))\n",
    "print(\"accuracy: \" + str(numpy.trace(cm) / cm.sum()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\n",
      "Attack type: neptune.     number predicted:  235\n",
      "Attack type: normal.     number predicted:  188\n",
      "Attack type: portsweep.     number predicted:  16\n",
      "Attack type: teardrop.     number predicted:  72\n",
      "Attack type: warezclient.     number predicted:  1\n",
      "\n",
      "[[235 188  16  72   1]\n",
      " [  0   0   0   0   0]\n",
      " [  0   0   0   0   0]\n",
      " [  0   0   0   0   0]\n",
      " [  0   0   0   0   0]]\n",
      "total: 512\n",
      "accuracy: 0.458984375\n"
     ]
    }
   ],
   "source": [
    "# retrieve generated attacks from file\n",
    "results = numpy.loadtxt(\"GANresults.txt\")\n",
    "\n",
    "# use our estimator to predict the labels of our generated attacks\n",
    "y_pred = estimator.predict(results)\n",
    "\n",
    "#create an array the same size as our generated array size, and make their labels neptune (in this case)\n",
    "neptune_labels = numpy.full((len(results),), neptune_index[0])\n",
    "print(neptune_labels[0]) # debugging, this should match the value from earlier\n",
    "\n",
    "# convert integer labels back to string, get all unique strings and their count\n",
    "predicted_as_label = attack_labels[y_pred]\n",
    "unique_labels = numpy.unique(predicted_as_label)\n",
    "\n",
    "print()\n",
    "for label in unique_labels:\n",
    "    print(\"Attack type: %s     number predicted:  %.0f\" % (label, len(numpy.where(predicted_as_label == label)[0])))\n",
    "\n",
    "print()\n",
    "# create a confusion matrix of the results\n",
    "cm = confusion_matrix(neptune_labels, y_pred)\n",
    "print(cm)\n",
    "print(\"total: \" + str(cm.sum()))\n",
    "print(\"accuracy: \" + str(numpy.trace(cm) / cm.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field          TP             FP             FN             TN             MC Rate        MCC            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "back.          0.45898        0.00000        1.00000        0.00000        0.54102        0.00000        \n",
      "guess_passwd.  0.00000        1.00000        0.00000        0.63281        1.00000        0.00000        \n",
      "ipsweep.       0.00000        1.00000        0.00000        0.96875        1.00000        0.00000        \n",
      "land.          0.00000        1.00000        0.00000        0.85938        1.00000        0.00000        \n",
      "neptune.       0.00000        1.00000        0.00000        0.99805        1.00000        0.00000        \n",
      "\n",
      "Average true positive rate: 0.091796875\n",
      "Average false positive rate: 0.8\n",
      "Average false negative rate: 0.2\n",
      "Average true negative rate: 0.691796875\n",
      "Average Misclassification Rate: 0.908203125\n",
      "Matthews Correlation Coefficient: -0.1640002986715141\n"
     ]
    }
   ],
   "source": [
    "def true_positive_rate(cm, i, total):\n",
    "    return cm[i][i]/total\n",
    "    \n",
    "def false_positive_rate(cm,j):\n",
    "    fp_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        if (i != j):\n",
    "            fp_rate += cm[i][j]\n",
    "    if ((fp_rate + cm[j][j]) != 0):\n",
    "        return fp_rate/(fp_rate + cm[j][j])\n",
    "    else:\n",
    "        return 0;\n",
    "        \n",
    "def false_negative_rate(cm, i):\n",
    "    fn_rate = 0;\n",
    "    for j in range(0,len(cm)):\n",
    "        if (i != j):\n",
    "            fn_rate += cm[i][j]\n",
    "    if ((fn_rate + cm[j][j]) != 0):\n",
    "        return fn_rate/(fn_rate + cm[j][j])\n",
    "    else:\n",
    "        return 0;\n",
    "\n",
    "def true_negative_rate(cm,i,total):\n",
    "    tn_rate = 0\n",
    "    for j in range(0,len(cm)):\n",
    "        for k in range(0,len(cm)):\n",
    "            if (j != i and k != i):\n",
    "                tn_rate += cm[j][k]\n",
    "    return tn_rate/total\n",
    "\n",
    "def misclassification_rate(cm,l):\n",
    "    fp_rate = 0\n",
    "    fn_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        if (i != l):\n",
    "            fp_rate += cm[i][l]\n",
    "    for j in range(0,len(cm)):\n",
    "        if (l != j):\n",
    "            fn_rate += cm[l][j]\n",
    "    return (fp_rate + fn_rate)/(fp_rate + fn_rate + cm[l][l])\n",
    "    \n",
    "def avg_true_positive_rate(cm):\n",
    "    tp_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        tp_rate += true_positive_rate(cm,i,cm.sum())\n",
    "    return tp_rate/len(cm)\n",
    "\n",
    "def avg_false_positive_rate(cm):\n",
    "    fp_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        fp_rate += false_positive_rate(cm,i)\n",
    "    return fp_rate/len(cm)\n",
    "\n",
    "def avg_false_negative_rate(cm):\n",
    "    fn_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        fn_rate += false_negative_rate(cm,i)\n",
    "    return fn_rate/len(cm)\n",
    "\n",
    "def avg_true_negative_rate(cm):\n",
    "    tn_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        tn_rate += true_negative_rate(cm,i,cm.sum())\n",
    "    return tn_rate/len(cm)\n",
    "\n",
    "def avg_misclassification_rate(cm):\n",
    "    mc_rate = 0\n",
    "    for i in range(0,len(cm)):\n",
    "        mc_rate += misclassification_rate(cm,i)\n",
    "    return mc_rate/len(cm)\n",
    "\n",
    "def matthews(TP,TN,FP,FN):\n",
    "    if ((TP + FP)*(TP + FN)*(TN + FP)*(TN + FN) == 0):\n",
    "        return 0\n",
    "    return (TP*TN - FP*FN)/math.sqrt((TP + FP)*(TP + FN)*(TN + FP)*(TN + FN))\n",
    "\n",
    "def print_table(cm):\n",
    "    print('{:15}'.format('Field'), end='')\n",
    "    print('{:15}'.format('TP'), end='')\n",
    "    print('{:15}'.format('FP'), end='')\n",
    "    print('{:15}'.format('FN'), end='')\n",
    "    print('{:15}'.format('TN'), end='')\n",
    "    print('{:15}'.format('MC Rate'), end='')\n",
    "    print('{:15}'.format('MCC'), end='')\n",
    "    print()\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    for i in range(0,len(cm)):\n",
    "        print('{:15}'.format(attack_labels[i]), end='')\n",
    "        print('{:15}'.format('{:.5f}'.format(true_positive_rate(cm,i,cm.sum()))), end='')\n",
    "        print('{:15}'.format('{:.5f}'.format(false_positive_rate(cm,i))), end='')\n",
    "        print('{:15}'.format('{:.5f}'.format(false_negative_rate(cm,i))), end='')\n",
    "        print('{:15}'.format('{:.5f}'.format(true_negative_rate(cm,i,cm.sum()))), end='')\n",
    "        print('{:15}'.format('{:.5f}'.format(misclassification_rate(cm,i))), end='')\n",
    "        print('{:15}'.format('{:.5f}'.format(matthews(true_positive_rate(cm,i,cm.sum()),true_negative_rate(cm,i,cm.sum()),\n",
    "                                                      false_positive_rate(cm,i),false_negative_rate(cm,i)))),end='')\n",
    "        print()\n",
    "    print()\n",
    "\n",
    "print_table(cm)\n",
    "print(\"Average true positive rate: \" + str(avg_true_positive_rate(cm)))\n",
    "print(\"Average false positive rate: \" + str(avg_false_positive_rate(cm)))\n",
    "print(\"Average false negative rate: \" + str(avg_false_negative_rate(cm)))\n",
    "print(\"Average true negative rate: \" + str(avg_true_negative_rate(cm)))\n",
    "print(\"Average Misclassification Rate: \" + str(avg_misclassification_rate(cm)))\n",
    "print(\"Matthews Correlation Coefficient: \" + str(matthews(avg_true_positive_rate(cm),avg_true_negative_rate(cm),avg_false_positive_rate(cm),avg_false_negative_rate(cm))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

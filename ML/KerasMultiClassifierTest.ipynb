{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Number Generator\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# dataframe = pandas.read_csv(\"kddforpandatrain.csv\")#, header=True)\n",
    "dataframe = pandas.read_csv(\"kdd_dataset.csv\")#, header=True)  # read the whole 10% dataset into dataframe\n",
    "\n",
    "# samples 3000 random data points from 500k\n",
    "dataframe = dataframe.sample(n=30)\n",
    "\n",
    "# LabelEncoder, turns all our categorical data into integers\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply \"le.fit_transform\" to every column (usually only works on 1 column)\n",
    "dataframe_encoded = dataframe.apply(le.fit_transform)\n",
    "\n",
    "dataset = dataframe_encoded.values\n",
    "\n",
    "#Set X as our input data and Y as our label\n",
    "X = dataset[:,0:41].astype(float)\n",
    "Y = dataset[:,41]\n",
    "\n",
    "init_offset = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "# print(dummy_y)\n",
    "print(len(dummy_y[0]))\n",
    "num_of_classes = len(dummy_y[0])  # the length of dummy y is the number of classes we have in our small sample\n",
    "# since we are randomly sampling from a large dataset, we might not get 1 of every class in our sample\n",
    "# we need to set output layer to be equal to the length of our dummy_y vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Vary and log our data using this\n",
    "def set_and_log_hyperparams(offset):\n",
    "    [i, h1, h2, h3, o] = [41, 19 + offset, 5 + offset, 0 + offset, num_of_classes] # add offset to relevant node counts\n",
    "    f = open('KerasOptimizationResults.txt','a+')\n",
    "    f.write(\"inputs: \" + str(i) + \", hidden1: \" + str(h1) + \", hidden2: \" + str(h2) + \", hidden3: \" + str(h3) + \", outputs: \" + str(o))\n",
    "    f.close()\n",
    "    return [i, h1, h2, h3, o] # return the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model(offset):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    inputs = 41\n",
    "    hidden_layer1 = 19\n",
    "    hidden_layer2 = 5\n",
    "    hidden_layer3 = 0\n",
    "    outputs = num_of_classes  #needs to be this variable in case we forget to sample. Could end up having 10 classes or 12, etc\n",
    "    [inputs, hidden_layer1, hidden_layer2, hidden_layer3, outputs] = set_and_log_hyperparams(offset)\n",
    "    \n",
    "    model.add(Dense(hidden_layer1, input_dim=inputs, activation='relu'))\n",
    "    if hidden_layer2 != 0:\n",
    "        model.add(Dense(hidden_layer2, activation='relu'))\n",
    "    if hidden_layer3 != 0:\n",
    "        model.add(Dense(hidden_layer3, activation='relu'))\n",
    "    model.add(Dense(outputs, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a wrapper class that takes no args\n",
    "def get_model():\n",
    "    model = baseline_model(init_offset + 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 83.33% (22.36%)\n",
      "Baseline: 63.33% (31.45%)\n",
      "Baseline: 60.00% (29.06%)\n",
      "Baseline: 76.67% (26.03%)\n",
      "Baseline: 66.67% (29.81%)\n",
      "Baseline: 53.33% (33.99%)\n",
      "Baseline: 66.67% (25.82%)\n",
      "Baseline: 63.33% (34.80%)\n",
      "Baseline: 73.33% (24.94%)\n",
      "Baseline: 60.00% (32.66%)\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "for i in range(0, 10):\n",
    "    estimator = KerasClassifier(build_fn=get_model, epochs=200, batch_size=5, verbose=0)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "    result_string = \"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100)\n",
    "    f = open('KerasOptimizationResults.txt','a+')\n",
    "    f.write(\"      Results: \" + result_string + \"\\n\")\n",
    "    f.close()\n",
    "    print(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this didn't work at all Cause we're doing kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
